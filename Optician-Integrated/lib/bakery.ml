let items : (string,string) Hashtbl.t = Hashtbl.create 37
let _ = Hashtbl.add items "diffy" "module Diffy =\n\nlet sep_list (a:lens) (b:lens) = a . (b . a)*\n\nlet df (name:string) = Tag (Diffy true, Threshold 0, Key, name)\nlet dl (name:string) = Tag (Diffy false, Threshold 0, Key, name)\nlet g (t:int) (name:string) = Tag (Greedy, Threshold t, Key, name)\nlet p (name:string) = Tag (Positional, Threshold 0, Key, name)\n\nlet main = (* df *)\n  let word = (copy [a-z] . del [A-Z]* )+ in\n  let line = sep_list <df \"w\":word> \" \" in\n  let file = sep_list <df \"l\":line> \"\\n\" in\n  file\n\ntest get main \"aRobASe\" = \"aobe\"\ntest get main <<\n  worDonE woRDTwo\n  linETwo loETne lOteE\n  omTEo mENToe o nto\n  aoOEEU thoeu nOEUA\n>> = <<\n  woron wowo\n  linwo lone lte\n  omo moe o nto\n  ao thoeu n\n>>\n\ntest create main \"aoeu\" = \"aoeu\"\ntest create main <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>> = <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>>\n\ntest put main \"a b c\" \"aA bB cC\" = \"aA bB cC\"\n\ntest put main \"a b c d f\" \"aA cC dD eE fF\" = \"aA b cC dD fF\"\n\ntest put main \"a b c\" \"bB cC\" = \"a bB cC\"\ntest put main \"a b c\" \"aA cC\" = \"aA b cC\"\ntest put main \"a b c\" \"aA bB\" = \"aA bB c\"\n\ntest put main \"b c\" \"aA bB cC\" = \"bB cC\"\ntest put main \"a c\" \"aA bB cC\" = \"aA cC\"\ntest put main \"a b\" \"aA bB cC\" = \"aA bB\"\n\ntest put main \"a\" \"aAa aAAAA\" = \"aA\" (* put is done first with <df:l> *)\ntest put main \"a a\" \"aA\" = \"aA a\" (* put is done first *)\n\ntest put main \"b a\" \"aA bB\" = \"b aA\"\n\ntest put main <<\n  ooo ooo oo\n  nn nnn\n  aaa a aa\n  uu u\n  ddd dd d\n>> <<\n  oooOOoO oOOooO oOo\n  aaAAa aAaa aAA aAAa\n  eeEeEE eE\n  uUUuuU uuUU\n>> = <<\n  oooOO oOOooO oOo\n  nn nnn\n  aaAAa aA aAAa\n  uUUu u\n  ddd dd d\n>>\n\ntest put main \"ooo o\" \"oOoOoOO oOOoO oO\" = \"oOoOoOO oOO\" (* strange case *)\n\ntest put main \"o a o a o a o a\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA\"\n\ntest put main \"o a o a o a\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO aAA oOO aAAA oOOO aAAAA\"\n\ntest put main \"o o o o o\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO oOO oOOO oOOOO oOOOOO\"\n\ntest put main \"o o o o\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO oOO oOOO oOOOO\"\n\nlet main =\n  let word = ([a-m] . del [A-Z]* | [n-z] . del [A-Z]* )+ in\n  sep_list (\"+\" . <df \"w\":word> | \"-\" . <df \"w\":word>) \" \"\n\ntest get main \"+aA -bB\" = \"+a -b\"\ntest put main \"+a -b +c -d\" \"+aA -bB +cC -dD\" = \"+aA -bB +cC -dD\"\ntest put main \"+a +c -d\" \"+aA -bB +cC\" = \"+aA +cC -d\"\ntest put main \"-a +n +d -e\" \"+aA -bB +cC -dD\" = \"-aA +n +dD -e\"\n\nlet main = (* dl *)\n  let word = (copy [a-z] . del [A-Z]* )+ in\n  let line = sep_list <dl \"w\":word> \" \" in\n  let file = sep_list <dl \"l\":line> \"\\n\" in\n  file\n\ntest get main \"aRobASe\" = \"aobe\"\ntest get main <<\n  worDonE woRDTwo\n  linETwo loETne lOteE\n  omTEo mENToe o nto\n  aoOEEU thoeu nOEUA\n>> = <<\n  woron wowo\n  linwo lone lte\n  omo moe o nto\n  ao thoeu n\n>>\n\ntest create main \"aoeu\" = \"aoeu\"\ntest create main <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>> = <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>>\n\ntest put main \"a b c\" \"aA bB cC\" = \"aA bB cC\"\n\ntest put main \"a b c\" \"bB cC\" = \"a bB cC\"\ntest put main \"a b c\" \"aA cC\" = \"aA b cC\"\ntest put main \"a b c\" \"aA bB\" = \"aA bB c\"\n\ntest put main \"b c\" \"aA bB cC\" = \"bB cC\"\ntest put main \"a c\" \"aA bB cC\" = \"aA cC\"\ntest put main \"a b\" \"aA bB cC\" = \"aA bB\"\n\ntest put main <<\n  ooo ooo oo\n  nn nnn\n  aaa a aa\n  uu u\n  ddd dd d\n>> <<\n  oooOOoO oOOooO oOo\n  aaAAa aAaa aAA aAAa\n  eeEeEE eE\n  uUUuuU uuUU\n>> = <<\n  oooOO oOOooO oOo\n  nn nnn\n  aAaa aAA aAAa\n  uUUu u\n  ddd dd d\n>>\n\ntest put main \"a\" \"aA aAA\" = \"aAA\" (* deletion is done first ; put at the end *)\ntest put main \"a a\" \"aA\" = \"a aA\" (* creation is done first *)\n\ntest put main \"b a\" \"aA bB\" = \"bB a\"\n\ntest put main \"ooo o\" \"oOoOoOO oOoOO oO\" = \"oOoOoOO oO\" (* strange case *)\n\ntest put main \"o a o a o a o a\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA\"\n\ntest put main \"o a o a o a\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oOO aAAA oOOO aAAAA oOOOO aAAAAA\"\n\ntest put main \"o o o o o\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO oOO oOOO oOOOO oOOOOO\"\n\ntest put main \"o o o o\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oOO oOOO oOOOO oOOOOO\"\n\n(* compose *)\n\nlet main =\n  let a = copy [a-z] . copy [A-Z] . del [0-9] in\n  let b = copy [a-z] . del [A-Z] in\n  let c = a;b in\n  ( <g 0 \"\":a>* ; <g 0 \"\":b>* ) . <g 0 \"\":c>\n\ntest get main \"bB1cC2\" = \"bc\"\ntest put main \"cb\" \"bB1cC2\" = \"cC2bB1\"\n\nlet main =\n  let word1 = ([a-z] . [A-Z]* . del [0-9]* )+ in\n  let line1 = sep_list <df \"w\":word1> \" \" in\n  let file1 = sep_list <df \"l\":line1> \"\\n\" in\n  let word2 = ([a-z] . del [A-Z]* )+ in\n  let line2 = sep_list <df \"w\":word2> \" \" in\n  let file2 = sep_list <df \"l\":line2> \"\\n\" in\n  file1 ; file2\n\ntest get main \"aA0 bB1 cC2\" = \"a b c\"\ntest create main \"a b c\" = \"a b c\"\ntest put main \"a b c\" \"aA0 bB1 cC2\" = \"aA0 bB1 cC2\"\ntest put main \"a c d\" \"aA0 bB1 cC2\" = \"aA0 cC2 d\"\n\n(* we could have wanted \"aA0 cC2 d\"\n   so we need to write : *)\n\nlet main =\n  let word = ([a-z] . [A-Z]* . del [0-9]* )+ ; ([a-z] . del [A-Z]* )+ in\n  let line = sep_list <df \"w\":word> \" \" in\n  let file = sep_list <df \"l\":line> \"\\n\" in\n  file\n\ntest get main \"aA0 bB1 cC2\" = \"a b c\"\ntest create main \"a b c\" = \"a b c\"\ntest put main \"a b c\" \"aA0 bB1 cC2\" = \"aA0 bB1 cC2\"\ntest put main \"a c d\" \"aA0 bB1 cC2\" = \"aA0 cC2 d\"\n\nlet a = copy \"a\" . copy \"b\"*\nlet a2 = copy (\"a\" . \"b\"* )\nlet b = copy \"a\" . del \"b\"*\nlet b2 = align b\n\ntest (\"1\" . <p \"\":a2> | \"2\" . <p \"\":b>) = error\n\nlet main = \"1\" . <p \"\":a> | \"2\" . <p \"\":b>  (* TODO: change <a> to <a2> *)\n\ntest get main \"1abbb\" = \"1abbb\"\ntest get main \"2abbb\" = \"2a\"\ntest create main \"2a\" = \"2a\"\ntest put main \"2a\" \"1abbb\" = \"2abbb\"\n\nlet main = \"1\" . <p \"\":a2> | \"2\" . <p \"\":b2>\n\ntest get main \"1abbb\" = \"1abbb\"\ntest get main \"2abbb\" = \"2a\"\ntest create main \"2a\" = \"2a\"\ntest put main \"2a\" \"1abbb\" = \"2abbb\"\n\ntest <p \"\":main> = error (* no recursive lenses *)\n\nlet main =\n  let wc = copy [a-z] . copy [A-Z]* in\n  let wd = copy [a-z] . del  [A-Z]* in\n  let lwc = (\"C\" . copy [0-9]) . <p \"\":wc> | (\"D\" . copy [0-9]) . <p \"\":wd> in\n  let lwd =  \"C\" . del  [0-9]  . <p \"\":wc> |  \"D\" . del  [0-9]  . <p \"\":wd> in\n  \"A\" . <p \"l\":lwc> | \"B\" . <p \"l\":lwd>\n\ntest get main \"AC1aA\" = \"AC1aA\"\ntest get main \"BD2bB\" = \"BDb\"\n\nlet main =\n  let sep_iter (a:lens) (b:lens) (n:int) = a . lens_iter (b . a) n n in\n  let cn = [a-z] . [A-Z]* in\n  let wn = <df \"c\":cn>+ in\n  let wnc = <df \"w\":wn> in\n  let c = [a-z] . del [A-Z]* in\n  let w = <df \"c\":c>+ in\n  let wc = <df \"w\":w> in\n  ( sep_iter   wnc \" \" 3 . '1' <-> '2' \n  ; sep_iter   wnc \" \" 3 . '2' <-> '3')\n  ; ( sep_iter wnc \" \" 3 . '3' <-> '4' \n    ; sep_iter wc \" \" 3 . '4' <-> '5')\n\ntest get main \"aAbB cCdD eE fF1\" = \"ab cd e f5\"\ntest create main \"a b c e5\" = \"a b c e1\"\ntest put main \"b de ge h5\" \"aAbB cC dDeE fFgG1\" = \"bB dDeE gGe h1\"\n\n(* invert *)\n\nlet main =\n  let l = invert (copy [a-z] . del \"B\") . del [ 0-9]\n  in <df \"\":l>*\n\ntest get main \"a1b2\" = \"aBbB\"\ntest create main \"aBbB\" = \"a b \"\ntest put main \"aBbBcBeB\" \"a1c3d4e5\" = \"a1b3c4e5\"\n\nlet l = copy [a-z] . del \"B\"\n\ntest (invert <p \"\":l>) = error (* chunks in invert *)\n\n(* default *)\n\nlet main =\n  let l = default (copy [a-z] . del [ A-Z]) \"aN\" in\n  <df \"\":l>*\n\ntest get main \"aAbBcCdD\" = \"abcd\"\ntest create main \"abcd\" = \"aNbNcNdN\"\ntest put main \"acde\" \"aAbBcCdD\" = \"aAcCdDeN\"\n\n(* left quot *)\n\nlet main =\n  let c = canonizer_of_lens (sep_list [a-z]+ (\" \" . del \" \"* )) in\n  left_quot c (sep_list [a-z]+ \" \")\n\ntest get main \"a  b   c d\" = \"a b c d\"\ntest create main \"a b c d\" = \"a b c d\"\n\n(* let main = *)\n(*   let a = ([a-z] . [A-Z]* )+ in *)\n(*   let c = canonizer_of_lens (sep_list a (\" \" . del \" \"* )) in *)\n(*   let a = ([a-z] . del [A-Z]* )+ in *)\n(*   left_quot c (sep_list <df:a> \" \") *)\n\n(* test get main \"a  b   c d\" = \"a b c d\" *)\n(* test create main \"a b c d\" = \"a b c d\" *)\n(* test put main \"ab c d ef\" \"aAbB   cC  dD  eEfF\" = \"aAbB cC dD eEfF\" *)\n(* test put main \"a d ef\" \"aAbB   cC  dD  eEfF\" = \"aA dD eEfF\" *)\n\n(* let main = *)\n(*   let s = canonizer_of_lens (\" \" . del \" \"* ) in *)\n(*   let a = ([a-z] . del [A-Z]* )+ in *)\n(*   sep_list <df:a> (left_quot s \" \") *)\n\n(* test get main \"a  b   c d\" = \"a b c d\" *)\n(* test create main \"a b c d\" = \"a b c d\" *)\n(* test put main \"ab c d ef\" \"aAbB   cC  dD  eEfF\" = \"aAbB cC dD eEfF\" *)\n(* test put main \"a d ef\" \"aAbB   cC  dD  eEfF\" = \"aA dD eEfF\" *)\n\n(* right quot *)\n\nlet main =\n  let c = canonizer_of_lens (sep_list [a-z]+ (\" \" . del \" \"* )) in\n  right_quot (sep_list [a-z]+ \" \") c\n\ntest get main \"a b c d\" = \"a b c d\"\ntest create main \"a    b   c  d\" = \"a b c d\"\n\n(* let main = *)\n(*   let a = ([a-z] . [A-Z]* )+ in *)\n(*   let c = canonizer_of_lens (sep_list a (\" \" . del \" \"* )) in *)\n(*   let a = [a-z]+ in *)\n(*   let d = canonizer_of_lens (sep_list a (\" \" . del \" \"* )) in *)\n(*   let a = ([a-z] . del [A-Z]* )+ in *)\n(*   right_quot (left_quot c (sep_list <df:a> \" \")) d *)\n\n(* test get main \"a  b   c d\" = \"a b c d\" *)\n(* test create main \"a   b  c    d\" = \"a b c d\" *)\n(* test put main \"ab  c   d  ef\" \"aAbB   cC  dD  eEfF\" = \"aAbB cC dD eEfF\" *)\n(* test put main \"a     d   ef\" \"aAbB   cC  dD  eEfF\" = \"aA dD eEfF\" *)\n\n(* let main = *)\n(*   let s = canonizer_of_lens (\" \" . del \" \"* ) in *)\n(*   let a = ([a-z] . del [A-Z]* )+ in *)\n(*   sep_list <df:a> (left_quot s (right_quot \" \" s)) *)\n\n(* test get main \"a  b   c d\" = \"a b c d\" *)\n(* test create main \"a     b   c  d\" = \"a b c d\" *)\n(* test put main \"ab    c  d   ef\" \"aAbB   cC  dD  eEfF\" = \"aAbB cC dD eEfF\" *)\n(* test put main \"a   d   ef\" \"aAbB   cC  dD  eEfF\" = \"aA dD eEfF\" *)\n\n(* sort *)\n\nlet main =\n  sort #{regexp}['a';'b';'c']\n\ntest canonize main \"bac\" = \"abc\"\ntest canonize main \"ba\" = error\ntest canonize main \"bbac\" = error\ntest choose main \"bac\" = error\ntest choose main \"abc\" = \"abc\"\n\n(* fiat *)\n\nlet main =\n  let c = sort #{regexp}['a';'b';'c'] in\n  let l = \"abc\" in\n  fiat (right_quot (left_quot c l) c)\n\ntest get main \"abc\" = \"abc\"\ntest get main \"bca\" = \"abc\"\n\ntest put main \"cba\" \"bca\" = \"abc\"\ntest put main \"abc\" \"bca\" = \"bca\"\n\n(* permute *)\n\nlet main =\n  let cc (m:char) (M:char) = m . del M? in\n  let a = cc 'a' 'A' in\n  let b = cc 'b' 'B' in\n  let c = cc 'c' 'C' in\n  lens_permute #{int}[2;0;1] #{lens}[a;b;c]\n\ntest get main \"aAbBcC\" = \"bca\"\ntest create main \"bca\" = \"abc\"\ntest put main \"bca\" \"aAbcC\" = \"aAbcC\"\n\nlet main =\n  let l = [a-z] . del [A-Z]* in\n  let lc = <df \"\":l> in\n  lens_permute #{int}[2;0;1] #{lens}[lc;lc;lc]\n\ntest get main \"aAbBcC\" = \"bca\"\ntest create main \"bca\" = \"abc\"\ntest put main \"bca\" \"aAbcC\" = \"aAbcC\"\n\ntest put main \"ebc\" (* bca *) \"aAbBcC\" = \"cCebB\" (* crossing in the source with diffy *)\n\nlet main =\n  let a =\n    let c =[a-z] . del [A-Z] in\n    <g 0 \"\":c>\n  in\n  let b =\n    let c = key [a-z] in\n    <g 0 \"\":c>\n  in\n  ( a ; b ) . (\n    (\"+\"|\"-\").a.a.a ; (\n      \"+\" . lens_permute #{int}[2;0;1] #{lens}[b;b;b]\n    | \"-\" . b.b.b\n    )\n  ) . ( a ; b )\n\ntest get main \"bB+cCdDeEfF\" = \"b+decf\"\ntest put main \"b+decf\" \"bB+cCdDeEfF\" = \"bB+cCdDeEfF\"\ntest create main \"b+decf\" = \"bA+cAdAeAfA\"\n\ntest get main \"bB-cCdDeEfF\" = \"b-cdef\"\ntest put main \"b-cdef\" \"bB-cCdDeEfF\" = \"bB-cCdDeEfF\"\ntest create main \"b-cdef\" = \"bA-cAdAeAfA\"\n\ntest put main \"b-decf\" \"bB+cCdDeEfF\" = \"bB-dDeEcCfF\"\ntest put main \"b+cdef\" \"bB-cCdDeEfF\" = \"bB+eEcCdDfF\"\n\ntest put main \"d+befc\" \"bB+cCdDeEfF\" = \"dD+fFbBeEcC\"\n\n(* align *)\n\nlet main =\n  (* this is an example of rewriting a asymmetric compose:\n     (file . \"\\n\")? . (p ; line)\n  *)\n  let word = (copy [a-z] . del [A-Z]* )+ in\n  let line = sep_list <df \"w\":word> \" \" in\n  let file = sep_list <df \"l\":line> \"\\n\" in\n  let p = del \"LAST \" . stype line in\n  ((stype file . \"\\n\")? . p) ; align file\n\ntest get main \"LAST aRobASe\" = \"aobe\"\ntest get main <<\n  worDonE woRDTwo\n  linETwo loETne lOteE\n  omTEo mENToe o nto\n  LAST aoOEEU thoeu nOEUA\n>> = <<\n  woron wowo\n  linwo lone lte\n  omo moe o nto\n  ao thoeu n\n>>\n\ntest create main \"aoeu\" = \"LAST aoeu\"\ntest create main <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>> = <<\n  sntoh sanose ate\n  san asnta to\n  LAST snt aoe nst\n>>\n\ntest put main \"a b c\" \"LAST aA bB cC\" = \"LAST aA bB cC\"\n\ntest put main \"a b c d f\" \"LAST aA cC dD eE fF\" = \"LAST aA b cC dD fF\"\n\ntest put main \"a b c\" \"LAST bB cC\" = \"LAST a bB cC\"\ntest put main \"a b c\" \"LAST aA cC\" = \"LAST aA b cC\"\ntest put main \"a b c\" \"LAST aA bB\" = \"LAST aA bB c\"\n\ntest put main \"b c\" \"LAST aA bB cC\" = \"LAST bB cC\"\ntest put main \"a c\" \"LAST aA bB cC\" = \"LAST aA cC\"\ntest put main \"a b\" \"LAST aA bB cC\" = \"LAST aA bB\"\n\ntest put main \"a\"   \"LAST aA aAA\" = \"LAST aA\" (* put is done first with <df:l> *)\ntest put main \"a a\" \"LAST aA\"     = \"LAST aA a\" (* put is done first *)\n\ntest put main \"b a\" \"LAST aA bB\" = \"LAST b aA\"\n\ntest put main <<\n  ooo ooo oo\n  nn nnn\n  aaa a aa\n  uu u\n  ddd dd d\n>> <<\n  oooOOoO oOOooO oOo\n  aaAAa aAaa aAA aAAa\n  eeEeEE eE\n  LAST uUUuuU uuUU\n>> = <<\n  oooOO oOOooO oOo\n  nn nnn\n  aaAAa aA aAAa\n  uUUu u\n  LAST ddd dd d\n>>\n\n(* weight test *)\n\nlet main =\n  sep_list <df \"l\":sep_list <df \"w\":force_nokey (copy [a-z] . del [A-Z]* )+> \" \"> \"\\n\"\n\ntest get main \"aRobASe\" = \"aobe\"\ntest get main <<\n  worDonE woRDTwo\n  linETwo loETne lOteE\n  omTEo mENToe o nto\n  aoOEEU thoeu nOEUA\n>> = <<\n  woron wowo\n  linwo lone lte\n  omo moe o nto\n  ao thoeu n\n>>\n\ntest create main \"aoeu\" = \"aoeu\"\ntest create main <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>> = <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>>\n\ntest put main \"a b c\" \"aA bB cC\" = \"aA bB cC\"\n\ntest put main \"a b c d f\" \"aA cC dD eE fF\" = \"aA bC cD dE fF\"  (* we're doing positional since everything but spaces costs one *)\n\ntest put main \"a b c\" \"bB cC\" = \"aB bC c\"\ntest put main \"a b c\" \"aA cC\" = \"aA bC c\"\ntest put main \"a b c\" \"aA bB\" = \"aA bB c\"\n\ntest put main \"b c\" \"aA bB cC\" = \"bA cB\"\ntest put main \"a c\" \"aA bB cC\" = \"aA cB\"\ntest put main \"a b\" \"aA bB cC\" = \"aA bB\"\n\n(* ambiguous concat *)\n\nlet main =\n  let ac = Native.Prelude.lens_concat in\n  let w = [a-z] . del [ A-Z] in\n  let l = w* in\n  let s = del \".\" in\n  ac (l . s) l\n\ntest get main \"aAbBcC.\" = \"abc\"\ntest put main \"abcde\" \"aAbBcC.\" = \"aAbBcC.d e \"\ntest put main \"ab\" \"aAbBcC.\" = \"aAbB.\"\ntest put main \"cd\" \"aAbBcC.\" = \"cAdB.\"\ntest put main \"ab\" \"aA.bBcC\" = \"aA.bB\"\n\nlet main =\n  let part (r:regexp) (s:regexp) =\n    let ac = Native.Prelude.lens_concat in\n    ac (lens_swap r* s) r*\n  in\n  let wisp = [a-z] in\n  let needle = '!' in\n  let haystack =\n    ( part wisp needle\n    | wisp*\n    )\n  in\n  let needle = needle <=> 'y' in\n  let nothing = \"\" <=> 'n' in\n  let straw = del wisp+ . ins '.' in\n  let sep = ' ' in\n  let first = sep_list haystack sep in\n  let search =\n    ( needle\n    | needle . <p \"p\":straw>\n    | nothing\n    | nothing . <p \"p\":straw>\n    )\n  in\n  let second = sep_list <df \"df\":search> sep in\n  first ; align second\n\nlet source =        \"aoze !  ce!tz totz! nth !nt \"\nlet view =             \"n. y n y. y. n. y. n\"\nlet edited_view =      \"n. n n n. y. n n. n.\"\nlet edited_source = \"aoze   cetz totz!  nt a\"\n\ntest get main source = view\ntest put main view source = source\ntest put main edited_view source = edited_source\ntest put main edited_view edited_source = edited_source\n\ntest put main \"n.\" \"aoeu!snth\" = \"aoeusnth\"\ntest put main \"y.\" \"snth\" = \"!snth\"\n\n(* ambiguous star *)\n\nlet main =\n  let star = Native.Prelude.lens_star in\n  let concat = Native.Prelude.lens_concat in\n  let w = [a-z] . del [ A-Z] in\n  let l = w* in\n  let s = del \".\" in\n  concat l (star (s . l))\n\ntest get main \".aAbB.cC..dD\" = \"abcd\"\ntest put main \"abc\" \"..aA.bB.cC..\" = \"..aA.bB.cC..\"\ntest put main \"abc\" \".aAbB.cC..dD\" = \".aAbB.cC..\"\ntest put main \"ab\" \".aAbB.cC..dD\" = \".aAbB...\"\ntest put main \"\" \".aAbB.cC..dD\" = \"....\"\ntest put main \"ab\" \"\" = \".a .b \"\ntest put main \"abcde\" \".aAbB.cC..dD\" = \".aAbB.cC..dD.e \"\ntest put main \"abcde\" \".aAbB.cC..dD...\" = \".aAbB.cC..dD....e \"\ntest put main \"aoeu\" \"\" = \".a .o .e .u \"\n\nlet main =\n  let star = Native.Prelude.lens_star in\n  let filter (r:regexp) (s:regexp) =\n    star (copy s | del r?)\n  in\n  filter [A-Z] [a-z]\n\nlet source = \"aoeuAOEUsnNtThH\"\nlet view = \"aoeusnth\"\n\ntest get main source = view\ntest put main view source = source\n\nlet edited_view = \"aoeu\"\nlet edited_source = \"aoeuAOEUNTH\"\n\ntest put main edited_view source = edited_source\n\n(* quotienting with alignment *)\n\nlet main =\n  let ch = copy [a-z] . del [A-Z] in\n  let vch = vtype ch in\n  let space = ' '* <-> ' ' in\n  let c =\n    canonizer_of_lens (\n      sep_list space <g 0 \"\":vch>\n    )\n  in\n  let l = sep_list ' ' <g 0 \"\":ch> in\n  right_quot l c . \"#\" . right_quot l c\n\ntest get main \" aA bB # cC dD \" = \"ab#cd\"\ntest put main \"ab#c\" \" aA bB # cC \" = \" aA bB # cC \"\ntest put main \"a#bc\" \" aA bB # cC \" = \" aA # bB cC \"\ntest put main \"  c    b  a  #  d  \" \" aA bB # cC dD \" = \" cC bB aA # dD \"\n\nlet main =\n  let word1 = ([a-z] . del [0-9]* )+ in\n  let line1 = sep_list <df \"w\":word1> \" \" in\n  let file1 = sep_list <df \"l\":line1> \"\\n\" in\n  let word2 = ([a-z] . del [A-Z]* )+ in\n  let line2 = sep_list <df \"w\":word2> \" \" in\n  let file2 = sep_list <df \"l\":line2> \"\\n\" in\n  right_quot file1 (canonizer_of_lens file2)\n\ntest get main \"a0 b1 c2\" = \"a b c\"\ntest create main \"aA bB cC\" = \"a b c\"\ntest put main \"aAO bEU cNSTH\" \"a0 b1 c2\" = \"a0 b1 c2\"\ntest put main \"aAOEU cCCC dD\" \"a0 b1 c2\" = \"a0 c2 d\"\n\nlet main =\n  let a =\n    let c = [a-z] . del [A-Z] in\n    <g 0 \"\":c>\n  in\n  let b =\n    let c = key [a-z] in\n    <g 0 \"\":c>\n  in\n  let ab = right_quot a (canonizer_of_lens b) in\n  ab . (\n    right_quot (\n    (\"+\"|\"-\").a.a.a \n    ) (\n      canonizer_of_lens (\n        \"+\" . lens_permute #{int}[2;0;1] #{lens}[b;b;b]\n      | \"-\" . b.b.b\n      )\n    )\n  ) . ab\n\ntest get main \"bB+cCdDeEfF\" = \"b+ecdf\"\ntest put main \"b+ecdf\" \"bB+cCdDeEfF\" = \"bB+cCdDeEfF\"\ntest create main \"b+ecdf\" = \"bA+cAdAeAfA\"\n\ntest get main \"bB-cCdDeEfF\" = \"b-cdef\"\ntest put main \"b-cdef\" \"bB-cCdDeEfF\" = \"bB-cCdDeEfF\"\ntest create main \"b-cdef\" = \"bA-cAdAeAfA\"\n\ntest put main \"b-ecdf\" \"bB+cCdDeEfF\" = \"bB-eEcCdDfF\"\ntest put main \"b+cdef\" \"bB-cCdDeEfF\" = \"bB+dDeEcCfF\"\n\ntest put main \"d+efbc\" \"bB+cCdDeEfF\" = \"dD+fFbBeEcC\"\n\n(* sort *)\n\nlet main =\n  let X = [A-M] in\n  let Y = [N-Z] in\n  let x = [a-m] in\n  let y = [n-z] in\n  let a = <p \"z\":X> . <p \"w\":Y> in\n  let b = <p \"x\":x> . <p \"y\":y> in\n  let c = <p \"y\":y> . <p \"z\":X> in\n  sort (astypes #{lens}[a;b;c])\n    \ntest canonize main \"AZazyB\" = \"AZazyB\"\ntest canonize main \"yBazAZ\" = \"AZazyB\"\ntest canonize main \"AZaz\" = error\ntest canonize main \"AZAZaz\" = error\ntest choose main \"azAZyB\" = error\ntest choose main \"AZazyB\" = \"AZazyB\"\n\n(* copy on aregexp *)\n\n(* let X = [A-Z] *)\n(* let x = [a-z] *)\n(* let a = astype <p:X> *)\n(* let b = astype <p:x> *)\n(* let c = astype (<p:X> . <p:x>) *)\n\n(* TODO: uncomment *)\n(* test (copy \"\" . a) . b = ? *)\n(* test copy \"\" . (a . b) = ? *)\n\n(* let main = ( a . c )* *)\n\n(* test get main \"BBbCCcDDd\" = \"BBbCCcDDd\" *)\n(* test put main \"EEeFFfBBbDDd\" \"BBbCCcDDd\" = \"EEeFFfBBbDDd\" *)\n\n(* representative of the equivalence *)\n\nlet main =\n  let ch = copy [a-z] . del [A-Z]* in\n  let space = ' '* <-> ' ' in\n  let c =\n    canonizer_of_lens (\n      sep_list <g 0 \"\":ch> space\n    )\n  in\n  let l = sep_list <g 0 \"\":ch> ' ' in\n  right_quot l c\n\ntest get main \"aA bB\" = \"ab\"\ntest put main \"aBBB    bAAA\" \"aAAAA bBBBB\" = \"aAAAA bBBBB\"\ntest vrep main \"aBBB     bCCC\" = \"ab\"\n\n(* ktype and mtype *)\n\nlet main =\n  let word = (copy [a-z] . del [A-Z]* )+ in\n  let line = sep_list <df \"w\":word> \" \" in\n  let file = sep_list <df \"l\":line> \"\\n\" in\n  file\n\n(* test ktype main = ? *)\n(* test mtype main = ? *)\n\n(* mmatch as an operator *)\n\nlet main =\n  <p \"\":align (copy 'a'* . del 'b'* )> . '#' . <p \"\":copy ('a'* . 'b'* )>\n\nlet main = <p \"a\":'a'*>.<p \"b\":'b'>.<p \"a\":del 'a'*>\n\n(* dynamic tags *)\n\nlet main =\n  let c = 'a' in\n  <p \"a\":'a'>.<p c:del 'a'>\n\nlet main = <p \"a\":\"12\">.<p \"a\":'1'.'2'>\n\ntest main.<p \"a\":copy '1'.'2'> = error\n\n(* threshold *)\n\nlet main =\n  let word = (copy [a-z] . del [A-Z]* )+ in\n  let line = sep_list <g 100 \"w\":word> (nokey \" \") in\n  let file = sep_list <g 100 \"l\":line> (nokey \"\\n\") in\n  file\n\ntest put main \"a b c\" \"aA bB cC\" = \"aA bB cC\"\n\ntest put main \"a b c d f\" \"aA cC dD eE fF\" = \"aA b cC dD fF\"\n\ntest put main \"a b c\" \"bB cC\" = \"a bB cC\"\ntest put main \"a b c\" \"aA cC\" = \"aA b cC\"\ntest put main \"a b c\" \"aA bB\" = \"aA bB c\"\n\ntest put main \"b c\" \"aA bB cC\" = \"bB cC\"\ntest put main \"a c\" \"aA bB cC\" = \"aA cC\"\ntest put main \"a b\" \"aA bB cC\" = \"aA bB\"\n\ntest put main \"b c c a d a b\" \"aA aAA aAAA bB bBB cC\" = \"bB cC c aA d aAA bBB\"\n\n(* mtype_match_compatible *)\n\ntest <df \"a\":\"\">.<dl \"a\":\"\"> = error\ntest <df \"a\":<dl \"a\":\"\">> = error\n\ntest <df \"a\":rxlift \"\">.<dl \"a\":rxlift \"\"> = error\ntest <df \"a\":<dl \"a\":rxlift \"\">> = error\n"
let _ = Hashtbl.add items "sys" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2008                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /lenses/core.boom                                                          *)\n(* Imports natively-defined primitives                                        *)\n(* $Id: sys.boom 4629 2009-08-17 20:46:16Z ddavi $ *)\n(******************************************************************************)\n\nmodule Sys = \n\n#{@}\n\n\\section{System functions}\n\n\\LENSSECTION{@read@} The @read@ function reads the contents of a file\nfrom the local filesystem. If the argument is @-@, it reads the\ncontents of the standard input.\n\n#* let read : string -> string \n## = Native.Prelude.read\n\n\\LENSSECTION{@write@} The @write@ function writes a string to a file\non the local filesystem. If the name of the file is @-@, the output is\nthe standard output.\n\n#* let write : string -> string -> unit\n## = Native.Prelude.write\n#* let put_str : string -> unit\n#* = write \"-\"\n\n\\LENSSECTION{@exec@} The @exec@ function executes a shell command. \n\n#* let exec : string -> string \n## = Native.Prelude.exec\n\n\\LENSSECTION{@file_exists@} Test if a file with the given name exists.\n\n#* let file_exists : string -> bool\n## = Native.Prelude.file_exists\n\n\\LENSSECTION{@is_directory@} Returns @true@ if the given name refers\nto a directory, @false@ if not.\n\n#* let is_directory : string -> bool\n## = Native.Prelude.is_directory\n\n\\LENSSECTION{@remove@} Remove the given file name from the file system.\n\n#* let remove : string -> unit\n## = Native.Prelude.remove\n\n\\LENSSECTION{@rename@} Rename a file. The first argument is the old\nname and the second is the new name. Returns @true@ iff the file has\nbeen renamed.\n\n#* let rename : string -> string -> bool\n## = Native.Prelude.rename\n\n\\LENSSECTION{@getcwd@} Return the current working directory of the\nprocess.\n\n#* let getcwd : unit -> string\n## = Native.Prelude.getcwd\n\n\\LENSSECTION{@os_type@} Operating system currently executing\nBoomerang. The return is the same as the ocaml function @sys.os_stype@\nand is\n\\begin{itemize}\n \\item @\"Unix\"@ (for all Unix versions, including Linux and Mac OS X),\n \\item @\"Win32\"@ (for MS-Windows, OCaml compiled with MSVC++ or Mingw),\n \\item @\"Cygwin\"@ (for MS-Windows, OCaml compiled with Cygwin).\n\\end{itemize}\n\n#* let os_type : string\n## = Native.Prelude.os_type\n\n"
let _ = Hashtbl.add items "test_patsubst" "module Test_patsubst =\n\nlet id (a : string) : (b : string where a = b) = a\n\nlet test_pair (p : string * string) =\n  let (x,y) = p in\n  id x\n\nlet test_list (l : string List.t) =\n  let (List.Cons(s,l)) = l in\n  id s\n\nlet l = #{int}[1;2;3]\n\nlet (a::_) = l\ntest a = 1\nlet (_::b) = l\ntest b = List.tl{int} l\nlet (a::b::c) = l\ntest a = 1\ntest b = 2\ntest c = #{int}[3]\n\nlet a,b = 1,2\ntest a = 1\ntest b = 2\ntest (a,b) = (1,2)\n\nlet l2 = #{int}[4;5;6]\nlet (a::_,_::b) = l, l2\nlet (a::_),(_::b) = l, l2\ntest a = 1\ntest b = #{int}[5;6]\n\ntest (match l with\n\t  a::b -> (a, b)\n\t| _ -> (0, #{int}[])) = (1,List.tl{int} l)\n\ntest (match l,l2 with\n\t  a::_, c::_ -> (a, c)\n\t| _ -> (0, 0)) = (1,4)\n\ntest (match l,l2 with\n\t  _::b, _::d -> List.append{int} b d\n\t| _ -> #{int}[]) = #{int}[2;3;5;6]\n\ntest (match #{int}[100;200] with\n\t| a::b::c::d -> 0\n\t| a::[] -> 1\n\t| a::_::c -> a\n\t| _::b -> 2\n\t| _ -> 3) = 100\n\ntest (match #{int}[100] with\n\t| a::[] -> a\n\t| _ -> 0) = 100\n\ntest (match #{int}[100;200] with\n\t| 100::[] -> 1\n\t| 100::200::[] -> 100\n\t| _ -> 0) = 100\n\ntest (match #{int}[100;200] with\n\t| 100::[] -> 1\n\t| 100::200::[] -> 100\n\t| _ -> 0) = 100\n\ntest (match Some{int} 2, None{int}, #{int}[100] with\n\t| None, _, _ -> 1\n\t| _, Some _, _ -> 2\n\t| _, None, a::b::c -> 3\n\t| _, _, 101::_ -> 4\n\t| Some 1, _, _ -> 5\n\t| Some 2, _, a::_ -> a\n\t| _ -> 100) = 100\n"
let _ = Hashtbl.add items "prelude" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2008                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /lenses/prelude.boom                                                       *)\n(* Boomerang definitions of lens primitives                                   *)\n(* $Id: prelude.boom 4995 2011-03-08 16:32:54Z jnfoster $ *)\n(******************************************************************************)\n\nmodule Prelude =\n\n#{@}\n\n\\section{The Standard Prelude}\n\nThe second module, @Prelude@, defines some common derived forms. Like\n@Core@, its values are available by default in every Boomerang\nprogram.\n\n\\subsection{Regular Expressions}\n\n\\LENSSECTION{@ANYCHAR@, @ANY@, @ANYP@}\n\nThe regular expression @ANYCHAR@ denotes the set of ASCII characters, \n@ANY@ denotes the set of all ASCII strings, and @ANYP@ denotes the \nset of all ASCII strings except for the empty string. By \nconvention, we append a ``P'' to the name of a regular expression \nto denote its ``positive'' variant (i.e., not containing the empty\nstring).\n\n#* let ANYCHAR : regexp = [^]\n#* let ANY : regexp = ANYCHAR*\n#* let ANYP : regexp = ANYCHAR+\n\n\\LENSSECTION{@containing@,@containingP@,@not_containing@,@not_containingP@}\nThe function @containing@ takes a regular expression @R@ as an\nargument and produces a regular expression describing the set of all\nstrings that contain a substring described by @R@.  The @-P@ variants\nrequire non-empty strings.\n\n#* let containing  (R:regexp) : regexp = ANY . R . ANY\n#* let containingP (R:regexp) : regexp = (ANY . R . ANY) - []\n\nThe function @not_containing@ takes a regular expression @R@ and\nproduces a regular expression describing the set of all strings not\ncontaining @R@.\n\n#* let not_containing  (R:regexp) : regexp = ANY - (containing R)\n#* let not_containingP (R:regexp) : regexp = ANYP - (containing R)\n\n\\LENSSECTION{@SCHAR@, @S@, @SP@}\n\nThe regular expressions @SCHAR@, @S@, and @SP@ denote sets of \nspace characters.\n\n#* let SCHAR : regexp = [ ]\n#* let S : regexp = SCHAR*\n#* let SP : regexp = SCHAR+\n\n\\LENSSECTION{@WSCHAR@, @WS@, @WSP@}\n\nThe regular expressions @WSCHAR@, @WS@, and @WSP@ denote sets of \nwhitespace characters.\n\n#* let WSCHAR : regexp = [ \\t\\r\\n]\n#* let WS : regexp = WSCHAR*\n#* let WSP : regexp = WSCHAR+\n\n\\LENSSECTION{@NWSCHAR@, @NWS@, @NWSP@}\n\nThe regular expressions @WSCHAR@, @WS@, and @WSP@ denote sets of \nnon-whitespace characters.\n\n#* let NWSCHAR : regexp = [^ \\t\\r\\n]\n#* let NWS : regexp = NWSCHAR*\n#* let NWSP : regexp = NWSCHAR+\n\n\\LENSSECTION{@newline@, @NLn@} The string @newline@ contains \nthe newline character. The strings given by @NL@$n$ each \ndenote a newline followed by $n$ spaces. These are used for indentation, \nfor example, in the @Xml@ module.\n\n#* let newline : string = \"\\n\"\n#* let NL0 : string= newline\n#* let NL1 : string= NL0 . \" \"\n#* let NL2 : string= NL1 . \" \"\n#* let NL3 : string= NL2 . \" \"\n#* let NL4 : string= NL3 . \" \"\n#* let NL5 : string= NL4 . \" \"\n#* let NL6 : string= NL5 . \" \"\n#* let NL7 : string= NL6 . \" \" \n#* let NL8 : string= NL7 . \" \"\n#* let NL9 : string= NL8 . \" \"\n#* let NL10 : string = NL9 . \" \"\n\n\\LENSSECTION{@DIGIT@, @NUMBER@, @FNUMBER@} The regular expressions \n@DIGIT@, @NUMBER@, and @FNUMBER@ represent strings of decimal digits, \nintegers, and floating point numbers respectively.\n\n#* let DIGIT : regexp = [0-9]\n#* let NUMBER : regexp = [0] | [1-9] . DIGIT* \n#* let FNUMBER : regexp = NUMBER . ([.] . DIGIT+)?\n\n\\LENSSECTION{@UALPHACHAR@, @UALPHANUMCHAR@} \nThe regular expression @UALPHACHAR@ and @UALPHANUMCHAR@ \ndenote the set of upper case alphabetic and alphanumeric \ncharacters respectively.\n\n#* let UALPHACHAR : regexp = [A-Z]\n#* let UALPHANUMCHAR : regexp = [A-Z0-9]\n\n\\LENSSECTION{@is_cset@}\nThe predicate @is_cset@ on regular expressions determines whether a\nregular expression identifies a set of characters.\n\n#* let is_cset (R:regexp) : bool = equiv_cex R (R & ANYCHAR)\n\n\\LENSSECTION{@subset@}\nThe binary predicate @subset@ decides whether the first regular\nexpression is a subset of the second.\n\n#* let subset (R1:regexp) (R2:regexp) : bool \n#*   = equiv_cex (R1 & R2) R1\n\n## test subset EMPTY [a-z] = true\n## test subset [a-z] [a-z] = true\n## test subset [abc] [a-z] = true\n## test subset [ab1] [a-z] = false\n\n\\subsection{Lenses}\n\n\\LENSSECTION{@lens_equiv@}\nThe binary operator on lenses, @lens_equiv@, tests whether the\n@astype@s and @avtype@s of two lenses are equivalent regular expressions\n(according to @equiv@).\n\n#* let lens_equiv (l1:lens) (l2:lens) : bool =\n#*  (equiv_cex (stype l1) (stype l2)) &&\n#*  (equiv_cex (vtype l1) (vtype l2))\n\n\\LENSSECTION{@ins@} The lens @ins@ maps the empty concrete \nstring to a fixed abstract string. It is defined straightforwardly \nusing @<->@.\n\n#* let ins (s:string) : (lens in EPSILON <=> s) = \"\" <-> s\n#* test get (ins \"ABC\") \"\" = \"ABC\"\n#* test put (ins \"ABC\") \"ABC\" \"\" = \"\"\n\n\\LENSSECTION{@del@} The lens @del@ deletes a regular expression. \nIt is also defined using @<->@.\n\n#* let del (R:regexp) : (lens in R <-> EPSILON) = R <-> \"\"\n\n#* test get (del ANY) \"Boomerang\" = \"\"\n#* test put (del ANY) \"\" \"Boomerang\" = \"Boomerang\"\n#* test create (del ANY) \"\" = \"\"\n\n\\LENSSECTION{@merge_with_sep@} The lens @merge_with_sep@ behaves like @merge@, \nbut allows a separator between the copied string. \n\n#* let merge_with_sep (R:regexp) (s:string) : (lens in (R . s . R) <-> R) = \n#*   copy (R . s . R) . ins s; \n#*   merge (R . s); \n#*   copy R . del s\n\n#* test (merge_with_sep [A-Z] \",\").get \"A,B\" = \"A\"\n#* test (merge_with_sep [A-Z] \",\").put \"C\" into \"A,B\" = \"C,B\"\n#* test (merge_with_sep [A-Z] \",\").create \"B\" = \"B,B\"\n\n\\subsection{Lens Predicates}\n\n\\LENSSECTION{@lens_iterable@} This predicate is true for lenses with\niterable stype and vtype.\n\n#* let lens_iterable (l:lens) : bool = \n#*   iterable_cex (stype l) && iterable_cex (vtype l)\n\n\\LENSSECTION{@lens_splittable@} This predicate is true for a pair of lenses\nif the stypes and vtypes are splittable.\n\n#* let lens_splittable (l1:lens) (l2:lens) : bool =\n#*   splittable_cex (stype l1) (stype l2) &&\n#*   splittable_cex (vtype l1) (vtype l2)\n\n\\LENSSECTION{@lens_unionable@,@lens_disjoint@} This predicate is true\nfor a pair of lenses if the astypes are disjoint and the equivalence\nrelation abstract domain of the second lens is the identity relation.\n\n#* let lens_unionable (l1:lens) (l2:lens) : bool =\n#*   disjoint_cex (stype l1) (stype l2) &&\n#*   rel_is_id (vequiv l2) && is_basic l1 && is_basic l2\n\n#* let lens_disjoint (l1:lens) (l2:lens) : bool =\n#*   disjoint_cex (stype l1) (stype l2) &&\n#*   disjoint_cex (vtype l1) (vtype l2)\n\n\\subsection{Quotient Lenses}\n\n\\LENSSECTION{@qconst@} The lens @qconst@ is like @const@, but accepts an \nentire regular expression on the abstract side. It is defined using quotienting \non the right, the lens @const@, and a canonizer built from @const@.\n\n#* let qconst (C:regexp) (A:regexp) (a:string where matches A a) (c:string where matches C c) \n#*   : (lens in C <-> A)\n#*   = \n#*   right_quot     \n#*     (const C a c)\n#*     (canonizer_of_lens (const A a a))\n\n#* test get (qconst [A-Z] [a-z] \"a\" \"A\") \"A\" = \"a\"\n#* test put (qconst [A-Z] [a-z] \"a\" \"A\") \"b\" \"B\" = \"B\"\n\n\\LENSSECTION{@qset@} The lens @qconst@ is like @set@ (i.e., @<->@), \nbut takes an entire regular expression on the abstract side. It is defined \nusing @qconst@.\n\n#* let qset (C:regexp) (A:regexp) : (lens in C <-> A) = \n#*  qconst C A (representative A) (representative C)\n\n#* test get (qset [A-Z] [a-z]) \"A\" = \"a\" \n#* test get (qset [A-Z] [a-z]) \"Z\" = \"a\" \n#* test put (qset [A-Z] [a-z]) \"z\" \"A\" = \"A\" \n#* test put (qset [A-Z] [a-z]) \"z\" \"Z\" = \"Z\" \n\n\\LENSSECTION{@qins@,@qins_representative@} The lens @qins@ is like\n@ins@ but accepts a regular expression in the $\\PUT$ direction. It is\ndefined using right quotienting and @ins@. The lens\n@qins_representative@ is +similar, but uses an arbitrary\nrepresentative of @E@ in the $\\GET$ direction.\n\n#* let qins (E:regexp) (e:string in E) : (lens in EPSILON <-> E) = \n#*   right_quot\n#*     (ins e)\n#*     (canonizer_of_lens (const E e e))\n\n#* test (get (qins [A-Z]+ \"A\") \"\") = \"A\"\n#* test (create (qins [A-Z]+ \"A\") \"ABC\") = \"\"\n\n#* let qins_representative (E:regexp) : (lens in EPSILON <-> E) =\n#*   qins E (representative E)\n\n#* test (get (qins_representative [A-Z]+) \"\") = \"A\"\n#* test (create (qins_representative [A-Z]+) \"ABC\") = \"\"\n\n\\LENSSECTION{@qdel@} The lens @qdel@ is like @del@ \nbut produces a canonical representative in the backwards direction. \nIt is defined using left quotienting.\n\n#* let qdel (E:regexp) (e:string) : (lens in E <-> EPSILON) = \n#*   left_quot \n#*     (canonizer_of_lens (default (del E) e))\n#*     (copy EPSILON)\n\n#* test (get (qdel [A-Z]+ \"ZZZ\") \"ABC\") = \"\"\n#* test (put (qdel [A-Z]+ \"ZZZ\") \"\" \"ABC\") = \"ZZZ\"\n#* test (put (qdel [A-Z]+ \"ZZZ\") \"1\" \"ABC\") = error\n\n\\subsection{Standard Datatypes}\n\n\\LENSSECTION{@'a option@, @('a,'b) maybe@} The polymorphic datatypes @option@ and @maybe@ \nrepresents optional and alternative values respectively.\n\n#* type 'a option = \n#*     None | Some of 'a\n\n#* type ('a,'b) maybe = \n#*     Left of 'a | Right of 'b \n\n\\subsection{Pairs}\n\n\\LENSSECTION{@fst@,@snd@} \nThe polymorphic functions @fst@ and @snd@ are the standard projections on pairs.\n\n#*let fst ('a) ('b) (p:'a * 'b) : 'a = \n#*  let x,_ = p in x\n\n#*let snd ('a) ('b) (p:'a * 'b) : 'b = \n#*  let _,y = p in y\n\n\\subsection{Lists of Lenses and Regular Expressions}\n\n\\LENSSECTION{@astypes@,@avtypes@} Calculates the @astype@s and @avtype@s of lists of \nlenses.\n\n#* let astypes (ls:lens List.t) = List.map{lens}{aregexp} astype ls\n#* let avtypes (ls:lens List.t) = List.map{lens}{aregexp} avtype ls\n#* let stypes (ls:lens List.t) = List.map{lens}{regexp} stype ls\n#* let vtypes (ls:lens List.t) = List.map{lens}{regexp} vtype ls\n\n\\LENSSECTION{@concatable@} The list of regexps @Rs = #{regexp}[R1;R2;...;Rn]@ \nare concatenable with regexp separator @S@ if the following are splittable:\n\\begin{itemize}\n    \\item @R1@ and @S@\n    \\item @R1.S@ and @R2@\n    \\item @R1.S.R2.S@ and @R3@\n    \\item ...\n    \\item @R1.S...SRn-1@ and @Rn@\n\\end{itemize}\n\n#* let concatable (rl : regexp List.t) : bool =\n##  let (res,_) = \n##    List.fold_left{regexp}{bool * regexp option}\n##      (fun (acc:bool * regexp option) (ri:regexp) -> match acc with\n##         | (true,None) -> (true,Some{regexp}(ri))\n##         | (true,(Some(racc))) -> \n##            begin match splittable_cex racc ri with\n##              | true -> (true,Some{regexp}(racc . ri))\n##              | cx   -> (cx,None{regexp})\n##            end \n##         | (cx,_) -> (cx,None{regexp}))\n##      (true,None{regexp}) rl in\n##  res\n\n#* test concatable #{regexp}[\"abc\";\"def\"] = true\n#* test concatable #{regexp}[\"abc\";\"def\"] = true\n#* test concatable #{regexp}[\"a\" | \"aa\";\"a\"?] = false\n\n\\LENSSECTION{@concat_regexps@,@concat_lenses@} Concatenates a list of regular \nexpressions or lenses, respectively.\n\n#* let concat_regexps (Rs:regexp List.t) : regexp =\n#*  List.fold_left{regexp}{regexp} \n#*    (fun (acc:regexp) (R:regexp) -> acc . R) \n#*    EPSILON Rs\n\n#* test concat_regexps #{regexp}[\"abc\";\"def\"] = \"abcdef\"\n#* test concat_regexps #{regexp}[\"a\"{5};\"a\"*] = \"a\"{5,}\n\n#* let concat_lenses (ls:lens List.t where (concatable (stypes ls))\n#*                                      && (concatable (vtypes ls)))\n#*   : (lens in concat_regexps (stypes ls)\n#*          <-> concat_regexps (vtypes ls))\n#*   =  List.fold_left{lens}{lens} \n#*       (fun (l_acc:lens) (l:lens) -> l_acc . l)\n#*       (copy EPSILON) ls \n\n#* test get (concat_lenses #{lens}[copy \"a\";copy \"b\";copy \"c\"]) \"abc\" = \"abc\"\n\n\\LENSSECTION{@disjoint_from_regexps@,@disjoint_regexps@} The function \n@disjoint_from_regexps@ determines whether a given regexp is disjoint from a \nlist of regular expressions.  The function @disjoint_regexps@ determines \nwhether a list of regular expressions are pairwise disjoint.\n\n#* let disjoint_from_regexps (R:regexp) (Rs:regexp List.t) =\n#*   List.fold_left{regexp}{bool}\n#*     (fun (ok:bool) (R':regexp) ->\n#*\t ok && disjoint_cex R R')\n#*     true Rs\n\n#* let disjoint_regexps (Rs:regexp List.t) : bool =\n#*   let (ok,_) = List.fold_left{regexp}{bool * regexp List.t}\n#*     (fun (acc:bool * regexp List.t) (R:regexp) ->\n#*        let (ok,Rs) = acc in\n#*        (ok && disjoint_from_regexps R Rs,List.Cons{regexp}(R,Rs)))\n#*     (true,#{regexp}[]) Rs in\n#*   ok\n\n#* test disjoint_regexps #{regexp}[\"a\";\"b\";\"c\"] = true\n\n\\LENSSECTION{@union_regexps@,@union_lenses@,@disj_union_lenses@} Takes the \nunion of a list of regular expressions or lenses, respectively. By default, \nthe non-disjoint lens union @||@ is used; use @disj_union_lenses@ for disjoint \nunion @|@.\n\n#* let union_regexps (Rs:regexp List.t) : regexp =\n#*  List.fold_left{regexp}{regexp} \n#*    (fun (acc:regexp) (R:regexp) -> acc | R) \n#*    EMPTY Rs\n\n#* test union_regexps #{regexp}[\"abc\";\"def\"] = (\"abc\" | \"def\")\n#* test union_regexps #{regexp}[\"a\"{5};\"a\"*] = (\"a\"{5} | \"a\"* )\n\n% TODO: Isn't this false?  What about the condition on the relation in the view?\n#* let union_lenses (ls:lens List.t where disjoint_regexps (stypes ls))\n#*   : (lens in union_regexps (stypes ls)\n#*          <-> union_regexps (vtypes ls))\n#*   = \n#*   List.fold_left{lens}{lens} \n#*   (fun (l_acc:lens) (l:lens) -> l_acc || l)\n#*   (copy EMPTY) ls\n\n#* test create (union_lenses #{lens}[\"z\" <-> \"a\"; (copy [a-c])]) \"a\" = \"z\"\n#* test get (union_lenses #{lens}[copy \"a\";copy \"b\";copy \"c\"]) \"a\" = \"a\"\n\n#* let disj_union_lenses (ls:lens List.t where \n#*                          disjoint_regexps (stypes ls) &&\n#*                          disjoint_regexps (vtypes ls))\n#*   : (lens in union_regexps (stypes ls)\n#*          <-> union_regexps (vtypes ls))\n#*   = List.fold_left{lens}{lens} \n#*     (fun (l_acc:lens) (l:lens) -> \n#*        (l_acc | l))\n#*     (copy EMPTY) ls\n\n#* test disj_union_lenses #{lens}[copy [a]; \"a\" <-> \"b\"] = error\n#* test get (disj_union_lenses #{lens}[copy \"a\";copy \"b\";copy \"c\"]) \"a\" = \"a\"\n\n\\subsection{Lenses with List Arguments}\n\nThese final two combinators take lists as arguments (and so have to be defined\nhere instead of @Core@.)\n\nFirst, we have @permute@.\n\n\\LENSSECTION{@permute@} The lens @permute@ is an $n$-ary, permuting \nconcatenation operator on lenses. Given a concrete string, it splits it \ninto $n$ pieces, applies the $\\GET$ function of the corresponding lens to each \npiece, reorders the abstract strings according to the fixed permutation \nspecified by @sigma@, and concatenates the results.  Given a permutation \n@sigma@ and a list of lenses @l = #{lens}[l1;l2;...;ln]@ with types \n@Ci <-> Ai@.  It produces a lens with type \n@C1.C2...Cn <-> Asigma(1).Asigma(2)...Asigma(n)@.\n\n#* let lens_permute \n#*   (sigma:int List.t)\n#*   (ls:lens List.t where \n#*     (List.valid_permutation{lens} sigma ls) &&\n#*     ((concatable (stypes ls)) &&\n#*      (concatable (List.permute{regexp} sigma (vtypes ls)))))\n#*   : (lens in concat_regexps (stypes ls) <-> \n#*              concat_regexps (List.permute{regexp} sigma (vtypes ls)))\n##   = Native.Prelude.lens_permute sigma ls\n\n#* test stype (lens_permute #{int}[1;0] #{lens}[\"abc\";\"def\"]) = \"abcdef\"\n#* test vtype (lens_permute #{int}[1;0] #{lens}[\"abc\";\"def\"]) = \"defabc\"\n#* test get (lens_permute #{int}[2;0;1] #{lens}[\"abc\";\"def\";\"ghi\"]) \n#*   \"abcdefghi\" = \"defghiabc\"\n#* test get (lens_permute \n#*             #{int}[2;1;0]\n#*             #{lens}[(copy UALPHACHAR);\n#*                     (copy UALPHACHAR);\n#*                     (copy UALPHACHAR)]) \"ABC\" = \"CBA\"\n\n\\LENSSECTION{@partition@} The @partition@ operator takes a list of regular expressions \n@Rs@ as arguments and produces a lens whose $\\GET$ function transforms a string \nbelonging to the iteration of the union of the @Rs@ by sorting the substrings \ninto substrings that belong to the elements of @Rs@. The regular expressions @Rs@ \nmust\nbe disjoint and the iteration of their union must be unambiguous.\n\n#* let partition \n#*     (Rs:regexp List.t where (disjoint_regexps Rs)\n#*            && (iterable_cex (union_regexps Rs)))\n#*   : (lens in (union_regexps Rs)* <-> concat_regexps (List.map{regexp}{regexp} regexp_star Rs))\n##   = Native.Prelude.partition Rs\n\n#* test get (partition #{regexp}[[A-Z];[0-9]]) \"A1B2C3\" = \"ABC123\"\n#* test put (partition #{regexp}[[A-Z];[0-9]]) \"ABC123456\" \"A1B2C3\" = \"A1B2C3456\"\n\n\\LENSSECTION{@filter@} The @filter@ operator takes two regular expressions @R@ \nand @S@ as arguments and produces a lens whose $\\GET$ function\ntransforms a string belonging to the iteration of the union of @R@ and @S@\nby discarding all of the substrings belonging to @R@. The regular expressions\n@R@ and @S@ must be disjoint and the iteration of their union must be \nunambiguous.\n\n#* let filter \n#*     (R:regexp) \n#*     (S:regexp where (disjoint_cex R S) && (iterable_cex (R | S)))\n#*   : (lens in (R | S)* <-> S* )\n#*   = partition #{regexp}[R; S]; \n#*     ( del R* . copy S* )\n\n#* test get (filter [A-Z] [0-9]) \"A1B2C3\" = \"123\"\n#* test put (filter [A-Z] [0-9]) \"123456\" \"A1B2C3\" = \"A1B2C3456\"\n\n\\LENSSECTION{@sortable@, @sort@} The canonizer @sort@ puts substrings into \nsorted order according to a list of regular expressions. An exception \nis raised if the unsorted string does not have exactly one substring \nbelonging to each regular expression. This allows us to assign sort a type \nthat is compact (though imprecise); see~\\cite{QuotientLens08} for a discussion.\n\n#* let sortable (rl:regexp List.t) : bool = \n#*      disjoint_regexps (List.map{regexp}{regexp} (fun (r:regexp) -> r - EPSILON) rl) \n#*   && iterable_cex ((union_regexps rl) - EPSILON)\n\n#* let sort \n#*   (rl:aregexp List.t where sortable (List.map{aregexp}{regexp} rxdrop rl)) \n#* : (cn:canonizer where (uncanonized_type cn = (union_regexps (List.map{aregexp}{regexp} rxdrop rl))* )\n#*                    && (canonized_type cn = concat_regexps (List.map{aregexp}{regexp} rxdrop rl)))\n## = Native.Prelude.sort rl\n\n#* test canonize (sort #{regexp}[UALPHACHAR; DIGIT]) \"A1\" = \"A1\"\n#* test canonize (sort #{regexp}[UALPHACHAR; DIGIT]) \"1A\" = \"A1\"\n#* test canonize (sort #{regexp}[UALPHACHAR; DIGIT]) \"A\" = error\n#* test sort #{regexp}[\"a\";\"a\"] = error\n\n#* test uncanonized_type (sort #{regexp}[UALPHACHAR; DIGIT]) =\n#*   (UALPHACHAR | DIGIT)*\n\n#* test canonized_type (sort #{regexp}[UALPHACHAR; DIGIT]) = \n#*   (UALPHACHAR . DIGIT)\n\n\\subsection{Miscellaneous}\n\n\\LENSSECTION{@iterate@} The operator @iterate@ compose @f@ with itself\n @i@ times using @b@ for the first argument, i.e., @f(f(...(f b)...))@\n where @f@ appears @i@ times.\n\n#* let iterate ('a) (i:int where (bgeq i 0)) (f:'a -> 'a) (b:'a) : 'a =\n#*   List.fold_left{int}{'a}\n#*     (fun (acc:'a) (i:int) -> f acc)\n#*     b\n#*     (List.mk_seq i)\n\n#* test (iterate{regexp} 3 (fun (x:regexp) -> x | \"(\".x.\")\") [a-z]).get \"((b))\" = \"((b))\"\n#* test (iterate{regexp} 3 (fun (x:regexp) -> x | \"(\".x.\")\") [a-z]).get \"((((b))))\" = error\n\n\\LENSSECTION{@show@} Gives a string representation of the value. Some\nvalues cannot be translated in full, e.g., functions.\n\n#* let show : forall 'a => 'a -> string\n## = Native.Prelude.poly_show\n\n\\LENSSECTION{@int_of_string@} The operator @int_of_string@ converts a string \nto the corresponding integer. \n\n#* let int_of_string : ( string in (\"-\"? . [0-9]+ ) ) -> int \n## = Native.Prelude.int_of_string\n"
let _ = Hashtbl.add items "conflin" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2007 J. Nathan Foster and Benjamin C. Pierce                 *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /examples/conflin.boom                                                     *)\n(* management tool for multiple versions of the same file                     *)\n(* $Id:: conflin.boom 4901 2010-05-13 21:14:49Z cretin                      $ *)\n(******************************************************************************)\n(*@view: *)(*@*)\nmodule Conflin =\n\n(* ---------------------------------------------------------------- *)\n(*                               TODO                               *)\n(*\n\n ! check the value (identifier in File_pref) before using it ; also\n   change the way we get this value (see writing an Arg module)\n\n x add a --force option ; we check the date of the files to see if the\n   given file is the right one\n\n x add a lock when doing a put, to avoid potentials simultaneous puts\n\n - add a string_pref that returns a string option (without default)\n\n - try to make it multi-parameter but linear\n\n - give a better error message when doing a put with the wrong value\n   in view prefix\n\n - add a rename lens maybe (or just with another value of format)\n\n - check the tests in main_lens and put them in main if the user is\n   able to give a specific preference ; something better would be to\n   add a check function in File_pref\n\n *)\n\n(* ---------------------------------------------------------------- *)\n(*                           definitions                            *)\n\nlet if 'a (b:bool) (t:'a) (f:'a) =\n  match b with\n  | true -> t\n  | false -> f\n  :'a\nlet id 'a (x:'a) = x\nlet ambiguous_lens_concat_contract (a:lens) (b:lens) =\n  is_basic a && is_basic b && splittable_cex (stype a) (stype b)\nlet ambiguous_lens_concat (a:lens) (b:lens where ambiguous_lens_concat_contract a b) =\n  Native.Prelude.lens_concat a b\nlet ambiguous_lens_partition_one_contract (a:lens) (b:lens) =\n  lens_star_contract b && lens_swap_contract b* a\n  && ambiguous_lens_concat_contract (lens_swap b* a) b*\nlet ambiguous_lens_partition_one (a:lens) (b:lens where ambiguous_lens_partition_one_contract a b) =\n  ambiguous_lens_concat (lens_swap b* a) b*\nlet positional (name:string) = Tag (Positional, Threshold 0, Key, name)\nlet diffy (first:bool) (name:string) = Tag (Diffy first, Threshold 0, Key, name)\nlet show_list 'a (l:'a List.t) =\n  \"[\" . fst{string}{bool} (\n    List.fold_left{'a}{string * bool} (\n      fun (sb:string * bool) (x:'a) ->\n        match sb with\n        | s, b -> (s . if{string} b \";\" \"\" . show{'a} x, true)\n            :string * bool\n    ) (\"\", false) l\n  ) . \"]\"\nlet mk_error (message:string) = \"Error: \" . message\nlet identifier = [a-zA-Z] . [ a-zA-Z0-9_\\-@]*\nlet is_lens (l:lens) = rel_is_id (sequiv l) && rel_is_id (vequiv l)\nlet show_s = show{string}\nlet if_none 'a (x:'a) (yo:'a option) =\n  match yo with\n  | None -> x\n  | Some y -> y\n  :'a\nlet if_none_s = if_none{string}\nlet write (file:string) (data:string) =\n  let _ = Sys.write file data in 0\nlet read = Sys.read\nlet file_exists = Sys.file_exists\nlet put_str_ln (x:string) = Sys.put_str (x . newline)\n\n(*@*)\n(* ---------------------------------------------------------------- *)\n(*                         File_pref module                         *)\n\nmodule File_pref =\n  type t = T of regexp(*@!*)(*@*) * (string * string) * (string * string) * string\n  let make (values:regexp)(*@!*)(*@*)\n      (comment_prefix:string) (comment_suffix:string)\n      (command_prefix:string) (command_suffix:string)\n      (view_prefix:string) =\n    T (values,(*@!*)(*@*)\n       (comment_prefix, comment_suffix),\n       (command_prefix, command_suffix),\n       view_prefix)\n  let default_view_prefix = \"view: \"\n  let default_commands = \"@\", \"\"(*@!*)(*@*)\n  let uncuttable_prefix, uncuttable_suffix = \"\", \"!\"\n  let shell_like = T (identifier, (\"#\", \"\\n\"), default_commands, default_view_prefix)\n  let c_like = T (identifier, (\"//\", \"\\n\"), default_commands, default_view_prefix)\n  let cpp_like = T (identifier, (\"/*\", \"*/\"), default_commands, default_view_prefix)\n  let ocaml_like = T (identifier, (\"(*\", \"*)\"), default_commands, default_view_prefix)\n  let debug_like = T ([a-z], (\"(\", \")\"), (\"\", \"\"), \"\")\n  let set_command_prefix (x:string) (t:t) =\n    match t with\n    | T (values, comments, (_, command_suffix), view_prefix) ->\n        T (values, comments, (x, command_suffix), view_prefix)\n    :t\n  let set_command_suffix (x:string) (t:t) =\n    match t with\n    | T (values, comments, (command_prefix, _), view_prefix) ->\n        T (values, comments, (command_prefix, x), view_prefix)\n    :t\n  let get_values (t:t) =\n    match t with\n    | T (values, _, _, _) -> values\n    :regexp\n  let get_comments (t:t) =\n    match t with\n    | T (_, comments, _, _) -> comments\n    :string * string\n  let get_commands (t:t) =\n    match t with\n    | T (_, _, commands, _) -> commands\n    :string * string\n  let get_view_prefix (t:t) =\n    match t with\n    | T (_, _, _, view_prefix) -> view_prefix\n    :string\n  let comment_signs (t:t) =\n    let prefix, suffix = get_comments t in\n    prefix | suffix\n  let c_prefix (t:t) =\n    let comment, _ = get_comments t in\n    let command, _ = get_commands t in\n    comment . command\n  let c_suffix (t:t) =\n    let _, comment = get_comments t in\n    let _, command = get_commands t in\n    command . comment\n  let no_comments (t:t) = not_containing (comment_signs t)\n  let commands (t:t) = c_prefix t . no_comments t . c_suffix t\n  let data (t:t) = not_containing (commands t)\n  let c_exact (t:t) (value:string):string =\n    c_prefix t . value . c_suffix t\n  let c_exact_uncuttable (t:t) (value:string):string =\n    c_exact t (uncuttable_prefix . value . uncuttable_suffix)\n  let c_other (t:t) (value:string):regexp =\n    c_prefix t . diff (get_values t) value . c_suffix t\n  let c_all (t:t):regexp = c_prefix t . get_values t . c_suffix t\n  let c_stop (t:t):string = c_exact t \"\"\n  let c_stop_uncuttable (t:t):string = c_exact_uncuttable t \"\"\nend\n\n(*@*)\n(* ---------------------------------------------------------------- *)\n(*                            main lens                             *)\n\nlet main_lens (prefs:File_pref.t) (value:string) :(l:lens where is_lens l) =\n  (* read prefs *)\n  let view_prefix = File_pref.get_view_prefix prefs in\n  let data = File_pref.data prefs in\n  let c_exact = File_pref.c_exact prefs in\n  let c_exact_uncuttable = File_pref.c_exact_uncuttable prefs in\n  let c_other = File_pref.c_other prefs in\n  let c_all = File_pref.c_all prefs in\n  let c_stop = File_pref.c_stop prefs in\n  let c_stop_uncuttable = File_pref.c_stop_uncuttable prefs in\n  (* we check that the informations are useable *)\n(*   let _:(string where *)\n(*            is_empty (diff *)\n(*                        (view_prefix? . uncuttable_prefix? . values? . uncuttable_suffix?) *)\n(*                        no_comments)) = *)\n(*     mk_error \"Your values and/or view_prefix contain comments.\" *)\n(*   in *)\n(*   let _:(string where *)\n(*            not (matches values \"\")) = *)\n(*     mk_error \"Your values should NOT contain the empty string.\" *)\n(*   in *)\n(*   let _:(string where *)\n(*            matches values? value) = *)\n(*     mk_error (\"The value \" . show_s value . \" does not match \" . show{regexp} values? . \".\") *)\n(*   in *)\n  let factor (format:bool) (value:string) =\n    match format with\n    | true ->\n        c_stop . data\n        . (\n          match value = \"\" with\n          | true -> copy (c_all . data)*\n          | false ->\n              ( (c_other value . data)*\n              | ambiguous_lens_partition_one (c_exact value . data) (c_other value . data)\n              )\n          :lens)\n    | false -> (\n        let data_tag = positional \"data\" in\n        let siblings_tag = positional \"siblings\" in\n        let ccsd = nokey c_stop . key data in\n        let dcsd = del c_stop . del data in\n        let ccsud = nokey (c_stop <=> c_stop_uncuttable) . key data in\n        let ccevd = nokey (c_exact value) . key data in\n        let ccevud = nokey (c_exact value <=> c_exact_uncuttable value) . key data in\n        let siblings = del (c_other value . data)+ in\n        match value = \"\" with\n        | true -> ( ccsd | ccsud . siblings )\n        | false ->\n            ( ( <data_tag: ccsd > | <data_tag: dcsd > . ccevd )\n            | ( <data_tag: ccsud > | <data_tag: dcsd > . ccevud) . siblings\n            )\n        :lens\n      )\n    :lens\n  in\n  (* to check the value for put *)\n  let value_check (value:string) = ins (c_exact (view_prefix . value)) in\n  let main (format:bool) =\n    data\n    . (match format with\n       | true -> (factor true value)*\n       | false -> value_check value . <diffy true \"factor\": factor false value >*\n       :lens\n      )\n  in\n  main true ; align ( main false )\n\n(*@*)\n(* ---------------------------------------------------------------- *)\n(*                          main function                           *)\n\nlet okfailwith 'a =\n  (), Exception.raise{'a}, Exception.try{'a}, Exception.failwith{'a}, Exception.ok{'a}\n\nlet bind = Exception.bind\nlet bind_pi = bind{File_pref.t}{int}\nlet bind_pp = bind{File_pref.t}{File_pref.t}\nlet bind_si = bind{string}{int}\nlet bind_sOi = bind{string option}{int}\nlet bind_sOs = bind{string option}{string}\nlet bind_ss = bind{string}{string}\nlet bind_ui = bind{unit}{int}\n\nlet okfailwith_i  = okfailwith{int}\nlet okfailwith_p  = okfailwith{File_pref.t}\nlet okfailwith_s  = okfailwith{string}\nlet okfailwith_sO = okfailwith{string option}\nlet okfailwith_u  = okfailwith{unit}\n\n(* definitions *)\nlet list_to_option 'a (xs:'a List.t) =\n  let _, failwith, ok = okfailwith{'a option} in\n  match xs with\n  | [] -> ok None{'a}\n  | x::[] -> ok (Some{'a} x)\n  | _ -> failwith \"list_to_option\"\n\nlet list_to_option_s = list_to_option{string}\n\n(* command line arguments *)\nlet help_pref = Prefs.create_bool \"-help\" false \"print this help\"\nlet _ = Prefs.alias_bool help_pref \"h\"\n\nlet init_pref = Prefs.create_bool \"-init\" false \"create the source file\"\nlet _ = Prefs.alias_bool init_pref \"i\"\n\n(* TODO: might consider writing an Arg module *)\nlet create_string_pref (name:string) (default:string) (doc:string) =\n  let pref = Prefs.create_string_list (\"-\" . name) (doc . \"(default: \" . show_s default . \")\") in\n  let read () =\n    let value = Prefs.read_string_list pref in\n    bind_sOs\n      (let _, try, failwith, _ = okfailwith_sO in\n       try (list_to_option_s value) $ fun () ->\n         failwith (\"You can't define more than one \" . name . \".\"))\n      (fun (value:string option) ->\n         let _, ok = okfailwith_s in\n         ok (if_none_s default value))\n  in\n  pref, read\n\nlet extension_pref, extension_read = create_string_pref \"extension\" \"conflin\" \"extension of source\"\nlet _ = Prefs.alias_string_list extension_pref \"e\"\n\nlet value_pref, value_read = create_string_pref \"value\" \"\" \"value of the view\"\nlet _ = Prefs.alias_string_list value_pref \"v\"\n\nlet output_pref = Prefs.create_string_list \"-output\" \"output file (default: <file> with or without <extension>)\"\nlet _ = Prefs.alias_string_list output_pref \"o\"\n\nlet default_pref = Prefs.create_string_list \"-default\" \"mandatory: shell, c, cpp or ocaml\"\nlet _ = Prefs.alias_string_list default_pref \"d\"\n\nlet command_prefix_pref = Prefs.create_string_list \"-command-prefix\" \"identify a command from a comment\"\nlet _ = Prefs.alias_string_list command_prefix_pref \"ap\"\nlet command_suffix_pref = Prefs.create_string_list \"-command-suffix\" \"identify a command from a comment\"\nlet _ = Prefs.alias_string_list command_suffix_pref \"as\"\n\nlet rest_pref = Prefs.extern_rest ()\n\n(* TODO: write a --documentation *)\n\n(* usage message *)\nlet usage:string = \"Usage: \" . Prefs.get_prog_name () . \" --default <file_type> <file>\"\n\n(*@*)\n(* main code *)\nlet main () =\n  (* shortcuts *)\n  let print_usage (code:int) () =\n    let _ = Prefs.print_usage usage in\n    code\n  in\n  let safe_read (file:string) =\n    let _, failwith, ok = okfailwith_s in\n    match file_exists file with\n    | true -> ok (read file)\n    | false -> failwith (\"File \" . show_s file . \" does not exist.\")\n  in\n  let check_string_with (r:regexp) (s:string) (m:string) =\n    let _, failwith, ok = okfailwith_s in\n    match matches r s with\n    | true -> ok s\n    | false -> failwith m\n  in\n  let file_error (filename:string) (head:string) (advices:string List.t) =\n    let tail =\n      match advices with\n      | [] -> \"\"\n      | _ ->\n          List.fold_left{string}{string}\n            (fun (acc:string) (line:string) ->\n               acc . \"\\n* \" . line)\n            \"\\n\\nYou might want to check these:\"\n            advices\n    in\n    \"File \" . show_s filename . \" \" . head . \".\" . tail\n  in\n  (* parsing the commandline *)\n  let init = Prefs.read_bool init_pref in\n  let value = Prefs.read_string_list value_pref in\n  let extension =\n    bind_ss (extension_read ()) $ fun (extension:string) ->\n    let _, ok = okfailwith_s in\n    ok (\".\" . extension)\n  in\n  let help =\n    let _, fail, _, _, ok = okfailwith_u in\n    match Prefs.read_bool help_pref with\n    | true -> fail (print_usage 0)\n    | false -> ok ()\n  in\n  let output =\n    let _, failwith, ok = okfailwith_sO in\n    match Prefs.read_string_list output_pref with\n    | [] -> ok None{string}\n    | output::[] -> ok (Some{string} output)\n    | _ -> failwith \"You can define at most one output file.\"\n  in\n  let default =\n    let _, failwith, ok = okfailwith_p in\n    match Prefs.read_string_list default_pref with\n    | \"shell\"::[] -> ok File_pref.shell_like\n    | \"c\"::[]     -> ok File_pref.c_like\n    | \"cpp\"::[]   -> ok File_pref.cpp_like\n    | \"ocaml\"::[] -> ok File_pref.ocaml_like\n    | pref::[] -> failwith (show_s pref . \" is not a valid file preference.\")\n    | _ -> failwith \"You need to define exactly one file preference.\"\n  in\n  let command_prefix (default:File_pref.t) =\n    let _, failwith, ok = okfailwith_p in\n    match Prefs.read_string_list command_prefix_pref with\n    | [] -> ok default\n    | pref::[] -> ok (File_pref.set_command_prefix pref default)\n    | _ -> failwith \"You can define at most one command-prefix preference.\"\n  in\n  let command_suffix (default:File_pref.t) =\n    let _, failwith, ok = okfailwith_p in\n    match Prefs.read_string_list command_suffix_pref with\n    | [] -> ok default\n    | pref::[] -> ok (File_pref.set_command_suffix pref default)\n    | _ -> failwith \"You can define at most one command-suffix preference.\"\n  in\n  let action (prefs:File_pref.t) =\n    let _, fail, _, failwith, ok = okfailwith_i in\n    match Prefs.read_string_list rest_pref with\n    | [] -> fail (print_usage 1)\n    | filename::[] -> (\n        match init with\n        | true -> (  (* create the source file *)\n            (* TODO: check if no .conflin boom is already there *)\n            bind_ui  (* check value is not defined *)\n              (let _, failwith, ok = okfailwith_u in\n               match value with\n               | [] -> ok ()\n               | _ -> failwith \"You can't give a value with init.\")\n              $ fun () ->\n            let c_stop = File_pref.c_stop in\n            let data = File_pref.data prefs in\n            let file =  (* read and check file *)\n              bind_ss (safe_read filename) $ fun (file:string) ->\n              check_string_with data file\n                (file_error filename \"contains commands-like comments\"\n                   #{string}[])\n            in\n            bind_si extension $ fun (extension:string) ->\n            bind_si file $ fun (file:string) ->\n            bind_sOi output $ fun (output:string option) ->\n            ok (\n              let output = if_none_s (filename . extension) output in\n              write output (c_stop prefs . file)))\n        | false -> (  (* get or put *)\n            bind_si extension $ fun (extension:string) ->\n            bind_si (value_read ()) $ fun (value:string) ->\n            let mlpv = main_lens prefs value in\n            match String.end_with filename extension with\n            | true -> (  (* get *)\n                let sfile = filename in\n                let vfile = String.rdrop (length extension) filename in\n                let source =\n                  bind_ss (safe_read sfile) $ fun (source:string) ->\n                  check_string_with (stype mlpv) source\n                    (file_error sfile \"is not a valid source\"\n                       #{string}[\n                         \"The file_type is the right one\";\n                         \"The file does not contain mispelled commands\"])\n                in\n                bind_si source $ fun (source:string) ->\n                bind_sOi output $ fun (output:string option) ->\n                ok (\n                  let output = if_none_s vfile output in\n                  write output (get mlpv source)))\n            | false -> (  (* put *)\n                let vfile = filename in\n                let sfile = filename . extension in\n                let view =\n                  bind_ss (safe_read vfile) $ fun (view:string) ->\n                  check_string_with (vtype mlpv) view\n                    (file_error vfile \"is not a valid view\"\n                       #{string}[\n                         \"The expanding value \" . show_s value . \" is the one after the view prefix\";\n                         \"The file_type is the right one\"])\n                in\n                let source =\n                  bind_ss (safe_read sfile) $ fun (source:string) ->\n                  check_string_with (stype mlpv) source\n                    (file_error sfile \"is not a valid source\"\n                       #{string}[\n                         \"The file_type is the right one\";\n                         \"The extension \" . show_s (String.drop 1 extension) . \" is the right one\"])\n                in\n                bind_si view $ fun (view:string) ->\n                bind_si source $ fun (source:string) ->\n                bind_sOi output $ fun (output:string option) ->\n                ok (\n                  let output = if_none_s sfile output in\n                  write output (put mlpv view source)))\n          )\n      )\n    | _ -> failwith \"You can do an action on at most one file.\"\n  in\n  let prefs = bind_pp (bind_pp default command_prefix) command_suffix in\n  let result = bind_ui help $ fun () -> bind_pi prefs action in\n  Exception.convert_main result\n\n(*@*)\n(* ---------------------------------------------------------------- *)\n(*                            unit tests                            *)\n\n(* --- Debug --- *)\n\nlet mld = main_lens File_pref.debug_like\n\nlet mldv = mld \"\"\ntest get mldv (  \"(\" .\")d0(a)a0(b)b0(\" .\")d1(b)b1()d2\")\n            = (\"()(\".\"!)d0\"       .\"(\".\"!)d1\"  .\"()d2\")\ntest create mldv (\"()()d0()d1()d2\")\n               = (  \"()d0()d1()d2\")\ntest put mldv (\"()\" .\"(\".\"!)D1\"  .\"(\".\"!)D2\"     ) (* ()    (!)D1(!)D2 *)\n              (  \"()d0(\" .\")d1(a)a1(\" .\")d2(a)a2\") (* ()()d0(!)d1(!)d2 *)\n            = (      \"(\" .\")D1(a)a1(\" .\")D2(a)a2\")\ntest put mldv (\"()()D0(\".\"!)D1\"  .\"(\".\"!)D2\"     ) (* ()()D0(!)D1(!)D2 *)\n              (      \"(\" .\")d1(a)a1(\" .\")d2(a)a2\") (* ()    (!)d1(!)d2 *)\n            = (  \"()D0(\" .\")D1(a)a1(\" .\")D2(a)a2\")\ntest put mldv (\"()(\".\"!)D0\"  .\"()D1(\".\"!)D2\"     ) (* ()(!)D0()D1(!)D2 *)\n              (  \"(\" .\")d0(a)a0\" .\"(\" .\")d2(a)a2\") (* ()(!)d0    (!)d2 *)\n            = (  \"(\" .\")D0(a)a0()D1(\" .\")D2(a)a2\")\ntest put mldv (\"()(\".\"!)D0\"      .\"(\".\"!)D2\"     ) (* ()(!)D0    (!)D2 *)\n              (  \"(\" .\")d0(a)a0()d1(\" .\")d2(a)a2\") (* ()(!)d0()d1(!)d2 *)\n            = (  \"(\" .\")D0(a)a0\" .\"(\" .\")D2(a)a2\")\ntest put mldv (\"()(\".\"!)D0\"      .\"(\".\"!)D2\"  .\"()D3()D4\") (* ()(!)D0    (!)D2()D3()D4 *)\n              (  \"(\" .\")d0(a)a0()d1(\" .\")d2(a)a2\" .\"()d4\") (* ()(!)d0()d1(!)d2    ()d4 *)\n            = (  \"(\" .\")D0(a)a0\" .\"(\" .\")D2(a)a2()D3()D4\")\n(* test put mldv (\"()(\".\"!)\"      .\"(\".\"!)\"     ) (\\* ()(!)    (!) *\\) *)\n(*               (  \"(\" .\")(a)a0()d1(\" .\")(a)a2\") (\\* ()(!)()d1(!) *\\) *)\n(*             = (  \"(\" .\")(a)a0\" .\"(\" .\")(a)a2\") *)\n(* test put mldv (\"()(\".\"!)\"  .\"()D1(\".\"!)\"     ) (\\* ()(!)()D1(!) *\\) *)\n(*               (  \"(\" .\")(a)a0\" .\"(\" .\")(a)a2\") (\\* ()(!)    (!) *\\) *)\n(*             = (  \"(\" .\")(a)a0()D1(\" .\")(a)a2\") *)\ntest put mldv (\"()\" .\"(\".\"!)D1\"  .\"(\".\"!)D2\"  .\"()D3\") (* ()    (!)D1(!)D2()D3 *)\n              (  \"()d0(\" .\")d1(a)a1(\" .\")d2(a)a2\"    ) (* ()()d0(!)d1(!)d2     *)\n            = (      \"(\" .\")D1(a)a1(\" .\")D2(a)a2()D3\")\ntest put mldv (\"()\" .\"(\".\"!)D1\"  .\"()D2(\".\"!)D3\"  .\"()D4\") (* ()    (!)D1()D2(!)D3()D4 *)\n              (  \"()d0(\" .\")d1(a)a1(\"     .\")d3(a)a3\"    ) (* ()()d0(!)d1    (!)d3     *)\n            = (      \"(\" .\")D1(a)a1()D2(\" .\")D3(a)a3()D4\")\ntest put mldv (\"()\" .\"(\".\"!)D1\"      .\"(\".\"!)D3\"  .\"()D4\") (* ()    (!)D1    (!)D3()D4 *)\n              (  \"()d0(\" .\")d1(a)a1()d2(\" .\")d3(a)a3\"    ) (* ()()d0(!)d1()d2(!)d3     *)\n            = (      \"(\" .\")D1(a)a1\" .\"(\" .\")D3(a)a3()D4\")\n\nlet mldv = mld \"a\"\ntest get mldv (   \"()d0(a\" .\")a0(b)b0(\" .\")d1(b)b1()d2\")\n            = (\"(a)\" .\"(a\".\"!)a0\"  .\"(\".\"!)d1\"  .\"()d2\")\ntest create mldv (\"(a)\".\"(a)a0()d1()d2\"  .\"(a)a3\")\n               = (    \"()(a)a0()d1()d2\".\"()(a)a3\")\ntest put mldv (\"(a)\" .\"(a)A0()D1()D2\") (* (a)    (a)A0()D1()D2 *)\n              (   \"()d0\"  .\"()d1()d2\") (* (a)()d0     ()d1()d2 *)\n            = (   \"()d0(a)A0()D1()D2\")\ntest put mldv (\"(a)()D0\" .\"(a)A1()D2\") (* (a)()D0    (a)A1()D2 *)\n              (   \"()d0()d1\"  .\"()d2\") (* (a)()d0()d1     ()d2 *)\n            = (   \"()D0()d1(a)A1()D2\")\ntest put mldv (\"(a)()D0\"  .\"(a)A1()D2\") (* (a)()D0  (a)A1()D2 *)\n              (   \"()d0()\"     .\"()d2\") (* (a)()d0()     ()d2 *)\n            = (   \"()D0()\".\"(a)A1()D2\")\ntest put mldv (\"(a)(\".\"!)D0\"    .\"(a)A1(\".\"!)D2\"     ) (* (a)(!)D0  (a)A1(!)D2 *)\n              (   \"(\" .\")d0(b)b0()\"  .\"(\" .\")d2(b)b2\") (* (a)(!)d0()     (!)d2 *)\n            = (   \"(\" .\")D0(b)b0()(a)A1(\" .\")D2(b)b2\")\ntest put mldv (\"(a)\" .\"(a\".\"!)A0\"  .\"()D1()D2\") (* (a)     (a!)A0()D1()D2 *)\n              (   \"()d0\"      .\"(b)b0()d1()d2\") (* (a)(!)d0      ()d1()d2 *)\n            = (   \"()d0(a\" .\")A0(b)b0()D1()D2\")\ntest put mldv (\"(a)()D0\" .\"(a\".\"!)A1\"  .\"()D2\") (* (a)()D0     (a!)A1()D2 *)\n              (   \"()d0()d1\"      .\"(b)b1()d2\") (* (a)()d0(!)d1      ()d2 *)\n            = (   \"()D0()d1(a\" .\")A1(b)b1()D2\")\ntest put mldv (\"(a)(\".\"!)D0\"  .\"()D1(\".\"!)D2\"     ) (* (a)(!)D0()D1(!)D2 *)\n              (   \"(\" .\")d0(b)b0\" .\"(\" .\")d2(b)b2\") (* (a)(!)d0    (!)d2 *)\n            = (   \"(\" .\")D0(b)b0()D1(\" .\")D2(b)b2\")\ntest put mldv (\"(a)(\".\"!)D0\"  .\"()D1\".\"()D2\".\"()D3(\".\"!)D4\"     ) (* (a)(!)D0()D1()D2()D3(!)D4 *)\n              (   \"(\" .\")d0(b)b0()d1\"  .\"d2\"  .\"d3(\" .\")d4(b)b4\") (* (a)(!)d0()d1  d2  d3(!)d4 *)\n            = (   \"(\" .\")D0(b)b0()D1\".\"()D2\".\"()D3(\" .\")D4(b)b4\")\ntest put mldv (\"(a)\" .\"(a)A0\" .\"()D2\") (* (a)A0    ()D2 *)\n              (   \"()d0\"  .\"()d1()d2\") (* (a)a0()d1()d2 *)\n            = (   \"()d0(a)A0\" .\"()D2\")\ntest put mldv (\"(a)\" .\"(a)A0\"     .\"(a)A2\") (* (a)A0    (a)A2 *)\n              (   \"()d0\"  .\"()d1()d2(a)a2\") (* (a)a0()d1(a)a2 *)\n            = (   \"()d0(a)A0\" .\"()d2(a)A2\")\ntest put mldv (\"(a)\" .\"(a\".\"!)A0\"      .\"()D2\") (*      (a!)A0    ()D2 *)\n              (   \"()d0\"      .\"(b)b0()d1()d2\") (* (!)d0      ()d1()d2 *)\n            = (   \"()d0(a\" .\")A0(b)b0\" .\"()D2\")\ntest put mldv (\"(a)\" .\"(a)A0\" .\"(a\".\"!)A1\"          .\"(a)A3\") (* (a)a0     (a!)A1    (a)A3 *)\n              (   \"()d0(a)a0()d1\"      .\"(b)b1()d2()d3(a)a3\") (* (a)a0(!)d1      ()d2(a)a3 *)\n            = (   \"()d0(a)A0()d1(a\" .\")A1(b)b1\" .\"()d3(a)A3\")\n(* test put mldv (\"(a)\"      .\"(a)A1()D2\") (\\*         (a)A1()d2 *\\) *)\n(*               (    \"()d0()d1\"  .\"()d2\") (\\* ()d0()d1     ()d2 *\\) *)\n(*             = (        \"()d1(a)A1()D2\") *)\n(* test put mldv (\"(a)()D0\"     .\"(a)A2()D3\") (\\* ()D0        (a)A2()D3 *\\) *)\n(*               (   \"()d0()d1()d2\"  .\"()d3\") (\\* ()d0()d1()d2     ()d3 *\\) *)\n(*             = (   \"()D0\" .\"()d2(a)A2()D3\") *)\ntest put mldv (\"(a)()D0\" .\"(a)A1\" .\"()D3\") (* ()D0    (a)A1    ()D3 *)\n              (   \"()d0()d1\"  .\"()d2()d3\") (* ()d0()d1     ()d2()d3 *)\n            = (   \"()D0()d1(a)A1\" .\"()D3\")\n\n(*@*)\n(* ---------------------------------------------------------------- *)\n(*                          documentation                           *)\n\n#{@}\n\n\\section{Description}\n\nThis tool allows you to easily manage multiple versions of a file.\nFor example, if you have a file which varies a little bit depending on\nsome parameter, you do not need to have several files -- one for each\nvalue of the parameter.  That would mean that a change to a part\nshared by several versions, needs to be done for each version.  With\nthis tool you only need to change it once.\n\nThe main possibilities offered by this tool are:\n\\begin{itemize}\n\\item Retrieve an existing version\n\\item Update the source file with the changes done to one version\n\\item Create a new version forking the default\n\\item Create the source file from a default version\n\\end{itemize}\n\nThe source file will be the source file for Boomerang, and the\nversions will be view files.\n\n\\section{Quick usage}\n\n\\subsection{Installation}\n\nCreate a symbolic link named @conflin@ pointing to the @boomerang@\nbinary.  If you can't create a symbolic link, copy-paste the binary\nand rename it to @conflin@.\n\n\\subsection{Create the source file}\n\nIf you want to start to manage versions for the file @file.conf@,\nwhere the comments are shell-like -- start with a hash and end with a\nnewline.\n\n\\begin{progeg}\n% conflin --default shell --init file.conf\n\\end{progeg}\n\nThis will first check if @file.conf@ does not contain comments that\nmight be interpreted as commands and create a file named\n@file.conf.conflin@ being @file.conf@ preceded by a @#@@@ line.  Note:\nIf you need the first line to be something else, you can move the\n@#@@@ line down, but every thing above this line will be present in\nevery versions and you won't be able to specialize it.  Typically this\nis useful for the @#!@ line for scripts.\n\n\\subsection{Create a new version}\n\nNow that your file is managed, you may wish to specialize a part of\nit.  So you may choose a name for this new version.  It has to be an\nidentifier.  And you call @conflin@ with this name and the source\nfile (the one ending with @.conflin@).\n\n\\begin{progeg}\n% conflin --default shell --value myVersion file.conf.conflin\n\\end{progeg}\n\nYour file @file.conf@ is now a view of the source file, ie. a\nversion.  You may see it by looking at the beginning of your view.\nYou will see @#@@@@view: myVersion@.\n\n\\subsection{Edit a version}\n\nNow that we have our new version view, we want to edit it.  As\nBoomerang will have to understand what we want, we will write some\nadditional information to explain him.\n\n\\subsubsection{The view structure}\n\nThe view must respect the following syntax:\n\\begin{progeg}\nVIEWLINE ::= \"#@@@@view: \" view \"\\ensuremath{\\backslash}n\"\nCOMMAND ::= \"#@@@@\" view? \"!\"? \"\\ensuremath{\\backslash}n\"\nFILE ::= data VIEWLINE (COMMAND data)*\n\\end{progeg}\nwhere @view@ is the current version name, and @data@ is anything\nnot containing lines beginning with @#@@@.\n\n@#@@@@\\n@ lines are the default value for this section.  @#@@@@view\\n@\nlines are specialized version for the section.  When a @!@ is present,\nit means the section is uncuttable.  We'll see the meaning later.\n\n\\subsubsection{How to edit}\n\nYou may:\n\\begin{itemize}\n\\item edit every @data@ field\n\\item cut with @#@@@@\\n@ a @data@ preceded by a @#@@@@\\n@ command\n\\item specialize a @data@ not already specialized\n\\end{itemize}\n\nThe first edit is straightforward, you just edit the file where you\nwant, as long as it's in a @data@ field.  Here is an example for the\nsecond one.\n\\begin{progeg}\n  #@@@@view: \n  #@@@@\n  line1\n  line2\n\\end{progeg}\nto:\n\\begin{progeg}\n  #@@@@view: \n  #@@@@\n  line1\n  #@@@@\n  line2\n\\end{progeg}\n\nWe may specialize the second @data@ field.\n\n\\begin{progeg}\n  #@@@@view: \n  #@@@@\n  line1\n  #@@@@myVersion\n  myline2\n\\end{progeg}\n\n\\subsubsection{Important warnings}\n\nSome changes may not be done together before the source file is\nupdated, and you'll have to do a first bunch of changes, an update,\nand then the other changes.  This is because Boomerang has to be aware\nof what you want to do.  And you tell him so by pushing edited views.\n\nHere is a list of operations that may be done together before an\nupdate is necessary:\n\\begin{itemize}\n\\item editing any @data@ (even cutted ones)\n\\item specializing a @data@ which was already there (non edited, non\n  cutted)\n\\item cut any cuttable @data@ (even edited ones)\n\\end{itemize}\n\nOther warnings:\n\\begin{itemize}\n\\item You must not edit the very first part of the view, where the\n  name of the view is present.  If you want to change to another view,\n  first push back the possible edits, then get the other view.\n\\item You must never touch the @uncuttable@ symbol.  It's a hint\n  given by Boomerang for you to know the data is not cuttable.  Be\n  also aware that a specialized section is also uncuttable.\n\\item Do not use @#@@@@@ for your own commentary as they will be\n  interpreted as commands.\n\\end{itemize}\n\nAdvices:\n\\begin{itemize}\n\\item When specializing a @data@, first cut the @data@ so that the\n  remaining @data@ you will specialize is atomic for the semantic of\n  your file.  Because once you specialized a @data@, you won't be\n  able to cut it later.\n\\item You can read the @uncuttable@ symbol as: this section contains\n  hidden information from other versions\n\\end{itemize}\n\n\\subsection{Update the source file}\n\nYou may only push back an existing view with it's own value.\n\n\\begin{progeg}\n% conflin --default shell --value myVersion file.conf\n\\end{progeg}\n\n\\subsection{Retrieve another view}\n\n\\begin{progeg}\n% conflin --default shell --value another file.conf.conflin\n\\end{progeg}\n\n\\section{For curious people}\n\nYou may take a look at the source file to see how the informations are\nsaved.\n\n#{#}\n\n(*@*)\n(* ---------------------------------------------------------------- *)\n(*                        bigger unit tests                         *)\n\nlet mls = main_lens File_pref.shell_like\n\nlet source =\n<<\n  #@\n  # Define the specific parts of PATH for each machine\n  #@\n  # This is the default\n  SPATH=\"\"\n  #@upenn\n  # If we are in UPenn\n  SPATH=\"/home/harmony/bin:/home/harmony/boomerang/bin\"\n  #@\n  \n  # This is the common part of PATH\n  PATH=\"/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin\"\n  # We concatenate both parts\n  PATH=\"$PATH:$SPATH\"\n  \n  # We finally export the PATH\n  export PATH\n>>\n\ntest get (mls \"\") source =\n<<\n  #@view: \n  #@\n  # Define the specific parts of PATH for each machine\n  #@!\n  # This is the default\n  SPATH=\"\"\n  #@\n  \n  # This is the common part of PATH\n  PATH=\"/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin\"\n  # We concatenate both parts\n  PATH=\"$PATH:$SPATH\"\n  \n  # We finally export the PATH\n  export PATH\n>>\n\ntest get (mls \"upenn\") source =\n<<\n  #@view: upenn\n  #@\n  # Define the specific parts of PATH for each machine\n  #@upenn\n  # If we are in UPenn\n  SPATH=\"/home/harmony/bin:/home/harmony/boomerang/bin\"\n  #@\n  \n  # This is the common part of PATH\n  PATH=\"/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin\"\n  # We concatenate both parts\n  PATH=\"$PATH:$SPATH\"\n  \n  # We finally export the PATH\n  export PATH\n>>\n\ntest get (mls \"X\") source =\n<<\n  #@view: X\n  #@\n  # Define the specific parts of PATH for each machine\n  #@!\n  # This is the default\n  SPATH=\"\"\n  #@\n  \n  # This is the common part of PATH\n  PATH=\"/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin\"\n  # We concatenate both parts\n  PATH=\"$PATH:$SPATH\"\n  \n  # We finally export the PATH\n  export PATH\n>>\n\ntest put (mls \"X\")\n<<\n  #@view: X\n  #@\n  # Define the specific parts of PATH for each machine\n  #@X!\n  # For Polytechnique\n  SPATH=\"$HOME/bin\"\n  #@\n  \n  # This is the common part of PATH\n  PATH=\"/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin\"\n  # We concatenate both parts\n  PATH=\"$PATH:$SPATH\"\n  \n  # We finally export the PATH\n  export PATH\n>> source =\n<<\n  #@\n  # Define the specific parts of PATH for each machine\n  #@\n  # This is the default\n  SPATH=\"\"\n  #@X\n  # For Polytechnique\n  SPATH=\"$HOME/bin\"\n  #@upenn\n  # If we are in UPenn\n  SPATH=\"/home/harmony/bin:/home/harmony/boomerang/bin\"\n  #@\n  \n  # This is the common part of PATH\n  PATH=\"/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin\"\n  # We concatenate both parts\n  PATH=\"$PATH:$SPATH\"\n  \n  # We finally export the PATH\n  export PATH\n>>\n\n(*\n * Local Variables:\n * mode: tuareg\n * End:\n *)\n"
let _ = Hashtbl.add items "test_qmark" "module Test_qmark =\n\nlet l : (lens in ? <-> ANY) = copy ANY\n\nlet mk_l (R:regexp) : (lens in R <-> ?) = del R\n\nlet l' : (lens in ANY <-> EPSILON) = mk_l ANY\n\nlet l : (lens in ANY <=> ?) = copy ANY\n\nlet mk_l (R:regexp) : (lens in R <=> ?) = copy R\n\nlet l' : (lens in ANY <=> ANY) = mk_l ANY\n"
let _ = Hashtbl.add items "demo" "module Demo = \n(* Some useful regular expressions *)\nlet N : regexp= [a-zA-Z ]+\nlet E : regexp= [a-zA-Z@.]*\n\n(* ----------------------------------------------------------------- *)\n(* Basic lenses *)\n\n(* A basic lens that extracts just the name from a Name/Email string *)\nlet del_email : lens = \n  del \"Name:\" . \n  copy N . \n  del (\", Email:\" . E) \n\n(* Extract ALL the names from a LIST of Name/Emails *)\nlet del_emails = \"\" | del_email . (\"\\n\" . del_email)* \n\n(* Test the GET direction *)\ntest del_emails.get\n  (* GETting from... *)\n    \"Name:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n    |Name:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n= \n  (* ... yields: *)\n  \"Benjamin Pierce\n  |Steve Zdancewic\"\n\n(* Test the PUT direction (adding names at the end) *)\ntest del_emails.put\n   (* Putting back... *)\n     \"Benjamin C Pierce\n     |Steve Zdancewic\n     |Mike Hicks\"\ninto\n     \"Name:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n     |Name:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n= \n   (* ...yields: *)\n     \"Name:Benjamin C Pierce, Email:bcpierce@cis.upenn.edu\n     |Name:Steve Zdancewic, Email:stevez@cis.upenn.edu\n     |Name:Mike Hicks, Email:\"\n\n(* [break for semantics...] *)\n\n(* ----------------------------------------------------------------- *)\n(* A fly in the ointment... *)\n\n(* In general, PUT restores emails by position :-/ *)\ntest del_emails.put\n   (* Putting back... *)\n     \"Steve Zdancewic\n     |Benjamin Pierce\n     |Mike Hicks\"\ninto\n     \"Name:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n     |Name:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n = \n   (* ...yields: *)\n     \"Name:Steve Zdancewic, Email:bcpierce@cis.upenn.edu\n     |Name:Benjamin Pierce, Email:stevez@cis.upenn.edu\n     |Name:Mike Hicks, Email:\"\n\n(* ----------------------------------------------------------------- *)\n(* Dictionary lenses *)\n\n(* A better version where names act like keys to match up deleted emails. *)\nlet keyed_del_email = \n  del \"Name:\" . \n  key N . \n  del (\", Email:\" . E) \n\nlet keyed_del_emails = \"\"\n    | <dictionary \"\":keyed_del_email> . (\"\\n\" . <dictionary \"\":keyed_del_email>)*\n\n(* Getting behaves the same as above. *)\ntest keyed_del_emails.get\n  (* Getting from... *)\n    \"Name:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n    |Name:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n= \n  (* ... yields: *)\n    \"Benjamin Pierce\n    |Steve Zdancewic\"\n\n(* Putback restores emails using the name as a key *)\ntest keyed_del_emails.put\n   (* Putting back... *)\n     \"Steve Zdancewic\n     |Benjamin Pierce\n     |Mike Hicks\"\ninto\n     \"Name:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n     |Name:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n = \n   (* ...yields: *)\n     \"Name:Steve Zdancewic, Email:stevez@cis.upenn.edu\n     |Name:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n     |Name:Mike Hicks, Email:\"\n(* ----------------------------------------------------------------- *)\n\n(* Unions present a special challenge: common projected data needs to\n   flow across the union. This example shows a fragment of a lens for\n   processing bibiographic data where each entry either represents a\n   single authors of a list of co-authors with email addresses. *)\n\nlet chunk = \n  key N . \n  del (\", Email:\" . E) \n\nlet author_coauthor =\n       copy \"\"\n     | copy \"Author:\" . <dictionary \"\":chunk>\n     | copy \"CoAuthor:\" . <dictionary \"\":chunk> . (copy \"\\nCoAuthor:\" . <dictionary \"\":chunk>)*\n\n(* GET simply projects emails *)\ntest author_coauthor.get\n   (* Getting from... *)\n     \"CoAuthor:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n     |CoAuthor:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n  = \n    (* ...yields: *)\n     \"CoAuthor:Benjamin Pierce\n     |CoAuthor:Steve Zdancewic\"\n\n(* Putting back restores email for matching author/co-author *)\n(* First, let's try two co-authors put back into a single author *)\ntest author_coauthor.put\n  (* Putting back... *)\n    \"CoAuthor:Steve Zdancewic\n    |CoAuthor:Benjamin Pierce\"\ninto\n    \"Author:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\"\n =\n  (* ...yields: *)\n    \"CoAuthor:Steve Zdancewic, Email:\n    |CoAuthor:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\"\n\n(* Second, a single author put back into a list of co-authors *)    \ntest author_coauthor.put\n  (* Putting back... *)\n    \"Author:Steve Zdancewic\"\ninto\n    \"CoAuthor:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n    |CoAuthor:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n = \n  (* ...yields: *)\n    \"Author:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n\ntest (author_coauthor . (\";\\n\" . author_coauthor)* ).put\n  (* Putting back... *)\n    \"Author:Steve Zdancewic;\n    |Author:Benjamin Pierce\"\ninto\n    \"CoAuthor:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\n    |CoAuthor:Steve Zdancewic, Email:stevez@cis.upenn.edu\"\n  = \n   (* yields: *)\n     \"Author:Steve Zdancewic, Email:stevez@cis.upenn.edu;\n     |Author:Benjamin Pierce, Email:bcpierce@cis.upenn.edu\"\n\n\n\n(* (\\*** Q-lenses ***\\) *)\n(* let xml_space (space:string) = qconst \"\" \" \"* space \"\" *)\n\n(* let xml_tag (spaces:string) (name:string) (content:lens) =  *)\n(*   xml_space spaces .ins (\"<\" . name . \">\") . content . ins (\"</\" .name.\">\") . ins \"\\n\" *)\n\n(* let chunk = xml_tag \"  \" \"leaf\" (key [a-z]+ . del [0-9]* ) *)\n\n(* let ql =  *)\n(*   xml_space \"\" . ins \"<root>\".  *)\n(*   <chunk>* .  *)\n(*   xml_space \"\" . ins \"</root>\" *)\n\n(* test ql.get  *)\n(* << *)\n(* foo42 *)\n(* bar51 *)\n(* >> =  *)\n(* << *)\n(* <root> *)\n(*   <leaf>foo</leaf> *)\n(*   <leaf>bar</leaf> *)\n(* </root> *)\n(* >> *)\n\n(* (\\* adding extra spaces at the end of lines, removing or addind newlines, etc*\\) *)\n(* test ql.put  *)\n(* << *)\n(* <root> *)\n(*     <leaf>bar</leaf>   *)\n(*   <leaf>zoo</leaf>  <leaf>foo</leaf>  *)\n(*   <leaf>barfoo</leaf>  *)\n     \n(* </root> *)\n(* >> *)\n(* into *)\n(* << *)\n(* foo42 *)\n(* bar51 *)\n(* >> =  *)\n(* << *)\n(* bar51 *)\n(* zoo *)\n(* foo42 *)\n(* barfoo *)\n(* >>  *)\n"
let _ = Hashtbl.add items "poly" "module Poly =\n\nlet pred_app ('a) ('b) \n  (p : 'a -> bool) (f : 'a -> 'b) (v : 'a where p v) : 'b \n  = f v\n\ntest (pred_app{int}{int} (fun (x:int) -> x = 0)) : ?\ntest (pred_app{int}{int} (fun (f:int) -> f = 0)) : ?\n\n(* correctly, the following does not work -- p cannot be captured *)\n(* test (pred_app{int}{(x:int where p x)} (fun (f:int) -> f = 0)) : ? *)\n"
let _ = Hashtbl.add items "bcard" "module Bcard = \n\n  let Nl : regexp = [\\n] | [\\r] | \"\\r\\n\"\n  let Sp : string = \" \"\n  let Uri: regexp = [^\"\"\\n\\r<>]*\n\n  let simple (xml:string) (ascii:string) : lens =\n    Xml.simple_elt NL2 xml \n      begin \n        ins ascii . \n        ins Sp . \n        Xml.unesc_string [\\r\\n] . \n        qins Nl \"\\n\"\n      end\n\n  let logo : lens = \n    Xml.attr1_simple_elt NL2 \"logo\" \"uri\" \n      begin\n        ins \"L\" . \n        ins Sp . \n        copy Uri . \n        qins Nl \"\\n\"\n      end\n      (copy EPSILON)\n\n  let phone : lens = simple \"phone\" \"P\"\n\n  let email : lens = simple \"email\" \"E\"\n\n  let name : lens = simple \"name\" \"N\"\n\n  let title : lens = simple \"title\" \"T\"\n\n  let card : lens = \n    Xml.elt NL1 \"card\"\n      begin\n        name . \n        title . \n        email . \n        phone . \n        logo \n      end\n\n  let cards : lens = \n    Xml.elt NL0 \"cards\" \n      begin\n        card*\n      end\n\n  let card_ascii : string = \n<<\n  N John Doe\n  T CEO & CTO, Widget Inc.\n  E <\"John Doe\", john.doe@widget.com>\n  P (202) 5551414\n  L widget.gif\n\n>>\n\n  let card_xml : string = \n<<\n<cards>\n <card>\n  <name>John Doe</name>\n  <title>CEO &amp; CTO, Widget Inc.</title>\n  <email>&lt;&quot;John Doe&quot;, john.doe@widget.com&gt;</email>\n  <phone>(202) 5551414</phone>\n  <logo uri=\"widget.gif\"></logo>\n </card>\n</cards>\n>>\n\ntest cards.get card_xml = card_ascii \ntest cards.create card_ascii = (newline . card_xml)\n"
let _ = Hashtbl.add items "uniRX" "module UniRX =\n\nlet attr (name:string) (value:lens) : lens = \n  del name .  \n  del \"=\" . \n  value\n\nlet perm_sort3 (l1:lens) (l2:lens) (l3:lens) : lens =\n  let s23 : lens = (l2 . l3) || (l3 ~ l2) in \n    begin\n       (l3 ~ (l1 . l2))\n    || (s23 ~ l1)\n    end\n\nlet l1 = attr \"t\" (\"M\")\nlet l2 = attr \"k\" (del NUMBER)\nlet l3 = attr \"i\" ANY\n\nlet l2' = const ('t') \"\" \"t\" . \n          const ('=') \"\" \"=\" . \n          copy ('M') . \n          ((const ('k') \"\" \"k\" . \n\t    const ('=') \"\" \"=\" . \n\t    const ('0'|[1-9].[0-9]* ) \"\" \"0\" . \n\t    const ('i') \"\" \"i\" . \n\t    const ('=') \"\" \"=\" . copy ANY ||\n\t    ((const ('i') \"\" \"i\" . \n\t      const ('=') \"\" \"=\" . \n\t      copy ANY) ~\n\t     (const ('k') \"\" \"k\" . \n\t      const ('=') \"\" \"=\" . \n\t      const ('0'|[1-9].[0-9]* ) \"\" \"0\"))) ~\n\t   (const ('t') \"\" \"t\" . \n\t    const ('=') \"\" \"=\" . copy ('M')))\n\nlet l2'' = l1 . (((l2 . l3) || (l3 . l2)) ~ l1)\n\ntest stype l2' = stype l2''\ntest vtype l2' = vtype l2''\n\nlet u' = perm_sort3 l1 l2 l3\n\ntest splittable \"a\"? \"a\"? = false\ntest splittable \"ab\"? \"ab\"? = false\ntest splittable \"abc\"? \"abc\"? = false\n"
let _ = Hashtbl.add items "address" "(*******************************************************************************)\n(* The Harmony Project                                                         *)\n(* harmony@lists.seas.upenn.edu                                                *)\n(*******************************************************************************)\n(* Copyright (C) 2008                                                          *)\n(* J. Nathan Foster and Benjamin C. Pierce                                     *)\n(*                                                                             *)\n(* This library is free software; you can redistribute it and/or               *)\n(* modify it under the terms of the GNU Lesser General Public                  *)\n(* License as published by the Free Software Foundation; either                *)\n(* version 2.1 of the License, or (at your option) any later version.          *)\n(*                                                                             *)\n(* This library is distributed in the hope that it will be useful,             *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of              *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU           *)\n(* Lesser General Public License for more details.                             *)\n(*******************************************************************************)\n(* /examples/address.boom                                                      *)\n(* VCard, XCard, CSV address books lens                                        *)\n(* $Id: address.boom 4607 2009-08-03 16:53:28Z ddavi $ *)\n(*******************************************************************************)\n\nmodule Address = \nopen Sys\nopen Exception\n\n(* This module contains lenses for mapping between vCard, CSV, and a\n   simple XML format (based on XCard). Most of the complexity is\n   related to escaping / unescaping of the special characters in\n   each format. We use sequential composition to build lenses that\n   make multiple passes over each string--escaping / unescaping the\n   raw strings, and then processing the tidied data. \n\n   In going from vCard to CSV, entire fields (e.g., addresses) and\n   the formatting details of specific lines (e.g, item1, item2,\n   item3, and abemail vs. email) are discarded. \n\n   In going from XML to CSV whitespace is discarded. \n\n   In each case, each entry is a chunk and the name serves as a key.\n*)\n\n(* -------------------------------------------------------------------- *)\n(* GENERIC DEFINITIONS *)\n\n(* NL: portable newline *)\nlet NL : regexp = \"\\r\"? . \"\\n\"\n\n(* NonNL: any string not containing a newline *)\nlet NonNL : regexp = not_containing [\\n\\r]\n\n(* filterwith: derived lens that removes characters in [both], then\n   runs [l]*)\nlet filterwith (BOTH: regexp) (l: lens where lens_iterable l && \n                                             iterable_cex (stype l | BOTH)) \n  : lens \n  = filter (BOTH - (stype l)) (stype l) ; l*\n\n(* -------------------------------------------------------------------- *)\n(* ESCAPING *)\n\nlet base_escs = #{char * string}['\\n',\"\\\\n\";\n\t\t\t\t '\\r',\"\\\\r\";\n\t\t\t\t '\\\\',\"\\\\\\\\\"]\n\nlet escs_of_chars (chars:char List.t where disjoint (union_regexps chars) [\\n\\r]) =\n  let ext_escs = List.map{char}{char * string} \n    (fun (c:char) -> (c,'\\\\' . c)) \n    chars in\n  List.append{char * string} base_escs ext_escs\n\nlet escaped_char (escs:(char * string) List.t) = Escaping.char_or_escaped ANYCHAR escs\n\nlet escaped (chars : char List.t) = (escaped_char (escs_of_chars chars))*\n\nlet escapedP (chars : char List.t) = (escaped_char (escs_of_chars chars))+\n\n(* escchar: escape characters in [c], which should be a character\n class. *)\nlet escchar (chars:char List.t where disjoint (union_regexps chars) [\\n\\r])\n  : (lens in ANYCHAR <=> escaped_char (escs_of_chars chars))\n  = Escaping.escape_char ANYCHAR (escs_of_chars chars)\n\n(* unescchar: inverse of (the bijective lens) escchar *)\nlet unescchar (chars:char List.t where disjoint (union_regexps chars) [\\n\\r])\n  : (lens in escaped_char (escs_of_chars chars) <=> ANYCHAR)\n  = Escaping.unescape_char ANYCHAR (escs_of_chars chars)\n\n(* escstr: escape a string using [escchar] *)\nlet escstr (chars:char List.t where disjoint (union_regexps chars) [\\n\\r])\n  : (lens in ANY <=> escaped chars)\n  = (escchar chars)*\n\n(* escstrP: escape a non-empty string using [escchar] *)\nlet escstrP (chars:char List.t where disjoint (union_regexps chars) [\\n\\r])\n  : (lens in ANYP <=> escapedP chars)\n  = (escchar chars)+\n\n(* unescstr: unescape a string using [unescchar] *)\nlet unescstr (chars:char List.t where disjoint (union_regexps chars) [\\n\\r])\n  : (lens in (escaped_char (escs_of_chars chars))* <=> ANY)\n  = (unescchar chars)*\n\n(* unescstrP: unescape a non-empty string using [unescchar] *)\nlet unescstrP (chars:char List.t where disjoint (union_regexps chars) [\\n\\r])\n  : (lens in (escaped_char (escs_of_chars chars))* <=> ANYP)\n  = (unescchar chars)+\n\n(* unit tests for escaping lenses *)\ntest (escchar #{char}[])*.get \"a\\nb\\\\c\" = \"a\\\\nb\\\\\\\\c\"\ntest (unescchar #{char}[])*.get \"\\n\" = error\ntest (unescchar #{char}[])*.get \"abc\" = \"abc\"\ntest (unescchar #{char}[])*.get \"\\\\\\\\\" = \"\\\\\"\ntest (unescchar #{char}[])*.get \"\\\\n\" = \"\\n\"\ntest (escchar #{char}[','])*.get \"a,b\" = \"a\\\\,b\"\ntest (unescchar #{char}[','])*.get \"\\\\,\" = \",\"\n\n(* -------------------------------------------------------------------- *)\n(* TELEPHONE AND NAME FIELDS *)\n\n(* TelTags: strings used in markers for tel fields in CSV *)\nlet TelTags : regexp = [hwce] | \"note\"\n\n(* TelMarker: strings used to mark tel fields in CSV *)\nlet TelMarker : regexp = \" (\" . TelTags . \")\"\n\n(* Tel: a single, escaped tel field *)\nlet Tel : regexp = \", \" . (escaped #{char}[',']) . TelMarker\n\n(* Name: a single, escaped name field. Cannot end with a TelMarker *)\nlet Name : regexp = (escapedP #{char}[',']) - ( ANY . TelMarker )\n\n(* NameP: a single, non-empty name *)\nlet NameP : regexp = Name - EPSILON\n\n(* Family and Given: just non-empty names *)\nlet Family,Given : regexp * regexp = NameP,NameP\n\n(* GlobalName: a single name in CSV *)\nlet GlobalName : regexp = Family . (\", \" . Given)?\n  \n(* AbsAddr: type for CSV address book entry *) \nlet AbsAddr = GlobalName . Tel* \n\n\nlet suffix (mk_suffix : regexp -> lens) : lens =\n    (mk_suffix [)])\n  | (mk_suffix [hwce]) . copy \")\"\n  | (mk_suffix [t(])   . copy \"e)\"\n  | (mk_suffix [(])    . copy ( [hwc] . [)] | \"note)\" )\n  | (mk_suffix [ ])    . copy ([(] . TelTags . [)])\n  | (mk_suffix [o])    . copy \"te)\"\n  | (mk_suffix [n])    . copy \"ote)\"\n\nlet escape_ignore =\n  ( copy \")\" \n  | copy ([hwce] . \")\")\n  | copy \"te)\" \n  | copy \"ote)\"\n  | copy \"note)\"\n  | copy \"(note)\" \n  | copy ( \"(\" . [hwce] . \")\" ) )\n\nlet escaper (chars:char List.t) = \n  let mk_suffix (R:regexp) : lens = \n    Escaping.escape_char (ANYCHAR - R) (escs_of_chars chars) in\n  ( escstr chars . suffix mk_suffix\n  | escape_ignore )\n\nlet unescaper (chars:char List.t) =\n  let mk_suffix (R:regexp) : lens = \n    Escaping.unescape_char (ANYCHAR - R) (escs_of_chars chars) in\n  ( unescstr chars . suffix mk_suffix\n  | escape_ignore )\n\n            \n(* formatnotemptyname: escape string to Name *)\nlet formatnotemptyname : lens = \n  escaper #{char}[',']\n\n(* unformatnotemptyname: unescape string from Name *)\nlet unformatnotemptyname : lens = \n  unescaper #{char}[',';';';':']\n  \n(* name: handles escaping and formatting of a Name. We do this in two \n   passes. First, we unformat to put everything in a canonical \"raw\" form, \n   Then we format to escape characters and render the name *)\n\nlet name : lens =  \n  let escNameP = unformatnotemptyname ; formatnotemptyname in \n  let familyname = del \"N:\" . escNameP in\n  familyname . (del \";\" | (\";\" <-> \", \") . escNameP) . del \";;;\"\n\n(* unit test for name *)\ntest name.get \"N:Pierce;Benjamin C.;;;\" = \"Pierce, Benjamin C.\"\n\n(* formattel: lens for escaping tel data *)\nlet formattel : lens = escstr #{char}[',']\n\n(* field': helper for handling a field. The arguments are as follows:\n     o w0: first tag in vCard source\n     o w1: second tag in vCard source\n     o w2: tag in CSV view\n*)\nlet field' (w0:string) (w1:string) (w2:string) =\n  ((w0 . \";\") <-> \", \") . \n  del \"type=\" . del w1 . \n  del (\";type=\" . [A-Z]+)* . \n  del \";type=pref\"? .\n  del \":\" . \n  (unescstr #{char}[';';',';':']; formattel) .\n  ins \" (\" . ins w2 . ins \")\" .\n  del NL\n\n(* tel': helper lens for handling telephone fields *)\nlet tel' : string -> string -> lens = field' \"TEL\"\n\n(* tel: lens for handling all kinds of telephone fields *)\nlet tel : lens =\n    tel' \"WORK\" \"w\"\n  | tel' \"HOME\" \"h\"\n  | tel' \"CELL\" \"c\"\n\n(* formatnote: lens for escaping note data *)\nlet formatnote : lens = escstr #{char}[',']\n\n(* note: lens for handling note fields. Again, we use the two-pass \n   approach--unformatting / unescaping, and then reformatting / reescaping *)\nlet note : lens =\n  (\"NOTE:\" <-> \", \") .\n  (unescstr #{char}[',';':';';']; formatnote) .\n  ins \" (note)\" .\n  del NL\n\n(* abemail: lens for Apple's special email field. Uses two-pass approach. *)\nlet abemail : lens =\n  (\"item.EMAIL;type=INTERNET;type=pref:\" <-> \", \") .\n  (unescstr #{char}[',';':';';']; escstr #{char}[',']) .\n  del NL .\n  del \"item.X-ABLabel:E-mail\" . \n  del NL .\n  ins \" (e)\" \n\n(* email: lens for ordinary vCard (as in RFC) field *)\nlet email : lens = field' \"EMAIL\" \"INTERNET\" \"e\"\n\n(* entry : lens for an individual vCard field. *)\nlet entry : lens =  (abemail || email) | tel | note\n\n(* ItemLine: regexp for lines that use Apple's itemN convention *)\nlet ItemLine :regexp = \"item\" . NonNL . NL\n\n(* Line: regexp for any line *)\nlet Line : regexp = [^ ] . NonNL . NL . (\" \" . NonNL . NL)*\n\n(* Field: regexp for ItemLine fields: either an ordinary line or two\n   item lines *)\nlet Field : regexp = \n  ((Line - ItemLine) | (ItemLine . ItemLine))\n  - (\"END:VCARD\" . NL)\n\n(* numberedItem: regexp for lines with numbered items *)\nlet NumberedItem (n:string) : regexp =\n  \"item\" . regexp_of_string n . \".\" . NonNL . NL . \"item\" . regexp_of_string n . \".\" . NonNL . NL\n\n(* Field_unnumbered: regexp for fields without numbered item lines *)\nlet Field_unnumbered : regexp =\n  Field - (NumberedItem \"1\" | NumberedItem \"2\" | NumberedItem \"3\")\n\n(* remove_item_numbers: lens for deleting item numberings *)\nlet remove_item_numbers : (lens in ? <-> Field_unnumbered* ) = \n  let delItemNumber (n:string) : lens = \n    copy \"item\" . \n    del n . \n    copy ([.] . NonNL . NL . \"item\") . \n    del n . \n    copy ([.] . NonNL . NL) in\n  let Stuff = copy (Field - (\"item\" . NonNL . NL . \"item\" . NonNL . NL) ) in \n  ( ( Stuff* . delItemNumber \"1\" .\n      Stuff* . delItemNumber \"2\" .\n      Stuff* . delItemNumber \"3\" .\n      copy Field_unnumbered* )\n  || ( Stuff* . delItemNumber \"1\" .\n      Stuff* . delItemNumber \"2\" .\n      copy Field_unnumbered* )\n  || ( Stuff* . delItemNumber \"1\" .\n      copy Field_unnumbered* )\n  || ( copy Field_unnumbered* ) )\n\n(* chunk: lens for a vCard entry *)\nlet chunk : (lens in ? <-> AbsAddr) =  \n  (* delete preamble *)\n  del \"BEGIN:VCARD\" . del NL . \n  del \"VERSION:3.0\" . del NL .  \n  (* format name, tag it as key *)\n  (name; key (vtype name)) . del NL .\n  (* handle fields by: \n       removing item numbers, \n       removing unnumbered fields, \n       evaluating entry *)\n    (remove_item_numbers ;\n     filterwith\n       Field_unnumbered\n       entry) .\n  (* del postamble *)\n  del \"END:VCARD\" . del NL\n\n(* vcard lens: match a chunk *)\nlet vcard = <dictionary \"\":chunk>\n\n(* unit tests for vcard *)\nlet samplevcard = \n  <<\n    BEGIN:VCARD\n    VERSION:3.0\n    N:Andy Patroni;;;;\n    TEL;type=WORK;type=pref:6106236713\n    FN:Andy Patroni\n    X-ABUID:827704A0-38A3-4034-84BF-BADFB87EB1E2\\:ABPerson\n    END:VCARD\n    \n  >>\n\ntest vcard.create \n<<\n  Foo, Jean-Paul, jean-paul.courbebaisse@education.gouv.fr (e), 1234567 (h), bar (e)\n>>\n= \n<<\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Foo;Jean-Paul;;;\n  item1.EMAIL;type=INTERNET;type=pref:jean-paul.courbebaisse@education.gouv.fr\n  item1.X-ABLabel:E-mail\n  TEL;type=HOME:1234567\n  item2.EMAIL;type=INTERNET;type=pref:bar\n  item2.X-ABLabel:E-mail\n  END:VCARD\n\n>>\n  \ntest vcard.put \"Foo, Jean-Paul, bar (e)\" \n  into\n<<\n  BEGIN:VCARD\r\n  VERSION:3.0\r\n  N:AAAAA TEST;Jean-Paul;;;\r\n  item1.EMAIL;type=INTERNET;type=pref:jean-paul.courbebaisse@education.gouv.fr\r\n  item1.X-ABLabel:E-mail\n  TEL;type=WORK:1234567\n  item2.EMAIL;type=INTERNET;type=pref:foo\r\n  item2.X-ABLabel:E-mail\n  END:VCARD\r\n\n>> \n= \n<<\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Foo;Jean-Paul;;;\n  item1.EMAIL;type=INTERNET;type=pref:bar\n  item1.X-ABLabel:E-mail\n  END:VCARD\n\n>>\n\ntest vcard.get samplevcard = \"Andy Patroni, 6106236713 (w)\"\n\ntest vcard.put \n  \"Andy Patroni, 12345 (c), 67890 (h)\"\n  into samplevcard = \n  \"BEGIN:VCARD\n  |VERSION:3.0\n  |N:Andy Patroni;;;;\n  |TEL;type=CELL:12345\n  |FN:Andy Patroni\n  |X-ABUID:827704A0-38A3-4034-84BF-BADFB87EB1E2\\\\:ABPerson\n  |TEL;type=HOME:67890\n  |END:VCARD\n  |\"\n\ntest vcard.put \n  \"Andy Patroni, fubar (note)\" \n  into samplevcard =\n<<\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Andy Patroni;;;;\n  NOTE:fubar\n  FN:Andy Patroni\n  X-ABUID:827704A0-38A3-4034-84BF-BADFB87EB1E2\\:ABPerson\n  END:VCARD\n\n>>\n\n(* vcards: lens for a whole file of vcards *)\nlet vcards : lens = (<chunk> . ins \"\\n\") * . del WS\n\n(* unit test for vcards *)\nlet samplevcards = \n<<\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Androuet;;;;\n  FN:Androuet\n  NOTE:(01) 42 89 95 00  41 rue d'Amsterdam  M. Liege  (cheese restaurant near St. Lazare\\, Paris)  rather expensive and fancy and pungent (300FF/person)\n  X-ABUID:A5695B7A-5931-4A63-8308-ANOTHERIDENT0\\:ABPerson\n  END:VCARD\n  BEGIN:VCARD\n  VERSION:3.0\n  N:New York Restaurants;;;;\n  FN:New York Restaurants\n  NOTE:two best mexican in nyc (according to Scot\\, IIRC)\\n          rosa mexicana\\n          zarela's\n  X-ABUID:D40A8D20-F5E8-47E1-983E-D331E92C6F8B\\:ABPerson\n  END:VCARD\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Pierce;Benjamin C.;;;\n  FN:Benjamin C. Pierce\n  TEL;type=HOME;type=pref:215 732-4684\n  TEL;type=CELL:215 266-9001\n  TEL;type=WORK:215 898-6222\n  X-ABUID:87B85E7E-AB0F-4819-8647-0BD532019144\\:ABPerson\n  END:VCARD\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Andy Patroni;;;;\n  FN:Andy Patroni\n  TEL;type=WORK;type=pref:6106236713\n  X-ABUID:827704A0-38A3-4034-84BF-BADFB87EB1E2\\:ABPerson\n  END:VCARD\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Bistro de Vent;;;;\n  FN:Bistro de Vent\n  X-ABUID:F00ABF1D-8DC0-4C3C-98ED-2BC33FA8D90C\\:ABPerson\n  END:VCARD\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Biswas;Goutam;;;\n  FN:Goutam Biswas\n  X-ABUID:5BEAD7E0-AFF8-42AB-BD38-9A741CD64E20\\:ABPerson\n  END:VCARD\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Black;Andrew;;;\n  FN:Andrew Black\n  X-ABUID:A9BA5924-5A64-4D46-A40F-A0BC86073232\\:ABPerson\n  END:VCARD\n\n>>\n      \ntest vcards.get samplevcards = \n<<\n  Androuet, (01) 42 89 95 00  41 rue d'Amsterdam  M. Liege  (cheese restaurant near St. Lazare\\, Paris)  rather expensive and fancy and pungent (300FF/person) (note)\n  New York Restaurants, two best mexican in nyc (according to Scot\\, IIRC)\\n          rosa mexicana\\n          zarela's (note)\n  Pierce, Benjamin C., 215 732-4684 (h), 215 266-9001 (c), 215 898-6222 (w)\n  Andy Patroni, 6106236713 (w)\n  Bistro de Vent\n  Biswas, Goutam\n  Black, Andrew\n\n>>\n\ntest vcards.put \n<<\n  Andy Patroni, 6106236713 (w), fubar (note)\n  Pierce, Benjamin C., 215 898-6222 (w), 215 732-4684 (h), 215 266-9001 (c)\n\n>>\ninto samplevcards = \n<<\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Andy Patroni;;;;\n  FN:Andy Patroni\n  TEL;type=WORK;type=pref:6106236713\n  X-ABUID:827704A0-38A3-4034-84BF-BADFB87EB1E2\\:ABPerson\n  NOTE:fubar\n  END:VCARD\n  BEGIN:VCARD\n  VERSION:3.0\n  N:Pierce;Benjamin C.;;;\n  FN:Benjamin C. Pierce\n  TEL;type=WORK:215 898-6222\n  TEL;type=HOME:215 732-4684\n  TEL;type=CELL:215 266-9001\n  X-ABUID:87B85E7E-AB0F-4819-8647-0BD532019144\\:ABPerson\n  END:VCARD\n\n>>\n\n(* BCP's own unit test *)\n(* test vcards get (read \"/home/bcpierce/Desktop/vCards.vcf\") = ? *)\n\n\n(* -------------------------------------------------------------------- *)\n(* XML STUFF *)\n\nlet xml_escs : (char * string) List.t =\n  #{char * string}[ ('>',\"&gt;\"); ('<',\"&lt;\"); ('&',\"&amp;\") ] \n\n(* unescpcdata: regexp for unescaping raw PCDATA *)\nlet unescpcdata : lens = Escaping.unescape ANYCHAR xml_escs\n  \n(* formatpcdata: lens for escaping PCDATA; excludes TelTags using escaper helper from above. *)\nlet format_pcdata : lens = \n  let mk_suffix (R:regexp) : lens = copy (ANYCHAR - R)  in\n  ( unescpcdata . suffix mk_suffix\n  | escape_ignore )\n\n(* -------------------------------------------------------------------- *)\n(* BCP's personal variant of XCard *)\n\n(* name: lens for handling name field. In XCard, a name is either a\n   single element n, or has two subelements, family and given. Also\n   handles escaping. *)\nlet name : lens = \n  let n = format_pcdata; formatnotemptyname in \n    ( Xml.simple_elt NL4 \"n\" n\n      || (Xml.elt NL4 \"n\" \n         (Xml.simple_elt NL6 \"family\" n . \n            (copy \"\" | ins \", \" . Xml.simple_elt NL6 \"given\" n))))\n\n(* tel': helper for escaping and formatting telephone data. \n     o full: XCard tag\n     o short: CSV tag \n*)\nlet tel' (full:string) (short:string) : lens = \n  ins \", \" . \n  Xml.simple_elt NL4 full (unescpcdata ; formattel . ins (\" (\" . short . \")\"))\n\n(* tel: lens for handling all tags *)\nlet tel : lens = \n    tel' \"tel-home\" \"h\"\n  | tel' \"tel-work\" \"w\"\n  | tel' \"tel-cell\" \"c\"\n  | tel' \"email\"    \"e\"\n  | tel' \"note\"     \"note\"\n      \n(* chunk: lens for handling a single XCard entry *)\nlet chunk :lens = \n  Xml.elt NL2 \"vcard\" ((name; key (vtype name)) . tel* )\n\n(* vcard: lens for handling a single XCard vcard element *)\nlet vcard : lens = <chunk>\n\nlet samplevcard = \n  \"<vcard>\n      <n><family>foo</family><given>bar</given></n>\n      <tel-home>12345</tel-home>\n      <tel-cell>12345</tel-cell>\n      <note>hello world</note>\n   </vcard>\"\n\n(* unit test for vcard *)\ntest vcard.get samplevcard = \n  \"foo, bar, 12345 (h), 12345 (c), hello world (note)\"\n\n(* xcard: lens for handling a single XCard xcard elemnet *)\nlet xcard : lens = Xml.top \"xcard\" ((vcard . ins \"\\n\") * )\n\n(* unit tests for xcard *)\nlet samplexcards : string = \n  \"<xcard>\n     | <vcard>\n     |   <n>Charles Addams</n>\n     |   <note>goodbye world</note></vcard>\n     | <vcard>\n     |   <n><family>Doe</family><given>John</given></n>\n     |   <note>hello world</note>\n     |   <tel-home>792-8134</tel-home>\n     |   <tel-home>732-4684</tel-home></vcard>\n     | <vcard>\n     |   <n><family>Doe</family><given>Sally</given></n>\n     |   <tel-home>792-8134</tel-home>\n     |   <tel-home>732-4684</tel-home>\n     |   <note>hello, world ! Question : nice weather ? (no ?)</note>\n     | </vcard>\n     |</xcard>\"\n\ntest xcard.get samplexcards =\n<<\n  Charles Addams, goodbye world (note)\n  Doe, John, hello world (note), 792-8134 (h), 732-4684 (h)\n  Doe, Sally, 792-8134 (h), 732-4684 (h), hello\\, world ! Question : nice weather ? (no ?) (note)\n\n>>             \n\ntest xcard.create \"Foster, Nate, 267.342.1099 (h)\\n\" = \n<<\n  <xcard>\n    <vcard>\n      <n>\n        <family>Foster</family>\n        <given>Nate</given>\n      </n>\n      <tel-home>267.342.1099</tel-home>\n    </vcard>\n  </xcard>\n>>\n\n(* Some notes about the Apple Address Book application:\n   - \\ characters do NOT round-trip: It will read a vCard containing\n     \\\\Manchester and write it out as \\Manchester\n   - it trims blanks from the ends of fields\n   - Unknown vCard fields get dumped into NOTEs.\n   - It wants X-ABLabel fields to know how to display things, but it\n     doesn't require them\n   - It sometimes uses item1, item2, etc., instead of the EMAIL tag\n*)\n\n(* TO DO:\n\n   When processing a vCard, we might want to take *all* the fields we don't recognize\n   (except, perhaps, some that we explicitly choose to delete) and put them in the note\n   field in the abstract.  (This would mean that the lens is essentially a bijection.)\n\n   To achieve this, it seems we'd need to...\n      - use the order primitive to move the NOTE field to the end\n      - then use order again to move all the recognized fields to the beginning\n        and unrecognized fields to the end (before the NOTE)\n      - then invent some convention for smashing them together with a separator, say $\n      - escape $ everywhere it appears in the concrete vCard\n      - In other formats (e.g. xCard), disallow $ in the concrete format of notes, except\n        in situations where the whole note can be parsed as a real note plus some extra\n        fields.  (I.e., basically the abstract and concrete note formats are the same.)\n*)   \n\ntest (xcard).create \n<<\nFoster, Clare, jscef@uas.alaska.edu (e), (907) 738-0553 (c), (907) 747-5499 (h)\nFoster, Nate, jnfoster@cis.upenn.edu (e), 267 342-1099 (c)\n\n>> = ?\n\nlet okfailwith 'a = ok{'a}, raise{'a}, failwith{'a}\n\nlet usage = \n  let prog = Prefs.get_prog_name () in\n  \"Usage: \" . prog . \" {get|put} args\\n\"\n     . \"  \" . prog . \" get <source> <format of the view>\\n\"\n     . \"  \" . prog . \" put <view> <old source>\\n\"\n\ntype format = VCF | XML | CSV\n\nlet main () =\n  let vcf2csv = vcards in\n  let xml2csv = xcard . del WS in (* trailing whitespace *)\n  let xml2vcf = right_quot xml2csv (canonizer_of_lens vcf2csv) in\n  let vcf2xml = right_quot vcf2csv (canonizer_of_lens xml2csv) in\n  let get_type (so:string option) =\n    match so with\n      | Some \"vcf\" -> Some{format} VCF\n      | Some \"xml\" -> Some{format} XML\n      | Some \"csv\" -> Some{format} CSV\n      | _ -> None{format}\n  in\n  let read_file (f:string) =\n    let ok, fail, failwith = okfailwith{format * string} in\n    match get_type (String.file_ext f), file_exists f with\n      | None, _  -> failwith (\"File \".f.\" does not have a valid extension\")\n      | _, false -> failwith (\"File \".f.\" does not exists\")\n      | Some fmt, _ -> ok (fmt, read f)\n  in\n  let read_format (fmt:string) =\n    let ok, fail, failwith = okfailwith{format} in\n    match get_type (Some{string} fmt) with\n      | None -> failwith (fmt.\" is not a valid format\")\n      | Some fmt -> ok fmt\n  in\n  let cget (view':format) (source:(format*string)) =\n    let source', source = source in\n    match view', source' with\n      | VCF, VCF -> source\n      | XML, XML -> source\n      | CSV, CSV -> source\n\n      | CSV, VCF -> get vcf2csv    source\n      | VCF, CSV -> create vcf2csv source\n\n      | CSV, XML -> get xml2csv    source\n      | XML, CSV -> create xml2csv source\n\n      | XML, VCF -> get vcf2xml    source\n      | VCF, XML -> get xml2vcf    source\n  in\n  let cput (view:format*string) (source:format*string) =\n    let source', source = source in\n    let view', view = view in\n    match view', source' with\n      | VCF, VCF -> source\n      | XML, XML -> source\n      | CSV, CSV -> source\n\n      | CSV, VCF -> put vcf2csv view source\n      | VCF, CSV -> get vcf2csv view\n\n      | CSV, XML -> put xml2csv view source\n      | XML, CSV -> get xml2csv view\n\n      | XML, VCF -> put vcf2xml view source\n      | VCF, XML -> put xml2vcf view source\n  in\n  let run (args : string List.t) =\n    let ok, fail, failwith = okfailwith{int} in\n    let bind_fmt  = bind{format}{int} in\n    let bind_file = bind{format*string}{int} in\n    let print_usage (code:int) () =\n      let _ = put_str usage in code\n    in\n    match args with\n      | \"get\"::source::format::[] -> \n          (let source = read_file source in\n           let format = read_format format in\n           bind_fmt  format $ fun (view':format) ->\n           bind_file source $ fun (source:format*string) ->\n           let _ = put_str (cget view' source) in\n           ok 0)\n      | \"put\"::  view::source::[] ->\n          (let source = read_file source in\n           let view   = read_file view in\n           bind_file view   $ fun (view:format*string) ->\n           bind_file source $ fun (source:format*string) ->\n           let _ = put_str (cput view source) in\n           ok 0)\n      | [] -> fail (print_usage 0)\n      | _ ->  fail (print_usage 1)\n  in\n  convert_main $ run $ Prefs.read_string_list $ Prefs.extern_rest ()\n"
let _ = Hashtbl.add items "exception" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2009                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /lenses/exception.boom                                                     *)\n(* Use monad ideas to implement exception                                     *)\n(* $Id: exception.boom 4635 2009-08-25 18:52:01Z cretin $ *)\n(******************************************************************************)\n\nmodule Exception =\n\n#{@}\n\n#* type ('exn,'a) t = Value of 'a | Exn of 'exn\n\n#* let generic_fmap 'exn 'a 'b (f:'a -> 'b) (x:('exn,'a) t) =\n#*   match x with\n#*   | Value v -> Value{'exn}{'b} (f v)\n#*   | Exn e -> Exn{'exn}{'b} e\n\n#* let fmap = generic_fmap{unit -> int}\n\n#* let generic_join 'exn 'a (x:('exn,('exn,'a) t) t) =\n#*   match x with\n#*   | Value (Value v) -> Value{'exn}{'a} v\n#*   | Value (Exn e) -> Exn{'exn}{'a} e\n#*   | Exn e -> Exn{'exn}{'a} e\n\n#* let join = generic_join{unit -> int}\n\n#* let generic_bind 'exn 'a 'b (x:('exn,'a) t) (f:'a -> ('exn,'b) t) =\n#*   generic_join{'exn}{'b} (generic_fmap{'exn}{'a}{('exn,'b) t} f x)\n\n#* let bind = generic_bind{unit -> int}\n\n#* let generic_rbind 'exn 'a 'b (f:'a -> ('exn,'b) t) (x:('exn,'a) t) =\n#*   generic_bind{'exn}{'a}{'b} x f\n\n#* let rbind = generic_rbind{unit -> int}\n\n#* let generic_return 'exn 'a (x:'a) = Value{'exn}{'a} x\n#* let generic_ok = generic_return\n\n#* let return = generic_return{unit -> int}\n#* let ok = generic_ok{unit -> int}\n\n\n#* let generic_raise 'exn 'a (y:'exn) = Exn{'exn}{'a} y\n\n#* let raise = generic_raise{unit -> int}\n#* let failwith 'a (message:string) =\n#*   raise{'a} (fun (u:unit) ->\n#*               let _ = Sys.put_str (\"Failure: \" . message . \"\\n\") in 1)\n\n#* let generic_try 'exn 'a (x:('exn,'a) t) (catch:'exn -> ('exn,'a) t) =\n#*   match x with\n#*   | Value v -> Value{'exn}{'a} v\n#*   | Exn e -> catch e\n\n#* let try 'a (x:(unit -> int,'a) t) (catch:unit -> (unit -> int,'a) t) =\n#*   match x with\n#*   | Value v -> Value{unit -> int}{'a} v\n#*   | Exn e -> catch ()\n\n#* let generic_convert 'exn 'a (x:('exn,'a) t) (convert:'exn -> 'a) =\n#*   match x with\n#*   | Value v -> v\n#*   | Exn e -> convert e\n\n#* let convert = generic_convert{unit -> int}\n#* let convert_main (code:((unit -> int), int) t) =\n#*   match code with\n#*   | Value c -> c\n#*   | Exn e -> e ()\n"
let _ = Hashtbl.add items "sort" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2008                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /lenses/sort.boom                                                          *)\n(* Sorting functions                                                          *)\n(* $Id: sort.boom 4658 2009-11-14 02:55:39Z jnfoster $ *)\n(******************************************************************************)\n\nmodule Sort =\n\n#{@}\n\n\\section{Sorting}\n\nThe @Sort@ module defines functions for building lenses that do sorting. \n\n\\subsection{Permutation Sorting}\n\nUsing the @lens_permute@ operator, and the functions for manipulating \ninteger lists representing permutations from the @List@ module it is \nstraightforward to define lenses that do sorting. \n\n\\LENSSECTION{@perms_regexps@} The @perms_regexps@ function computes the\npermutations of a list of regular expressions as a list of lists of\nregular expressions.\n\n#* let perms_regexps (rl:regexp List.t) : (regexp List.t) List.t = \n#*   List.map{int List.t}{regexp List.t}\n#*     (fun (sigmai:int List.t) -> List.permute{regexp} sigmai rl)\n#*     (List.permutations (List.length{regexp} rl))\n\n#* test perms_regexps #{regexp}[\"a\";\"b\"] \n#* = #{regexp List.t}[#{regexp}[\"a\";\"b\"]; #{regexp}[\"b\";\"a\"]]\n\n\\LENSSECTION{@perm_regexps@} The @perm_regexps@ function is similar but\nflattens the inner lists using @regexp_concat@.\n\n#* let perm_regexps (rl:regexp List.t) : regexp List.t = \n#*   List.map{regexp List.t}{regexp} concat_regexps (perms_regexps rl)\n\n\n#* test perm_regexps #{regexp}[\"a\";\"b\"] \n#* = #{regexp}[\"ab\";\"ba\"]\n\n\\LENSSECTION{@perm_sortable@} The @perm_sortable@ predicate returns\n@true@ iff the concatenations of all permutations of a list of regular\nexpressions are unambiguous and also disjoint.\n\n#* let perm_sortable (rl:regexp List.t) : bool =\n#*   let perms = perms_regexps rl in \n#*   List.for_all{regexp List.t} (fun (pi:regexp List.t) -> concatable pi) perms\n#*   && disjoint_regexps (List.map{regexp List.t}{regexp} concat_regexps perms)\n\n\\LENSSECTION{@perm_sort@} The @perm_sort@ lens sorts a list of regular\nexpressions using instances of the @lens_permute@ combinator.\n\n#* let perm_sort \n#*   (rl:regexp List.t where perm_sortable rl)\n#* : (lens in union_regexps (perm_regexps rl) <-> concat_regexps rl) = \n#*   let k : int = List.length{lens} rl in\n#*   let ls_perms : lens List.t = \n#*     List.map{int List.t}{lens} \n#*       (fun (sigma:int List.t) -> \n#*          let sigma_inv = List.invert_permutation sigma in \n#*          lens_permute sigma (List.permute{lens} sigma_inv rl))\n#*       (List.permutations (List.length{lens} rl)) in\n#*   List.fold_left{lens}{lens}\n#*     (fun (acc:lens) (permi:lens) -> acc || permi)\n#*     (copy EMPTY) ls_perms\n\n## let l2 : (lens in (\"ab\" | \"ba\") <-> \"ab\") = \n##   perm_sort #{regexp}[\"a\";\"b\"]\n## test l2.get \"ab\" = \"ab\"\n## test l2.get \"ba\" = \"ab\"\n\n#* let l3 : (lens in (\"abc\" | \"acb\" | \"bac\" | \"bca\" | \"cab\" | \"cba\") <-> \"abc\") = \n#*   perm_sort #{regexp}[\"a\";\"b\";\"c\"]\n#* test l3.get \"abc\" = \"abc\"\n#* test l3.get \"acb\" = \"abc\"\n#* test l3.get \"bac\" = \"abc\"\n## test l3.get \"bca\" = \"abc\"\n## test l3.get \"cab\" = \"abc\"\n## test l3.get \"cba\" = \"abc\"\n\n## let l4 \n## : (lens in\n##      ( \"abcd\" | \"abdc\" | \"acbd\" | \"acdb\" | \"adbc\" | \"adcb\"  \n##      | \"bacd\" | \"badc\" | \"bcad\" | \"bcda\" | \"bdac\" | \"bdca\"  \n##      | \"cabd\" | \"cadb\" | \"cbad\" | \"cbda\" | \"cdab\" | \"cdba\" \n##      | \"dabc\" | \"dacb\" | \"dbac\" | \"dbca\" | \"dcab\" | \"dcba\" ) <-> \"abcd\" ) = \n##  perm_sort #{regexp}[\"a\";\"b\";\"c\";\"d\"]\n\n## test l4.get \"abcd\" = \"abcd\"\n## test l4.get \"abdc\" = \"abcd\"\n## test l4.get \"acbd\" = \"abcd\"\n## test l4.get \"acdb\" = \"abcd\"\n## test l4.get \"adbc\" = \"abcd\"\n## test l4.get \"adcb\" = \"abcd\"\n## test l4.get \"bacd\" = \"abcd\"\n## test l4.get \"badc\" = \"abcd\"\n## test l4.get \"bcad\" = \"abcd\"\n## test l4.get \"bcda\" = \"abcd\"\n## test l4.get \"bdac\" = \"abcd\"\n## test l4.get \"bdca\" = \"abcd\"\n## test l4.get \"cabd\" = \"abcd\"\n## test l4.get \"cadb\" = \"abcd\"\n## test l4.get \"cbad\" = \"abcd\"\n## test l4.get \"cbda\" = \"abcd\"\n## test l4.get \"cdab\" = \"abcd\"\n## test l4.get \"cdba\" = \"abcd\"\n## test l4.get \"dabc\" = \"abcd\"\n## test l4.get \"dacb\" = \"abcd\"\n## test l4.get \"dbac\" = \"abcd\"\n## test l4.get \"dbca\" = \"abcd\"\n## test l4.get \"dcab\" = \"abcd\"\n## test l4.get \"dcba\" = \"abcd\"\n\n\\LENSSECTION{@perm_sort_concat@} The @perm_sort_concat@ quotient lens\nuses a canonizer built using @perm_sort@ to sort the source string\nbefore it is processed by (the concatenation of) a list of lenses.\n\n#* let perm_sort_concat \n#*    (ls:lens List.t where perm_sortable (stypes ls) && concatable (vtypes ls))\n#*  : (lens in union_regexps (perm_regexps (stypes ls)) <-> concat_regexps (vtypes ls))\n#*  = left_quot (canonizer_of_lens (perm_sort (stypes ls))) (concat_lenses ls)\n\n\\LENSSECTION{@perm_concat@} The @perm_sort_concat@ lens does\nsorting, but its type on the source side grows as the {\\em factorial} of\nthe regular expressions being sorted. The final @sort_concat@ lens uses\nthe @sort@ canonizer, which has a much more compact (although imprecise)\ntype.\n\n#* let sort_concat \n#*    (ls:lens List.t where sortable (stypes ls) && concatable (vtypes ls))\n#*  : (lens in (union_regexps (stypes ls))* <-> concat_regexps (vtypes ls))\n#*  = left_quot (sort (astypes ls)) (concat_lenses ls)  \n\n#* let ls : (lens in [abc]* <-> \"abc\") = \n#*   sort_concat #{lens}[\"a\"; \"b\"; \"c\"]\n\n#* test get ls \"abc\" = \"abc\"\n#* test get ls \"cba\" = \"abc\"\n#* test get ls \"bca\" = \"abc\"\n#* test get ls \"bba\" = error\n#* test get ls \"dba\" = error\n#* test put ls \"abc\" \"cba\" = \"abc\"\n\n#* let partition_sort_concat \n#*   (ls:lens List.t where concatable (vtypes ls))\n#*   (l:lens where sortable (List.Cons{regexp} (stype l,stypes ls))\n#*              && splittable_cex (concat_regexps (vtypes ls)) (vtype l)* )\n#* : (lens in (union_regexps (stypes ls) | (stype l))* <->\n#*            (concat_regexps (vtypes ls) . (vtype l)* ))\n#*  = \n#*  let cn_partition =\n#*    canonizer_of_lens (partition #{regexp}[((union_regexps (stypes ls)) - EPSILON);(stype l)])\n#*  in \n#*  let cn_sort = sort (stypes ls) in\n#*  left_quot cn_partition (left_quot cn_sort (concat_lenses ls) . l* )\n\n#* test (partition_sort_concat #{lens}[copy [A-Z]; copy [0-9]] (copy [a-z])).get \"aBc3d\" = \"B3acd\"\n#* test (partition_sort_concat #{lens}[copy [A-Z]; copy [0-9]] (copy [a-z])).put \"Z9xyz\" into \"A1\" = \"Z9xyz\"\n"
let _ = Hashtbl.add items "coqsplit" "module Coqsplit =\n\nlet TAG = [A-Z] . [A-Z ]*\nlet IDENT = [a-zA-Z] . [a-zA-Z0-9_']*\n\n(* ugh...bounded polymorphism would be really nice here *)\nlet com_open  = \"(*\"\nlet com_close = \"*)\"\n\nlet SCOM (R:regexp) : regexp = com_open . \" \" . R . com_close\nlet scom (s:string) : string = com_open . \" \" . s . com_close\n\nlet DCOM (R:regexp) : regexp = com_open . \"* \" . R . com_close\nlet dcom (s:string) : string = com_open . \"* \" . s . com_close\n\nlet COM (R:regexp) : regexp = SCOM R | DCOM R\n\n(******************************************************************************)\n(* COPYING (not used) *********************************************************)\n(******************************************************************************)\n\nlet INLINE_TAG (tag:string in TAG) : regexp = \n  let internal = (tag . \": \" . not_containing com_close) in\n  COM internal\n\nlet inline_tag (tag:string in TAG) \n  : (lens in INLINE_TAG tag <=> INLINE_TAG tag) \n  = copy (INLINE_TAG tag)\n\ntest matches_cex (stype (inline_tag \"HIDE\")) \"(* HIDE: A better beginning would be nice... *)\" = true\ntest matches_cex (stype (inline_tag \"HIDE\")) \"(** HIDE: A better beginning would be nice... *)\" = true\n\nlet OPEN_TAG (tag:string in TAG) : regexp = SCOM (tag . \" \")\nlet CLOSE_TAG (tag:string in TAG) : regexp = SCOM (\"/\" . tag . \" \")\n\nlet BLOCK_TAG (tag:string in TAG) : regexp =\n  let OPEN = OPEN_TAG tag in\n  let CLOSE = CLOSE_TAG tag in\n  OPEN . (not_containing CLOSE) . CLOSE\n\nlet block_tag (tag:string in TAG)\n  : (lens in BLOCK_TAG tag <=> BLOCK_TAG tag)\n  = copy (BLOCK_TAG tag)\n\ntest matches_cex (stype (block_tag \"FULL\"))\n  <<\n   (* FULL *)\n     We will be investigating both aspects in tandem.\n   (* /FULL *)\n  >> = true\n\n(******************************************************************************)\n(* DELETING *******************************************************************)\n(******************************************************************************)\n\nlet del_inline_tag (tag:string in TAG) \n  : (lens in INLINE_TAG tag <-> \"\") \n  = del (INLINE_TAG tag)\n\ntest (del_inline_tag \"HIDE\").get \"(* HIDE: A better beginning would be nice... *)\" = \"\"\ntest (del_inline_tag \"HIDE\").get \"(** HIDE: A better beginning would be nice... *)\" = \"\"\n\nlet del_block_tag (tag:string in TAG)\n  : (lens in BLOCK_TAG tag <-> \"\")\n  = del (BLOCK_TAG tag)\n\ntest (del_block_tag \"FULL\").get\n  <<\n   (* FULL *)\n     We will be investigating both aspects in tandem.\n   (* /FULL *)\n  >> = \"\"\n\n(******************************************************************************)\n(* TAG DROPPING ***************************************************************)\n(******************************************************************************)\n\nlet drop_inline_tag (tag:string in TAG) \n  : (lens in INLINE_TAG tag <-> COM (not_containing com_close)) \n  = com_open . \"*\"? . del (\" \" . tag . \":\") . \" \" . (not_containing com_close) . com_close\n\ntest (drop_inline_tag \"HIDE\").get \"(* HIDE: A better beginning would be nice... *)\" = \"(* A better beginning would be nice... *)\"\ntest (drop_inline_tag \"HIDE\").get \"(** HIDE: A better beginning would be nice... *)\" = \"(** A better beginning would be nice... *)\"\n\n(* TODO: allow whitespace between open tag and newline *)\nlet drop_block_tag (tag:string in TAG)\n  : (lens in (OPEN_TAG tag . \"\\n\" . not_containing (CLOSE_TAG tag) . CLOSE_TAG tag . \"\\n\")\n         <-> not_containing (CLOSE_TAG tag))\n  = \n  let OPEN  = (OPEN_TAG tag) in\n  let CLOSE = (CLOSE_TAG tag) in\n  del (OPEN . \"\\n\") . not_containing CLOSE . del (CLOSE . \"\\n\")\n\ntest (drop_block_tag \"FULL\").get\n  <<\n   (* FULL *)\n     We will be investigating both aspects in tandem.\n   (* /FULL *)\n\n  >> = \"  We will be investigating both aspects in tandem.\\n\"\n\n(******************************************************************************)\n(* REPLACING ******************************************************************)\n(******************************************************************************)\n\n(* TODO: contract on s? *)\nlet replace_entire_block_tag (tag:string in TAG) (s:string) =\n  del_block_tag tag . ins s\n\ntest (replace_entire_block_tag \"ADMIT\" \"(* FILL IN HERE *) admit.\").get\n    <<\n     (* ADMIT *)\n       match b1 with\n       | true => negb b2\n       | false => true\n       end.\n     (* /ADMIT *)\n    >>\n    = \"(* FILL IN HERE *) admit.\"\n\nlet replace_block_tag (tag:string in TAG) (rs:string) =\n  ins rs . drop_block_tag tag\n\ntest (replace_block_tag \"ADMIT\" \"(* SOLUTION: *)\\n\").get\n    <<\n     (* ADMIT *)\n       match b1 with\n       | true => negb b2\n       | false => true\n       end.\n     (* /ADMIT *)\n\n    >>\n    =\n    <<\n     (* SOLUTION: *)\n       match b1 with\n       | true => negb b2\n       | false => true\n       end.\n\n    >>\n"
let _ = Hashtbl.add items "test_poly_coercion" "module Test_poly_coercion =\n\nlet xml_escs : (char * string) List.t =\n  #{char * string}[ ('>',\"&gt;\"); ('<',\"&lt;\"); ('&',\"&amp;\") ] \n\nlet str_map = List.map{char*string}{regexp}\nlet cs_fst = fst{char}{string}\nlet escaped_chars (escs : (char * string) List.t) : regexp List.t\n  = str_map cs_fst escs\n\nlet unescaped (escs : (char * string) List.t) : regexp =\n  union_regexps (escaped_chars escs)\n\ntest unescaped xml_escs = [&<>]\n"
let _ = Hashtbl.add items "uniProtV2" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2008                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /examples/uniProtV2.boom                                                   *)\n(* UniProtKB XML <-> UniProtKB ASCII lens                                     *)\n(* $Id: uniProtV2.boom 4607 2009-08-03 16:53:28Z ddavi $ *)\n(******************************************************************************)\n\nmodule UniProtV2 = \n\n(* --------------------------------------------------------------------------- *)\n(* GENERIC HELPER FUNCTIONS *)\n\n(* [bracket l] inserts enclosing square bracket. *) \nlet brackets (l:lens) : lens = \n  ins \"[\" . l . ins \"]\" \n\n(* [parens l] inserts enclosing parentheses. *) \nlet parens (l:lens) : lens = \n  ins \"(\" . l . ins \")\"\n\n(* [quotes s] inserts enclosing quotation marks. *) \nlet quotes (l:lens) : lens = \n  ins \"\\\"\" . l . ins \"\\\"\" \n  \n(* --------------------------------------------------------------------------- *)\n(* CONSTANTS *)\n\n\n(* [nlX]: X^th amount of whitespace--used to canonize XML *)\nlet NL = newline\nlet NL0 = NL\nlet NL1 = NL0 . \"  \"\nlet NL2 = NL1 . \"  \"\nlet NL3 = NL2 . \"  \"\nlet NL4 = NL3 . \"  \"\nlet NL5 = NL4 . \"  \"\nlet NL6 = NL5 . \"  \"\nlet NL7 = NL6 . \"  \" \nlet NL8 = NL7 . \"  \"\nlet NL9 = NL8 . \"  \"\nlet NL10 = NL9 . \"  \"\n\nlet esc : lens = Xml.unesc_string [] \nlet esc_s : lens = Xml.unesc_string [;]\nlet esc_c : lens = Xml.unesc_string [,] \nlet esc_cs : lens = Xml.unesc_string [,;]\nlet esc_csp : lens = Xml.unesc_string [,;()]\nlet esc_p : lens = Xml.unesc_string [()]\nlet esc_q : lens = Xml.unesc_string [\"\"''] \nlet esc_qnl : lens = Xml.unesc_string [\"\"''\\n] \nlet esc_dq : lens = Xml.unesc_string [\"\"''.] \nlet esc_dsq : lens = Xml.unesc_string [\\-;''\"\"] \nlet esc_sq : lens = Xml.unesc_string [;\"\"''] \nlet esc_qp : lens = Xml.unesc_string [\"\"''()] \nlet esc_cq : lens = Xml.unesc_string [,\"\"''] \nlet esc_cdq : lens = Xml.unesc_string [.,\"\"''] \nlet esc_d : lens = Xml.unesc_string [.] \nlet esc_n : lens = Xml.unesc_string [:]\nlet esc_p : lens = Xml.unesc_string [ ]\nlet raw : regexp = \n  let e : regexp = [^;\\n ] in \n  let m : regexp = [^;\\n] in \n  e . (m* . e)?\n\n(* --------------------------------------------------------------------------- *)\n(* ASCII Helpers *)\n\n(* [tag t] formats a UniProtKB format and standard three spaces. \n   o [t] tag. \n*)\nlet tag (t:string) : string = \n  t . \"   \"\n\n(* [split (t,l)] wraps [l] so that it also breaks long lines. *)\nlet split_n (n:int) (tag:string) (l:lens) : lens = \n  let cn : canonizer = columnize n (vtype l) ' ' (NL . tag) in \n  right_quot l cn\n\nlet split (tag:string) (l:lens) : lens = split_n 75 tag l\nlet split70 (tag:string) (l:lens) : lens = split_n 70 tag l\n\n(* [terminate l] wraps [l] so that it also inserts [NL]. \n   o [l] lens\n*)\nlet terminate (l:lens) : lens = l . ins NL\n\n(* [split_terminate (t,l)] wraps [l] so that it also breaks long lines and inserts [NL]. \n   o [(t,l)] tag * lens\n*)\nlet split_terminate (tag:string) (l:lens) : lens = \n  terminate (split tag l)\n\n(* insert strings into the view *)\nlet space : lens = ins \" \" \nlet qspace : lens = qins [ ]* \"\"\nlet qsp : lens = qins [ ]+ \" \"\nlet semi : lens = ins \";\"\nlet colon : lens = ins \":\"\nlet dot : lens = ins \".\" \nlet comma : lens = ins \",\" \nlet dash : lens = ins \"-\" \nlet nl : lens = ins NL\n\n(* [iter_with_sep l s] iterate lens [l] with separator [s] *)\nlet iter_with_sep (l:lens) (sep:lens) : lens = \n  l . (sep . l)*\n\n(* [iter_with_sqsp] iterate a lens with \"; \" as a separator. used\n   all over ASCII UniProtKB. *)\nlet iter_with_sqsp (l:lens) : lens = \n  iter_with_sep l (semi . qsp)\n\nlet qualifiers : lens = \n  ( \"by similarity\" <-> \" (By similarity)\"\n  | \"potential\"     <-> \" (Potential)\"    \n  | \"probable\"      <-> \" (Probable)\" )\n\n(* [date] and [partial_date] map between aphanumeric and numeric dates *)\nlet date,partial_date : lens * lens = \n  let DD : regexp = DIGIT{2} in \n  let MMM : lens = \n    ( \"01\" <-> \"JAN\" \n    | \"02\" <-> \"FEB\" \n    | \"03\" <-> \"MAR\" \n    | \"04\" <-> \"APR\" \n    | \"05\" <-> \"MAY\" \n    | \"06\" <-> \"JUN\" \n    | \"07\" <-> \"JUL\" \n    | \"08\" <-> \"AUG\" \n    | \"09\" <-> \"SEP\" \n    | \"10\" <-> \"OCT\" \n    | \"11\" <-> \"NOV\" \n    | \"12\" <-> \"DEC\" ) in       \n  let YYYY : regexp = DIGIT{4} in \n  let d : lens =  YYYY ~ ((\"-\" . MMM . \"-\") ~ DD) in \n  let pd : lens = YYYY ~ (del \"-\" . MMM . ins \"-\") in\n  (default d \"1900-01-01\", \n   default pd \"1900-01\")\n\n(* unit tests for date *)\nlet date_ascii : string = \"20-JAN-2009\" \nlet date_xml : string = \"2009-01-20\" \ntest date.get date_xml = date_ascii\ntest date.create date_ascii = date_xml\n\n(* unit tests for partial_date *)\nlet partial_ascii : string = \"JAN-2009\"\nlet partial_xml : string = \"2009-01\"\ntest partial_date.get partial_xml = partial_ascii\ntest partial_date.create partial_ascii = partial_xml\n\n(* --------------------------------------------------------------------------- *)\n(* ID line *)\n\ntest \"----- ID line-----\" = ?\n\n(* Notes: the ASCII representation of the ID line is dead simple, but\n   there are a few quirks that make generating it from the XML source\n   slightly tricky. First, the status of the entry--whether it is\n   SwissProt (\"Reviewed\") or TrEMBL (\"Unreviewed\") is actually\n   contained in the \"dataset\" attribute of the \"entry\" element. Since\n   there are only two possibilities, we handle this by parameterizing\n   the entire lens on a datatype and using types to determine which\n   branch we are in. Second, the sequence length is contained in the\n   \"length\" attribute of the \"sequence\" element, which appears at the\n   *end* of the entry. Thus, \"id_Xml.start\" lens actually only\n   generates the start of the ID line; the end of the line is\n   generated in the \"uniprot_entry\" lens using \"duplicate\" on the\n   \"sequence\" element, and a \"swap\" to pull it up to the top.\n*)\n\n(* [entry] representing kind of entry: SwissProt (human annotated) or\n   TrEMBL (computer generated). *)\ntype entry = SwissProt | TrEMBL\n\nlet id_tag : string = tag \"ID\"\n\nlet id_xml_start (ty:entry) : lens = \n  (* helpers *)\n  let EntryName : regexp = [A-Z0-9_]{1,12} in \n  let Status : lens = \n    ( match ty with \n    | SwissProt -> ins \"Reviewed\"\n    | TrEMBL    -> ins \"Unreviewed\") . \n    semi in \n  let SequenceLength : lens = \n    qins DIGIT+ \"000\" . qsp . \n    ins \"AA\" . \n    dot in \n  (* id_xml body *)\n  ins id_tag . \n  Xml.simple_elt NL1 \"name\" \n    begin \n      key EntryName . qsp . \n      Status . qsp \n    end\n\n(* unit tests for ID line *)\nlet P12544_id_ascii : string = \n  \"ID   GRAA_HUMAN              Reviewed; \" \n\nlet P12544_id_ascii_cn : string = \n  \"ID   GRAA_HUMAN Reviewed; \" \n\nlet P12544_id_xml : string = \n  NL . \"  <name>GRAA_HUMAN</name>\"\n\ntest (id_xml_start SwissProt).create \n  P12544_id_ascii = P12544_id_xml\n\ntest (id_xml_start SwissProt).get \n  P12544_id_xml = P12544_id_ascii_cn \n\n(* --------------------------------------------------------------------------- *)\n(* AC line *)\ntest \"----- AC line-----\" = ?\n\nlet ac_tag : string = tag \"AC\"\n\nlet ac_xml : lens =  \n  let AC_number : regexp = \n    ( [A-NR-Z] . DIGIT . UALPHACHAR . UALPHANUMCHAR{2} . DIGIT \n    | [OPQ]    . DIGIT . UALPHANUMCHAR{3}           . DIGIT ) in       \n  let ac_elt : lens = Xml.simple_elt NL1 \"accession\" AC_number in \n  ins ac_tag . \n  qspace . \n  iter_with_sqsp ac_elt . \n  semi\n\nlet ac_line : lens = split_terminate ac_tag ac_xml\n\n(* unit tests for AC line *)\nlet P12544_ac_ascii : string = \n  \"AC   P12544; Q6IB36;\" . NL\n\nlet P12544_ac_xml : string = \n  NL . \n  \"  <accession>P12544</accession>\n  |  <accession>Q6IB36</accession>\"\n\ntest ac_line.get \n  P12544_ac_xml = P12544_ac_ascii\n\ntest ac_line.create \n  P12544_ac_ascii = P12544_ac_xml\n\n(* --------------------------------------------------------------------------- *)\n(* DT line *)\ntest \"----- DT line-----\" = ?\n\nlet dt_tag : string = tag \"DT\" \n\nlet dt_lines (ty:entry) : lens =   \n  let dataset : lens = match ty with \n    | SwissProt -> \"Swiss-Prot\" \n    | TrEMBL -> \"TrEMBL\" in \n  ins dt_tag . \n  Xml.attr4_elt_open NL1 \"entry\" \n    \"created\" (date . comma . qsp . ins \"integrated into UniProtKB/\")\n    \"dataset\" (dataset . dot . ins NL)\n    \"modified\" (ins dt_tag . date . comma. qsp)\n    \"version\" (ins \"entry version\" . qsp . NUMBER . dot . ins NL)\n\n(* unit tests for DT lines *)\nlet P12544_dt_xml : string = \n  NL . \n  \"  <entry dataset=\\\"Swiss-Prot\\\" created=\\\"1989-10-01\\\" modified=\\\"2008-01-15\\\" version=\\\"101\\\">\"\n\nlet P12544_dt_xml_cn : string = \n  NL . \n  \"  <entry created=\\\"1989-10-01\\\" dataset=\\\"Swiss-Prot\\\" modified=\\\"2008-01-15\\\" version=\\\"101\\\">\"\n\nlet P12544_dt_xml : string = \n  NL . \n  \"  <entry dataset=\\\"Swiss-Prot\\\" created=\\\"1989-10-01\\\" modified=\\\"2008-01-15\\\" version=\\\"101\\\">\"\n\nlet P12544_dt_ascii : string = \n  \"DT   01-OCT-1989, integrated into UniProtKB/Swiss-Prot.\n  |DT   15-JAN-2008, entry version 101.\" . NL\n\ntest (dt_lines SwissProt).get \n  P12544_dt_xml = P12544_dt_ascii\n\ntest (dt_lines SwissProt).create \n  P12544_dt_ascii = P12544_dt_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* DE line *)\ntest \"----- DE line-----\" = ?\n\nlet de_tag : string = tag \"DE\" \n\nlet de_xml : lens = \n  let Description : lens = Xml.unesc_string [;()[\\]] in \n  let name (space:string) : lens =\n    Xml.raw_open space \"name\" . \n    ( (Xml.attr \"ref\" (qsp . brackets NUMBER))? ~ \n     (Xml.close . Description) ) . \n    Xml.simple_close_tag \"name\" in \n  let (name2,name3) : lens * lens = name NL2, name NL3 in \n  let names (tag:string) : lens = Xml.elt NL2 tag (name3 . (parens name3)* ) in \n  let (domain,component) : lens * lens = names \"domain\", names \"component\" in \n    ins de_tag .\n    Xml.elt NL1 \"protein\" \n      begin\n        name2 . (qsp . parens name2)* . \n        (qsp . brackets (ins \"Includes\" . colon . qsp . iter_with_sqsp domain))? . \n        (qsp . brackets (ins \"Contains\" . colon . qsp . iter_with_sqsp component))?\n      end . \n    dot\n\nlet de_line : lens = split_terminate de_tag de_xml\n\n(* unit tests for DE line *)\nlet P12544_de_ascii : string = \n  \"DE   Granzyme A precursor (EC 3.4.21.78) (Cytotoxic T-lymphocyte proteinase\n  |DE   1) (Hanukkah factor) (H factor) (HF) (Granzyme-1) (CTL tryptase)\n  |DE   (Fragmentin-1).\"\n\nlet P12544_de_ascii_actual : string = \n  \"DE   Granzyme A precursor [1] (Cytotoxic T-lymphocyte proteinase 1)\n  |DE   (Hanukkah factor) (H factor) (HF) (Granzyme-1) (CTL tryptase)\n  |DE   (Fragmentin-1).\" . \n  NL\n\nlet P12544_de_xml : string = \n  \"<protein>\n  |<name ref=\\\"1\\\">Granzyme A precursor</name>\n  |<name>Cytotoxic T-lymphocyte proteinase 1</name>\n  |<name>Hanukkah factor</name>\n  |<name>H factor</name>\n  |<name>HF</name>\n  |<name>Granzyme-1</name>\n  |<name>CTL tryptase</name>\n  |<name>Fragmentin-1</name>\n  |</protein>\" \n\nlet P12544_de_xml_cn : string = \n  NL . \n  \"  <protein>\n  |    <name ref=\\\"1\\\">Granzyme A precursor</name>\n  |    <name>Cytotoxic T-lymphocyte proteinase 1</name>\n  |    <name>Hanukkah factor</name>\n  |    <name>H factor</name>\n  |    <name>HF</name>\n  |    <name>Granzyme-1</name>\n  |    <name>CTL tryptase</name>\n  |    <name>Fragmentin-1</name>\n  |  </protein>\" \n\ntest de_line.get \n  P12544_de_xml = P12544_de_ascii_actual\n\ntest de_line.create \n  P12544_de_ascii_actual = P12544_de_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* GN line *)\ntest \"----- GN line-----\" = ?\n\nlet gn_tag : string = tag \"GN\"\n\nlet gn_xml : lens = \n  let gn_aux (ty:string) (f:lens -> lens) : lens = \n    Xml.attr1_simple_elt NL2 \"name\" \n      \"type\" (del ty) \n      (f esc_cs) in \n  let gn_primary : lens = \n    gn_aux \"primary\" (fun (l:lens) -> ins \"Name=\" . l) in \n  let gn_fst_syn : lens = \n    gn_aux \"synonym\" (fun (l:lens) -> ins \"Synonyms=\" . l) in \n  let gn_syn : lens = \n    gn_aux \"synonym\" (fun (l:lens) -> comma . space . l) in \n  let gn_fst_ordered_locus : lens = \n    gn_aux \"ordered locus\" (fun (l:lens) -> ins \"OrderedLocusNames=\" . l) in \n  let gn_ordered_locus : lens = \n    gn_aux  \"ordered locus\" (fun (l:lens) -> comma . space . l) in \n  let gn_fst_orf : lens = \n    gn_aux \"ORF\" (fun (l:lens) -> ins \"ORFNames=\" . l) in \n  let gn_orf : lens = \n    gn_aux \"ORF\" (fun (l:lens) -> comma . space . l) in \n  let gn_names : lens = \n    gn_primary . \n    (semi . space . gn_fst_syn . gn_syn* )? . \n    (semi . space . gn_fst_ordered_locus . gn_ordered_locus* )? .\n    (semi . space . gn_fst_orf . gn_orf* )? . \n    semi in \n  let gn_elt : lens = \n    ins gn_tag . \n    Xml.elt NL1 \"gene\" gn_names in \n  let gn_elt_line : lens = split gn_tag gn_elt in\n    gn_elt_line . \n    (ins \"\\n\" . ins gn_tag . ins \"and\\n\" . gn_elt_line)*\n\nlet gn_line : lens = terminate gn_xml \n\n(* unit tests for GN line *)\nlet P12544_gn_ascii : string = \n  \"GN   Name=GZMA; Synonyms=CTLA3, HFSP;\" . \n  NL\n\nlet P12544_gn_xml : string = \n  \"<gene>\n  |<name type=\\\"primary\\\">GZMA</name>\n  |<name type=\\\"synonym\\\">CTLA3</name>\n  |<name type=\\\"synonym\\\">HFSP</name>\n  |</gene>\"\n\nlet P12544_gn_xml_cn : string = \n  NL . \n  \"  <gene>\n  |    <name type=\\\"primary\\\">GZMA</name>\n  |    <name type=\\\"synonym\\\">CTLA3</name>\n  |    <name type=\\\"synonym\\\">HFSP</name>\n  |  </gene>\"\n\ntest gn_line.get\n  P12544_gn_xml = P12544_gn_ascii\n\ntest gn_line.create\n  P12544_gn_ascii = P12544_gn_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* OS line *)\ntest \"----- OS line-----\" = ?\n\n(* [names_xml sp] processes a sequence of name elements. It is also\n   used to format the OH line. *)\nlet names_xml (spaces:string) : lens = \n  let os_aux (ty:string) (f:lens -> lens) : lens = \n    Xml.attr1_simple_elt spaces \"name\" \n      \"type\" (del ty) \n      (f esc_csp) in \n  let scientific : lens = os_aux \"scientific\" (fun (l:lens) -> l) in \n  let common : lens = os_aux \"common\" (fun (l:lens) -> parens l) in \n  let synonym : lens = os_aux \"synonym\" (fun (l:lens) -> parens l) in \n    ( scientific \n    | scientific . space . common\n    | scientific . space . common . space . synonym+ )\n\nlet os_tag : string = tag \"OS\" \n\nlet os_xml : lens = \n  ins os_tag . \n    names_xml NL2 . \n    dot\n\nlet os_line : lens = split_terminate os_tag os_xml\n\n(* unit tests for OS line *)\nlet P12544_os_ascii : string = \n  \"OS   Homo sapiens (Human).\" . \n    NL\n\nlet P12544_os_xml : string = \n  \"<name type=\\\"scientific\\\">Homo sapiens</name>\n  |<name type=\\\"common\\\">Human</name>\"\n\nlet P12544_os_xml_cn : string = \n  NL . \n    \"    <name type=\\\"scientific\\\">Homo sapiens</name>\n  |    <name type=\\\"common\\\">Human</name>\"\n    \ntest os_line.get\n  P12544_os_xml = P12544_os_ascii\n\ntest os_line.create\n  P12544_os_ascii = P12544_os_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* OG line *)\ntest \"----- OG line-----\" = ?\n\nlet og_tag : string = tag \"OG\" \n\nlet og_xml : lens = \n  let og_plasmid : lens = \n    Xml.attr1_elt NL1 \"geneLocation\" \"type\" (del \"plasmid\") \n      (ins \"Plasmid\" . \n       qsp . \n       Xml.simple_elt NL2 \"name\" esc_c) in\n  let og_other : lens = \n    Xml.attr1_elt_no_kids NL1 \"geneLocation\" \"type\"   \n      ( \"hydrogenosome\" <-> \"Hydrogenosome\" \n      | \"mitochondrion\" <-> \"Mitochondrion\" \n      | \"nucleomorph\"   <-> \"Nucleomorph\"   \n      | \"plastid\"       <-> \"Plastid\"       \n      | \"apicoplast\"  <-> \"Plastid; Apicoplast\"  \n      | \"chloroplast\" <-> \"Plastid; Chloroplast\" \n      | \"cyanelle\"    <-> \"Plastid; Cyanelle\"    \n      | \"non-photosynthetic plastid\" <-> \"Plastid; Non-photosynthetic plastid\") in\n   ins og_tag . \n   ( og_plasmid . ((comma . space . og_plasmid)* . \n                   (comma . space . ins \"and\" . space . og_plasmid))?\n   | og_other) .       \n   dot\n\nlet og_line : lens = split_terminate og_tag og_xml\n\n(* unit tests for OG line *)\ntest og_line.create \n  ( \"OG   Plasmid R6-5, Plasmid IncFII R100 (NR1), and Plasmid IncFII R1-19 (R1\n    |OG   drd-19).\" .  \n    NL) \n= \n  ( NL . \n  \"  <geneLocation type=\\\"plasmid\\\">\n  |    <name>R6-5</name>\n  |  </geneLocation>\n  |  <geneLocation type=\\\"plasmid\\\">\n  |    <name>IncFII R100 (NR1)</name>\n  |  </geneLocation>\n  |  <geneLocation type=\\\"plasmid\\\">\n  |    <name>IncFII R1-19 (R1 drd-19)</name>\n  |  </geneLocation>\" )\n  \ntest og_line.get\n  \"<geneLocation type=\\\"non-photosynthetic plastid\\\"/>\" \n= \n  ( \"OG   Plastid; Non-photosynthetic plastid.\" . \n    NL )\n\n(* --------------------------------------------------------------------------- *)\n(* OC line *)\ntest \"----- OC line-----\" = ?\n\nlet oc_tag : string = tag \"OC\"\nlet oc_xml : lens = \n  let oc_aux : lens = Xml.simple_elt NL3 \"taxon\" esc_s in \n  ins oc_tag . \n  Xml.elt NL2 \"lineage\" (oc_aux . (semi . space . oc_aux)* ) . \n  dot\nlet oc_line : lens = split_terminate oc_tag oc_xml\n\n(* unit tests for OC line *)\nlet P12544_oc_ascii : string = \n  \"OC   Eukaryota; Metazoa; Chordata; Craniata; Vertebrata; Euteleostomi;\n  |OC   Mammalia; Eutheria; Euarchontoglires; Primates; Haplorrhini;\n  |OC   Catarrhini; Hominidae; Homo.\" . \n  NL\n\nlet P12544_oc_xml : string = \n  \"<lineage>\n  |<taxon>Eukaryota</taxon>\n  |<taxon>Metazoa</taxon>\n  |<taxon>Chordata</taxon>\n  |<taxon>Craniata</taxon>\n  |<taxon>Vertebrata</taxon>\n  |<taxon>Euteleostomi</taxon>\n  |<taxon>Mammalia</taxon>\n  |<taxon>Eutheria</taxon>\n  |<taxon>Euarchontoglires</taxon>\n  |<taxon>Primates</taxon>\n  |<taxon>Haplorrhini</taxon>\n  |<taxon>Catarrhini</taxon>\n  |<taxon>Hominidae</taxon>\n  |<taxon>Homo</taxon>\n  |</lineage>\"\n\nlet P12544_oc_xml_cn : string = \n  NL . \n  \"    <lineage>\n  |      <taxon>Eukaryota</taxon>\n  |      <taxon>Metazoa</taxon>\n  |      <taxon>Chordata</taxon>\n  |      <taxon>Craniata</taxon>\n  |      <taxon>Vertebrata</taxon>\n  |      <taxon>Euteleostomi</taxon>\n  |      <taxon>Mammalia</taxon>\n  |      <taxon>Eutheria</taxon>\n  |      <taxon>Euarchontoglires</taxon>\n  |      <taxon>Primates</taxon>\n  |      <taxon>Haplorrhini</taxon>\n  |      <taxon>Catarrhini</taxon>\n  |      <taxon>Hominidae</taxon>\n  |      <taxon>Homo</taxon>\n  |    </lineage>\"\n\ntest oc_line.get \n  P12544_oc_xml = P12544_oc_ascii\n\ntest oc_line.create \n  P12544_oc_ascii = P12544_oc_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* OX line *)\ntest \"----- OX line-----\" = ?\n\n(* [ncbi_xml sp] processes a \"dbReference\" element. It is also used to\n   format the OH line. *)\nlet ncbi_xml (spaces:string) : lens = \n  ins \"NCBI_TaxID=\" . \n  ( Xml.attr3_elt_no_kids spaces \"dbReference\"\n     \"type\" (del \"NCBI Taxonomy\")\n     \"key\" (del NUMBER)          \n     \"id\" (NUMBER) ) . \n  semi\n\nlet ox_tag : string = tag \"OX\"\n\nlet ox_xml : lens = \n  ins ox_tag . \n  ncbi_xml NL2\n\nlet ox_line : lens = split_terminate ox_tag ox_xml\n\n(* unit tests for OX line *)\nlet P12544_ox_ascii : string = \n  \"OX   NCBI_TaxID=9606;\" . \n  NL\n\nlet P12544_ox_xml : string = \n  \"<dbReference type=\\\"NCBI Taxonomy\\\" id=\\\"9606\\\" key=\\\"3\\\" />\"\n\nlet P12544_ox_xml_cn : string = \n  NL . \n  \"    <dbReference type=\\\"NCBI Taxonomy\\\" key=\\\"0\\\" id=\\\"9606\\\"/>\"\n\ntest ox_line.get \n  P12544_ox_xml = P12544_ox_ascii \n\ntest ox_line.create \n  P12544_ox_ascii = P12544_ox_xml_cn \n\n(* --------------------------------------------------------------------------- *)\n(* OH line *)\ntest \"----- OH line-----\" = ?\n\nlet oh_tag : string = tag \"OH\"\n\nlet oh_xml : lens =\n  ins oh_tag . \n  Xml.attr1_elt NL1 \"organism\" \"key\" (del NUMBER) \n  (names_xml NL2 ~ (ncbi_xml NL2 . qsp)) . \n  dot \n\nlet oh_line : lens = split_terminate oh_tag oh_xml\n\n(* unit tests for OH line *)\ntest oh_line.create\n  \"OH   NCBI_TaxID=9481; Callithrix.\n  |\" \n= \n  \"\n  |  <organism key=\\\"0\\\">\n  |    <name type=\\\"scientific\\\">Callithrix</name>\n  |    <dbReference type=\\\"NCBI Taxonomy\\\" key=\\\"0\\\" id=\\\"9481\\\"/>\n  |  </organism>\"\n\ntest oh_line.get \n  \"<organism key=\\\"0\\\">\n  |  <name type=\\\"scientific\\\">Callithrix</name>\n  |  <dbReference type=\\\"NCBI Taxonomy\\\" key=\\\"1\\\" id=\\\"9481\\\"/>\n  |</organism>\" \n= \n  \"OH   NCBI_TaxID=9481; Callithrix.\n  |\"\n\n(* --------------------------------------------------------------------------- *)\n(* Organism block *)\n\nlet organism_block = \n  Xml.attr1_elt_open NL1 \"organism\" \"key\" (del NUMBER) . \n  os_line . \n  (((ox_line ~ oc_line) . \n   Xml.close_tag NL1 \"organism\" . \n   oh_line* ) ~\n  og_line)\n\n(* unit tests for Organism block *)\nlet organism_block_xml : string = \n  NL . \n  \"  <organism key=\\\"0\\\">\n  |    <name type=\\\"scientific\\\">Solanum melongena</name>\n  |    <name type=\\\"common\\\">Eggplant</name>\n  |    <name type=\\\"synonym\\\">Aubergine</name>\n  |    <dbReference type=\\\"NCBI Taxonomy\\\" key=\\\"0\\\" id=\\\"9606\\\"/>\n  |    <lineage>\n  |      <taxon>Mammalia</taxon>\n  |      <taxon>Eutheria</taxon>\n  |    </lineage>\n  |  </organism>\n  |  <organism key=\\\"0\\\">\n  |    <name type=\\\"scientific\\\">Callithrix</name>\n  |    <dbReference type=\\\"NCBI Taxonomy\\\" key=\\\"0\\\" id=\\\"9481\\\"/>\n  |  </organism>\n  |  <organism key=\\\"0\\\">\n  |    <name type=\\\"scientific\\\">Cercopithecus hamlyni</name>\n  |    <name type=\\\"common\\\">Owl-faced monkey</name>\n  |    <name type=\\\"synonym\\\">Hamlyn's monkey</name>\n  |    <dbReference type=\\\"NCBI Taxonomy\\\" key=\\\"0\\\" id=\\\"9536\\\"/>\n  |  </organism>\n  |  <geneLocation type=\\\"apicoplast\\\"/>\"\n\nlet organism_block_ascii : string = \n  \"OS   Solanum melongena (Eggplant) (Aubergine).\n  |OG   Plastid; Apicoplast.\n  |OC   Mammalia; Eutheria.\n  |OX   NCBI_TaxID=9606;\n  |OH   NCBI_TaxID=9481; Callithrix.\n  |OH   NCBI_TaxID=9536; Cercopithecus hamlyni (Owl-faced monkey) (Hamlyn's\n  |OH   monkey).\" . \n  NL \n\ntest organism_block.get \n  organism_block_xml = organism_block_ascii\n\ntest organism_block.create \n  organism_block_ascii = organism_block_xml\n\n(* --------------------------------------------------------------------------- *)\n(* RN line *)\ntest \"----- RN line-----\" = ?\n\nlet rn_tag : string = tag \"RN\" \n\nlet rn_xml : lens = \n  ins rn_tag . \n    Xml.attr1_elt_open NL1 \"reference\" \"key\" (brackets NUMBER) \n\nlet rn_line : lens = \n  terminate rn_xml\n\n(* unit tests for RN line *)\ntest rn_line.create \n  \"RN   [1]\n  |\" \n= \n  \"\n  |  <reference key=\\\"1\\\">\" \n\ntest rn_line.get \n  \"  <reference key=\\\"1\\\">\" \n= \n  ( \"RN   [1]\" . \n    NL )\n\n(* --------------------------------------------------------------------------- *)\n(* RP line *)\ntest \"----- RP line-----\" = ?\n\nlet rp_tag : string = tag \"RP\"\n\nlet rp_xml : lens = \n  ins rp_tag . \n  Xml.simple_elt NL2 \"scope\" esc . \n  dot\n\nlet rp_line : lens =  split_terminate rp_tag rp_xml\n\n(* unit tests for RP line *)\ntest rp_line.create \n  \"RP   NUCLEOTIDE SEQUENCE [GENOMIC DNA].\n  |\" \n= \n  \"\n  |    <scope>NUCLEOTIDE SEQUENCE [GENOMIC DNA]</scope>\"\n\ntest rp_line.get \n  \"<scope>NUCLEOTIDE SEQUENCE [GENOMIC DNA]</scope>\"\n=\n  \"RP   NUCLEOTIDE SEQUENCE [GENOMIC DNA].\n  |\" \n\n(* --------------------------------------------------------------------------- *)\n(* RC line *)\ntest \"----- RC line-----\" = ?\n\nlet rc_tag : string = tag \"RC\"\n\nlet rc_xml : lens = \n  let rx_aux (xml:string) (ascii:string) : lens = \n    let l : lens = Xml.simple_elt NL3 xml esc_cs in \n    ins ascii . ins \"=\" . \n    l . \n    (( comma . space . l)* . \n     ( comma . space . ins \"and\" . space . l))? . \n    semi in \n  let strain : lens =  rx_aux \"strain\" \"STRAIN\" in \n  let tissue : lens =  rx_aux \"tissue\" \"TISSUE\" in \n  let plasmid : lens =  rx_aux \"plasmid\" \"PLASMID\" in \n  let transposon : lens =  rx_aux \"transposon\" \"TRANSPSON\" in \n  let final_plasmid : lens = (strain . qsp)? . plasmid in \n  let final_transposon : lens = ((strain | final_plasmid) . qsp)? . transposon in \n  let final_tissue : lens = ((strain | final_plasmid | final_transposon) . qsp)? . tissue in \n  let all = strain | final_tissue | final_plasmid | final_transposon in \n  ins rc_tag . \n  Xml.elt NL2 \"source\" all \n\nlet rc_line : lens = split_terminate rc_tag rc_xml\n\n(* unit tests for RC line *)\ntest rc_line.create \n  \"RC   STRAIN=AL.012, AZ.026, AZ.180, DC.005, GA.039, GA2181, IL.014, and IL2.17;\n  |\" \n= \n  \"\n  |    <source>\n  |      <strain>AL.012</strain>\n  |      <strain>AZ.026</strain>\n  |      <strain>AZ.180</strain>\n  |      <strain>DC.005</strain>\n  |      <strain>GA.039</strain>\n  |      <strain>GA2181</strain>\n  |      <strain>IL.014</strain>\n  |      <strain>IL2.17</strain>\n  |    </source>\"\n\ntest rc_line.get\n  \"      <source>\n  |        <plasmid>R1 (R7268)</plasmid>\n  |        <transposon>Tn3</transposon>\n  |      </source>\" \n= \n  \"RC   PLASMID=R1 (R7268); TRANSPSON=Tn3;\n  |\" \n\n(* --------------------------------------------------------------------------- *)\n(* RX line *)\ntest \"----- RX line-----\" = ?\n\nlet rx_tag : string = tag \"RX\"\n\nlet rx_xml : lens = \n  let rx_aux (db:string) : lens = \n    let l : lens = Xml.slow_attr3_elt_no_kids NL3 \"dbReference\" \n      \"type\" (db . ins \"=\")\n      \"key\" (del NUMBER) \n      \"id\" esc_s in \n    l . semi in\n  let any_ref = (rx_aux \"MEDLINE\" | rx_aux \"PubMed\" | rx_aux \"DOI\") in \n  ins rx_tag . \n  any_ref . (space . any_ref)*\n\nlet rx_line : lens = split_terminate rx_tag rx_xml\n\n(* unit tests for RX line *)\nlet P12544_rx_ascii : string = \n  \"RX   MEDLINE=88125000; PubMed=3257574;\" . NL\n\nlet P12544_rx_xml : string = \n  \"<dbReference type=\\\"MEDLINE\\\" id=\\\"88125000\\\" key=\\\"5\\\" />\n  |<dbReference type=\\\"PubMed\\\" id=\\\"3257574\\\" key=\\\"6\\\" />\"\n\nlet P12544_rx_xml_cn : string = \n  NL . \n  \"      <dbReference type=\\\"MEDLINE\\\" key=\\\"0\\\" id=\\\"88125000\\\"/>\n  |      <dbReference type=\\\"PubMed\\\" key=\\\"0\\\" id=\\\"3257574\\\"/>\"\n\ntest rx_line.get\n  P12544_rx_xml = P12544_rx_ascii\n\ntest rx_line.create \n  P12544_rx_ascii = P12544_rx_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* RG line *)\ntest \"----- RG line-----\" = ?\n\nlet rg_tag : string = tag \"RG\" \n\nlet rg_xml : lens = \n  ins rg_tag . \n  Xml.attr1_elt_no_kids NL4 \"consortium\" \"name\" esc_s .\n  semi\n\nlet rg_line : lens = split_terminate rg_tag rg_xml\n\n(* unit tests for RG line *)\nlet P12544_rg_ascii : string =  \n  \"RG   The MGC Project Team;\" . \n  NL\n\nlet P12544_rg_xml : string = \n  \"<consortium name=\\\"The MGC Project Team\\\" />\"\n\nlet P12544_rg_xml_cn : string = \n  NL4 . \n  \"<consortium name=\\\"The MGC Project Team\\\"/>\"\n\ntest rg_line.get\n  P12544_rg_xml = P12544_rg_ascii\n\ntest rg_line.create \n  P12544_rg_ascii = P12544_rg_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* RA line *)\ntest \"-----RA line-----\" = ?\n\nlet person (spaces:string) : lens = \n  Xml.attr1_elt_no_kids spaces \"person\" \"name\" esc_cs\n\nlet ra_tag : string = tag \"RA\" \n\nlet ra_xml : lens = \n  ins ra_tag . \n  iter_with_sep (person NL4) (comma . space) . \n  semi\n\nlet ra_line : lens = split_terminate ra_tag ra_xml\n\n(* unit tests for RA line *)\nlet P12544_ra_ascii : string = \n  \"RA   Gershenfeld H.K., Hershberger R.J., Shows T.B., Weissman I.L.;\" . \n  NL\n\nlet P12544_ra_xml : string = \n  \"<person name=\\\"Gershenfeld H.K.\\\" />\n  |<person name=\\\"Hershberger R.J.\\\" />\n  |<person name=\\\"Shows T.B.\\\" />\n  |<person name=\\\"Weissman I.L.\\\" />\"\n\nlet P12544_ra_xml_cn : string = \n  NL . \n  \"        <person name=\\\"Gershenfeld H.K.\\\"/>\n  |        <person name=\\\"Hershberger R.J.\\\"/>\n  |        <person name=\\\"Shows T.B.\\\"/>\n  |        <person name=\\\"Weissman I.L.\\\"/>\"\n\ntest ra_line.get\n  P12544_ra_xml = P12544_ra_ascii\n\ntest ra_line.create \n  P12544_ra_ascii = P12544_ra_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* RT line *)\ntest \"----- RT line-----\" = ?\n\nlet rt_tag : string = tag \"RT\" \n\nlet rt_xml : lens = \n  ins rt_tag . \n  Xml.simple_elt NL3 \"title\" (quotes (esc . [.!?])) . \n  semi \n\nlet rt_line : lens = split_terminate rt_tag rt_xml\n\n(* unit tests for RT line *)\nlet P12544_rt_ascii : string = \n  \"RT   \\\"Cloning and chromosomal assignment of a human cDNA encoding a T cell-\n  |RT   and natural killer cell-specific trypsin-like serine protease.\\\";\" . \n  NL \n\nlet P12544_rt_xml : string = \n  \"<title>Cloning and chromosomal assignment of a human cDNA encoding a T cell- \" . \n  \"and natural killer cell-specific trypsin-like serine protease.</title>\"\n  \ntest rt_line.get\n  P12544_rt_xml = P12544_rt_ascii\n\ntest rt_line.create\n  P12544_rt_ascii = ( NL3 . P12544_rt_xml )\n\n(* --------------------------------------------------------------------------- *)\n(* RL line *)\ntest \"----- RL line-----\" = ?\n\nlet rl_tag : string = tag \"RL\"\n\n(* journal citations *)\nlet journal_xml : lens = \n  ins rl_tag . \n  Xml.attrs_open NL2 \"citation\" \n    begin\n      (* this sorting is fragile: some interleavings of the abstract\n         schemas are not unambiguous (due to two-pass sorting in\n         swap4). This makes some assumptions--e.g., that volume,\n         first, last are grouped together--that seem reasonable. *)\n      Xml.attr \"type\" (del \"journal article\") . \n        Sort.sort_concat #{lens}[(Xml.attr \"name\" (esc_qp . space));\n\t\t\t\t ((Xml.attr \"volume\" (NUMBER . colon)) . \n\t\t\t\t    (Xml.attr \"first\" (NUMBER . dash)) . \n\t\t\t\t    (Xml.attr \"last\" (NUMBER)));\n\t\t\t\t (Xml.attr \"date\" (parens NUMBER))]\n    end . \n    dot \n\nlet journal_line : lens = split_terminate rl_tag journal_xml\n\n(* unit tests for journal citations *)\ntest journal_line.get \n  \"<citation type=\\\"journal article\\\" date=\\\"2005\\\" name=\\\"Science\\\" volume=\\\"309\\\" first=\\\"131\\\" last=\\\"133\\\">\" \n  =\n  ( \"RL   Science 309:131-133(2005).\" . \n    NL )\n\nlet P12544_journal_ascii : string = \n  \"RL   Proc. Natl. Acad. Sci. U.S.A. 85:1184-1188(1988).\" . \n   NL \n\nlet P12544_journal_xml : string = \n  \"<citation type=\\\"journal article\\\" date=\\\"1988\\\"\" . \n  \" name=\\\"Proc. Natl. Acad. Sci. U.S.A.\\\"\" . \n  \" volume=\\\"85\\\" first=\\\"1184\\\" last=\\\"1188\\\">\"\n\nlet P12544_journal_xml_cn : string = \n  \"<citation type=\\\"journal article\\\" name=\\\"Proc. Natl. Acad. Sci. U.S.A.\\\"\" . \n  \" volume=\\\"85\\\" first=\\\"1184\\\" last=\\\"1188\\\" date=\\\"1988\\\">\"\n\ntest journal_line.get\n  P12544_journal_xml = P12544_journal_ascii \n\ntest journal_line.create\n  P12544_journal_ascii = ( NL2 . P12544_journal_xml_cn )\n\n(* electronic citations *)\nlet electronic_xml : lens = \n  ins rl_tag . \n  Xml.slow_attr2_elt_open NL2 \"citation\"\n    \"type\" ((\"online journal article\" <-> \"(er)\" ) . space)\n    \"name\" esc_q . \n  dot\n\nlet electronic_line : lens = split_terminate rl_tag electronic_xml\n\n(* unit tests for electronic citations *)\ntest electronic_line.get\n  \"<citation type=\\\"online journal article\\\" name=\\\"Plant Gene Register PGR98-023\\\">\" \n= \n  ( \"RL   (er) Plant Gene Register PGR98-023.\" . \n    NL )\n\ntest electronic_line.create \n  (\"RL   (er) Plant Gene Register PGR98-023.\" . NL) \n= \n  ( NL2 . \n    \"<citation type=\\\"online journal article\\\" name=\\\"Plant Gene Register PGR98-023\\\">\" )\n\n(* editor list citations *)\nlet editors_xml : lens = \n  ins \"(In)\" . space . \n  Xml.elt NL3 \"editorList\"\n    begin \n      iter_with_sep (person NL4) (comma . space)     \n    end . \n  space . \n  ins \"(eds.)\" . \n  semi \n\n(* unit tests for editor lists *)\ntest editors_xml.get \n\"<editorList>\n|<person name=\\\"Rich D.H.\\\"/>\n|<person name=\\\"Gross E.\\\"/>\n|</editorList>\"\n=\n\"(In) Rich D.H., Gross E. (eds.);\" \n\ntest editors_xml.create \n \"(In) Rich D.H., Gross E. (eds.);\" \n=\n  ( NL .\n \"      <editorList>\n |        <person name=\\\"Rich D.H.\\\"/>\n |        <person name=\\\"Gross E.\\\"/>\n |      </editorList>\" )\n\n\n(* book citations *)\nlet book_xml : lens = \n  ins rl_tag . \n  ( (Xml.attrs_open NL2 \"citation\" \n      begin \n        Xml.attr \"type\" (del \"book\") . \n        Xml.attr \"name\" (esc_cq . comma . space) . \n        (Xml.attr \"volume\" (NUMBER . colon))? . \n        Xml.attr \"first\" (ins \"pp.\" . NUMBER . dash) . \n        Xml.attr \"last\" (NUMBER . comma . space) . \n        Xml.attr \"publisher\" (esc_cq . comma . space) . \n        Xml.attr \"city\" (esc_cq . space) . \n        Xml.attr \"date\" (parens NUMBER)\n      end . \n    dot) ~\n    (editors_xml . space) ) \n\nlet book_line : lens = split_terminate rl_tag book_xml\n\n(* unit tests for book citation *)\ntest book_line.get\n  \"<citation type=\\\"book\\\" name=\\\"Proceedings of the 7th American peptide symposium\\\" first=\\\"69\\\" last=\\\"72\\\" publisher=\\\"Pierce Chemical Co.\\\" city=\\\"Rockford Il.\\\" date=\\\"1981\\\">\n  |<editorList>\n  |<person name=\\\"Rich D.H.\\\"/>\n  |<person name=\\\"Gross E.\\\"/>\n  |</editorList>\"\n= \n  ( \"RL   (In) Rich D.H., Gross E. (eds.); Proceedings of the 7th American\n    |RL   peptide symposium, pp.69-72, Pierce Chemical Co., Rockford Il. (1981).\" . \n    NL )\n\ntest book_line.create\n  (\"RL   (In) Rich D.H., Gross E. (eds.); Proceedings of the 7th American peptide symposium,\" . \n  \" pp.69-72, Pierce Chemical Co., Rockford Il. (1981).\" . \n  NL)\n=\n  ( NL . \n    \"    <citation type=\\\"book\\\" name=\\\"Proceedings of the 7th American peptide symposium\\\" first=\\\"69\\\" last=\\\"72\\\" publisher=\\\"Pierce Chemical Co.\\\" city=\\\"Rockford Il.\\\" date=\\\"1981\\\">\n    |      <editorList>\n    |        <person name=\\\"Rich D.H.\\\"/>\n    |        <person name=\\\"Gross E.\\\"/>\n    |      </editorList>\" )\n\n(* unpublished citations *)\nlet unpublished_xml : lens = \n  ins rl_tag . \n  ins \"Unpublished observations\" . space . \n  Xml.slow_attr2_elt_no_kids NL2 \"citation\" \n    \"type\" (del \"unpulished observations\") \n    \"date\" (parens partial_date) . \n  dot \n\nlet unpublished_line : lens = split_terminate rl_tag unpublished_xml\n\n(* unit tests for unpublished citations *)\ntest unpublished_line.create \n  (\"RL   Unpublished observations (JAN-2009).\" . \n   NL)\n= \n  ( NL . \n    \"    <citation type=\\\"unpulished observations\\\" date=\\\"2009-01\\\"/>\" )\n\ntest unpublished_line.get \n  \"<citation type=\\\"unpulished observations\\\" date=\\\"2009-01\\\"/>\"\n=\n  ( \"RL   Unpublished observations (JAN-2009).\" . \n    NL )\n\n(* thesis citations *)\nlet thesis_xml : lens = \n  ins rl_tag . \n  Xml.slow_attr4_elt_no_kids NL2 \"citation\"\n    \"type\" ((\"thesis\" <-> \"Thesis\") . space) \n    \"date\" (parens esc_cdq . comma . space) \n    \"institute\" (esc_cdq . comma . space)\n    \"country\" (esc_cdq . dot) \n\nlet thesis_line : lens = split_terminate rl_tag thesis_xml\n\n(* unit tests for thesis citations *)\ntest thesis_line.get \n  \"<citation type=\\\"thesis\\\" date=\\\"1977\\\" institute=\\\"University of Geneva\\\" country=\\\"Switzerland\\\"/>\"\n=\n  ( \"RL   Thesis (1977), University of Geneva, Switzerland.\" . \n  NL )\n\ntest thesis_line.create \n  (\"RL   Thesis (1977), University of Geneva, Switzerland.\" . \n   NL)\n= \n  ( NL . \n    \"    <citation type=\\\"thesis\\\" date=\\\"1977\\\" institute=\\\"University of Geneva\\\" country=\\\"Switzerland\\\"/>\" )\n\n(* patent citations *)\nlet patent_xml : lens = \n  ins rl_tag . \n  Xml.slow_attr3_elt_no_kids NL2 \"citation\"\n    \"type\" ((\"patent\" <-> \"Patent number\") . space)\n    \"number\" (esc_q . comma . space)\n    \"date\" date . \n  dot\n\nlet patent_line : lens = split_terminate rl_tag patent_xml\n\n(* unit tests for patent citations *)\ntest patent_line.get\n  \"<citation type=\\\"patent\\\" number=\\\"WO9010703\\\" date=\\\"1990-09-20\\\"/>\"\n=\n  ( \"RL   Patent number WO9010703, 20-SEP-1990.\" . \n    NL )\n\ntest patent_line.create\n  (\"RL   Patent number WO9010703, 20-SEP-1990.\" . \n   NL)\n= \n  ( NL2 . \n    \"<citation type=\\\"patent\\\" number=\\\"WO9010703\\\" date=\\\"1990-09-20\\\"/>\" )\n\n(* submitted citations *)\nlet submitted_xml : lens = \n  ins rl_tag . \n  Xml.slow_attr3_elt_open NL2 \"citation\" \n     \"type\" ((\"submission\" <-> \"Submitted\") . space) \n     \"date\" (parens partial_date . space . ins \"to\" . space) \n     \"db\"   ( ins \"the \" . \"EMBL/GenBank/DDBJ databases\"\n            | \"UniProtKB\"\n            | ins \"the \" . \"PDB data bank\"\n            | ins \"the \" . \"PIR data bank\" ) . \n  dot\n\nlet submitted_line : lens = split_terminate rl_tag submitted_xml\n\n(* unit tests for submitted citations *)\nlet P12544_submitted_ascii : string = \n  \"RL   Submitted (JUN-2004) to the EMBL/GenBank/DDBJ databases.\" . \n  NL\n\nlet P12544_submitted_xml : string = \n  \"<citation type=\\\"submission\\\" date=\\\"2004-06\\\" db=\\\"EMBL/GenBank/DDBJ databases\\\">\"\n\ntest submitted_line.get\n  P12544_submitted_xml = P12544_submitted_ascii\n\ntest submitted_line.create\n  P12544_submitted_ascii = ( NL2 . P12544_submitted_xml )\n\ntest submitted_line.create \n  (\"RL   Submitted (OCT-1995) to the EMBL/GenBank/DDBJ databases.\" . \n  NL)\n= \n  ( NL2 . \n    \"<citation type=\\\"submission\\\" date=\\\"1995-10\\\" db=\\\"EMBL/GenBank/DDBJ databases\\\">\" )\n\n(* RL line final assembly *)\n\nlet rl_line : lens = \n  ( journal_line | electronic_line | book_line | unpublished_line | thesis_line \n  | submitted_line)\n\n(* --------------------------------------------------------------------------- *)\n(* Reference block *)\n\nlet rp_rc_rx_block : lens = \n  (rx_line? . Xml.close_tag NL2 \"citation\") ~ \n  ( rp_line . rc_line? )\n\nlet rg_ra_block : lens = \n  Xml.elt NL3 \"authorList\" \n    ( rg_line\n    | ra_line . \n      rg_line? )\n\nlet rg_ra_rt_block : lens = \n  rt_line? ~ rg_ra_block \n\nlet reference_block : lens = \n  rn_line . \n  ( (rl_line ~ rg_ra_rt_block) ~ \n    rp_rc_rx_block ) . \n  Xml.close_tag NL1 \"reference\"\n\n(* unit tests for reference block *)\nlet P12544_reference_ascii : string = \n  \"RN   [3]\n  |RP   NUCLEOTIDE SEQUENCE [LARGE SCALE MRNA].\n  |RC   TISSUE=Blood;\n  |RX   PubMed=15489334; DOI=10.1101/gr.2596504;\n  |RG   The MGC Project Team;\n  |RT   \\\"The status, quality, and expansion of the NIH full-length cDNA\n  |RT   project: the Mammalian Gene Collection (MGC).\\\";\n  |RL   Genome Res. 14:2121-2127(2004).\" . \n  NL\n\n(* deviates from version found on beta.uniprot.org: reference number\n   [8] vs [3], and order of entries in RX field. *)\nlet P12544_reference_ascii_actual : string = \n  \"RN   [8]\n  |RP   NUCLEOTIDE SEQUENCE [LARGE SCALE MRNA].\n  |RC   TISSUE=Blood;\n  |RX   DOI=10.1101/gr.2596504; PubMed=15489334;\n  |RG   The MGC Project Team;\n  |RT   \\\"The status, quality, and expansion of the NIH full-length cDNA\n  |RT   project: the Mammalian Gene Collection (MGC).\\\";\n  |RL   Genome Res. 14:2121-2127(2004).\" . \n    NL\n\nlet P12544_reference_xml : string = \n  \"<reference key=\\\"8\\\">\n  |<citation type=\\\"journal article\\\" date=\\\"2004\\\" name=\\\"Genome Res.\\\" volume=\\\"14\\\" first=\\\"2121\\\" last=\\\"2127\\\">\n  |<title>The status, quality, and expansion of the NIH full-length cDNA project: the Mammalian Gene Collection (MGC).</title>\n  |<authorList>\n  |<consortium name=\\\"The MGC Project Team\\\" />\n  |</authorList>\n  |<dbReference type=\\\"DOI\\\" id=\\\"10.1101/gr.2596504\\\" key=\\\"9\\\" />\n  |<dbReference type=\\\"PubMed\\\" id=\\\"15489334\\\" key=\\\"10\\\" />\n  |</citation>\n  |<scope>NUCLEOTIDE SEQUENCE [LARGE SCALE MRNA]</scope>\n  |<source>\n  |<tissue>Blood</tissue>\n  |</source>\n  |</reference>\"\n\nlet P12544_reference_xml_cn : string = \n  NL . \n  \"  <reference key=\\\"8\\\">\n  |    <citation type=\\\"journal article\\\" name=\\\"Genome Res.\\\" volume=\\\"14\\\" first=\\\"2121\\\" last=\\\"2127\\\" date=\\\"2004\\\">\n  |      <title>The status, quality, and expansion of the NIH full-length cDNA project: the Mammalian Gene Collection (MGC).</title>\n  |      <authorList>\n  |        <consortium name=\\\"The MGC Project Team\\\"/>\n  |      </authorList>\n  |      <dbReference type=\\\"DOI\\\" key=\\\"0\\\" id=\\\"10.1101/gr.2596504\\\"/>\n  |      <dbReference type=\\\"PubMed\\\" key=\\\"0\\\" id=\\\"15489334\\\"/>\n  |    </citation>\n  |    <scope>NUCLEOTIDE SEQUENCE [LARGE SCALE MRNA]</scope>\n  |    <source>\n  |      <tissue>Blood</tissue>\n  |    </source>\n  |  </reference>\"\n\ntest reference_block.get \n  P12544_reference_xml = P12544_reference_ascii_actual\n\ntest reference_block.create \n  P12544_reference_ascii_actual = P12544_reference_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* CC line *)\ntest \"----- CC line-----\" = ?\n\nlet cc_tag : string = tag \"CC\" \nlet cc_bang : string = \"-!- \" \nlet cc_long_tag : string = cc_tag . \"    \"\nlet cc_fix (l:lens) : lens = \n  split (cc_long_tag . \"  \") l\n\nlet cc_fix70 (l:lens) : lens = \n  split70 (cc_long_tag . \"  \") l\n\nlet cc_status : lens = Xml.attr \"status\" qualifiers\n\nlet cc_generic_xml (ty:lens) : lens = \n  let typ : lens = Xml.attr \"type\" ty in \n  let data_no_dot : lens = Xml.unesc_string_ends [\"\"] [.] in \n  let data_dot : lens = esc_q . \".\" in \n  let txt (d:lens) : lens = colon . space . Xml.simple_elt NL2 \"text\" d in \n  ins cc_tag . ins cc_bang . \n  Xml.raw_open NL1 \"comment\" . \n  ( typ . ( (cc_status . Xml.close) ~ (txt data_no_dot) ) . dot \n  || ( cc_status ~ (typ . Xml.close . txt data_no_dot) ) . dot  \n  || typ . Xml.close . txt (data_dot | data_no_dot) ) . \n  Xml.close_tag NL1 \"comment\" \n\n(* CC unstructured lines *)\ntest \"----- CC unstructured lines-----\" = ?\nlet cc_unstructured_xml : lens = \n  cc_generic_xml\n    ( \"allergen\"             <-> \"ALLERGEN\"\n    | \"biotechnology\"        <-> \"BIOTECHNOLOGY\"       \n    | \"catalytic activity\"   <-> \"CATALYTIC ACTIVITY\"  \n    | \"cofactor\"             <-> \"COFACTOR\"            \n    | \"developmental stage\"  <-> \"DEVELOPMENTAL STAGE\" \n    | \"disease\"              <-> \"DISEASE\"             \n    | \"domain\"               <-> \"DOMAIN\"              \n    | \"enzyme regulation\"    <-> \"ENZYME REGULATION\"   \n    | \"function\"             <-> \"FUNCTION\"            \n    | \"induction\"            <-> \"INDUCTION\"           \n    | \"miscellaneous\"        <-> \"MISCELLANEOUS\"       \n    | \"pathway\"              <-> \"PATHWAY\"             \n    | \"pharmaceutical\"       <-> \"PHARMACEUTICAL\"      \n    | \"polymorphism\"         <-> \"POLYMORPHISM\"        \n    | \"PTM\"                  <-> \"PTM\"                 \n    | \"RNA editing\"          <-> \"RNA EDITING\"         \n    | \"similarity\"           <-> \"SIMILARITY\"          \n    | \"subcellular location\" <-> \"SUBCELLULAR LOCATION\"\n    | \"subunit\"              <-> \"SUBUNIT\"             \n    | \"tissue specificity\"   <-> \"TISSUE SPECIFICITY\"  \n    | \"toxic dose\"           <-> \"TOXIC DOSE\" )\n\nlet cc_unstructured_line : lens = \n  split_terminate cc_long_tag cc_unstructured_xml\n\n(* unit tests for CC unstructured lines *)\ntest cc_unstructured_line.create \n  (\"CC   -!- ALLERGEN: Causes an allergic reaction in humans. Binds to IgE.\n   |CC       Partially heat-labile allergen that may cause both respiratory and\n   |CC       food-allergy symptoms in patients with the bird-egg syndrome.\" . \n   NL) = \n  \"\n  |  <comment type=\\\"allergen\\\">\n  |    <text>Causes an allergic reaction in humans. Binds to IgE. Partially heat-labile allergen that may cause both respiratory and food-allergy symptoms in patients with the bird-egg syndrome.</text>\n  |  </comment>\"\n\ntest cc_unstructured_line.create\n  (\"CC   -!- SUBCELLULAR LOCATION: Golgi apparatus (By similarity).\" . \n   NL)\n= \n  \"\n  |  <comment type=\\\"subcellular location\\\" status=\\\"by similarity\\\">\n  |    <text>Golgi apparatus</text>\n  |  </comment>\" \n\n(* UniProtKB breaks its own guidelines here, splitting a line at a hyphen :( *)\nlet P12544_cc_unstructured_ascii : string = \n  \"CC   -!- FUNCTION: This enzyme is necessary for target cell lysis in cell-\n  |CC       mediated immune responses. It cleaves after Lys or Arg. May be\n  |CC       involved in apoptosis.\" . \n  NL\n\nlet P12544_cc_unstructured_xml : string = \n  NL . \n  \"  <comment type=\\\"function\\\">\n  |    <text>This enzyme is necessary for target cell lysis in cell- mediated immune responses. It cleaves after Lys or Arg. May be involved in apoptosis.</text>\n  |  </comment>\" \n\n\ntest cc_unstructured_line.get \n  P12544_cc_unstructured_xml = P12544_cc_unstructured_ascii\n\ntest cc_unstructured_line.create \n  P12544_cc_unstructured_ascii = P12544_cc_unstructured_xml\n\n(* CC biophysiochemical properties line *)\ntest \"----- CC biophysiochemical properties line -----\" = ?\nlet cc_biophysicochemical_properties_xml : lens = \n  let aux (xml:string) (ascii:string) : lens = \n    Xml.simple_elt NL3 xml (ins ascii . ins \"=\" . esc_s . semi) in \n  let absorption : lens = \n    space . ins \"Absorption\" . colon . space . \n    Xml.elt NL2 \"absorption\"\n      (aux \"max\" \"Abs(max)\" . space . \n       aux \"text\" \"Note\") in \n  let kinetic_parameters : lens = \n    space . ins \"Kinetic parameters: \" . \n    Xml.elt NL2 \"kinetics\" \n      (aux \"KM\" \"KM\" . space . \n       aux \"Vmax\" \"Vmax\" . space . \n       aux \"text\" \"Note\") in \n  let generic (xml:string) (ascii:string) : lens = \n    space . ins ascii . colon . space . \n    Xml.elt NL2 xml (esc_s . semi . space) in \n  let ph_dependence : lens = generic \"phDependence\" \"pH dependence\" in\n  let redox_potential : lens = generic \"redoxPotential\" \"Redox potential\" in\n  let temperature_dependence : lens = generic \"temperatureDependence\" \"Temperature dependence\" in       \n  ins cc_tag . ins cc_bang . \n  Xml.attr1_elt NL1 \"comment\"\n    \"type\" ((\"biophysicochemical properties\" <-> \"BIOPHYSICOCHEMICAL PROPERTIES\") . colon)\n    begin\n      absorption? . \n      kinetic_parameters? . \n      ph_dependence? . \n      redox_potential? . \n      temperature_dependence? \n    end\n\nlet cc_biophysicochemical_properties_line : lens = \n  split_terminate cc_long_tag cc_biophysicochemical_properties_xml\n\n(* unit tests for biophysiochemical properties CC lines *)\nlet cc_bp_ascii : string = \n  \"CC   -!- BIOPHYSICOCHEMICAL PROPERTIES: Absorption: Abs(max)=465 nm;\n  |CC       Note=The above maximum is for the oxidized form. Shows a maximal\n  |CC       peak at 330 nm in the reduced form. These absorption peaks are for\n  |CC       the tryptophylquinone cofactor; Kinetic parameters: KM=5.4 uM for\n  |CC       tyramine; Vmax=17 umol/min/mg enzyme; Note=The enzyme is substrate\n  |CC       inhibited at high substrate concentrations (Ki=1.08 mM for\n  |CC       tyramine);\" .  \n  NL\n\nlet cc_bp_xml : string = \n  NL . \n  \"  <comment type=\\\"biophysicochemical properties\\\">\n  |    <absorption>\n  |      <max>465 nm</max>\n  |      <text>The above maximum is for the oxidized form. Shows a maximal peak at 330 nm in the reduced form. These absorption peaks are for the tryptophylquinone cofactor</text>\n  |    </absorption>\n  |    <kinetics>\n  |      <KM>5.4 uM for tyramine</KM>\n  |      <Vmax>17 umol/min/mg enzyme</Vmax>\n  |      <text>The enzyme is substrate inhibited at high substrate concentrations (Ki=1.08 mM for tyramine)</text>\n  |    </kinetics>\n  |  </comment>\"\n\ntest cc_biophysicochemical_properties_line.get\n  cc_bp_xml = cc_bp_ascii \n\ntest cc_biophysicochemical_properties_line.create\n  cc_bp_ascii = cc_bp_xml \n\n(* CC interactions block *)\ntest \"----- CC interactions block -----\" = ?\n\nlet interaction : lens = \n   let experiments : lens = \n     ins \"NbExp=\" . \n     Xml.simple_elt NL2 \"experiments\" NUMBER . \n     semi . space in\n  let self_rest : lens = \n    ins \"Self\" . \n    Xml.slash_close .     \n    Xml.simple_elt NL2 \"organismsDiffer\" (del \"false\") in\n  let id_rest : lens = \n    Xml.close . \n    Xml.simple_elt NL3 \"id\" esc_n . colon . \n    (dash || Xml.simple_elt NL3 \"label\" esc_p) . \n     Xml.close_tag NL2 \"interactant\" . \n     Xml.simple_elt NL2 \"organismsDiffer\" ( \"true\" <-> \" (xeno)\" | del \"false\") in    \n  ins cc_long_tag . \n  Xml.attr1_elt NL1 \"comment\" \"type\" (del \"interaction\") \n    begin  \n      ( ins \"IntAct=\" . \n        Xml.attr1_elt_no_kids NL2 \"interactant\" \"intactId\" esc_cs . \n        comma . space . \n        Xml.raw_open NL2 \"interactant\" . \n        Xml.attr \"intactId\" esc_s . \n        semi ) ~\n      ( ( self_rest | id_rest ) . \n      semi . space .\n      experiments )\n    end\n\nlet interaction_line : lens = terminate interaction\n\n(* unit tests for interaction line *)\ntest interaction_line.get \n  \"  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-1043398\\\"/>\n  |    <interactant intactId=\\\"EBI-1050185\\\">\n  |      <id>Q8NBH6</id>\n  |    </interactant>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\" \n= \n ( \"CC       Q8NBH6:-; NbExp=1; IntAct=EBI-1043398, EBI-1050185;\" . \n    NL )\n\ntest interaction_line.create \n  (\"CC       Q8NBH6:-; NbExp=1; IntAct=EBI-1043398, EBI-1050185;\" . \n   NL)\n=\n  ( NL . \n    \"  <comment type=\\\"interaction\\\">\n    |    <interactant intactId=\\\"EBI-1043398\\\"/>\n    |    <interactant intactId=\\\"EBI-1050185\\\">\n    |      <id>Q8NBH6</id>\n    |    </interactant>\n    |    <organismsDiffer>false</organismsDiffer>\n    |    <experiments>1</experiments>\n    |  </comment>\" )\n\n(* interaction block *)\nlet cc_interaction_block : lens =\n  ins cc_tag . \n  ins cc_bang . \n  ins \"INTERACTION:\" . nl . \n  interaction_line+\n\n(* unit tests for interaction block *)\ntest cc_interaction_block.get \n\"  <comment type=\\\"interaction\\\">\n    <interactant intactId=\\\"EBI-1043398\\\"/>\n    <interactant intactId=\\\"EBI-1043398\\\"/>\n    <organismsDiffer>false</organismsDiffer>\n    <experiments>1</experiments>\n  </comment>\n  <comment type=\\\"interaction\\\">\n    <interactant intactId=\\\"EBI-1043398\\\"/>\n    <interactant intactId=\\\"EBI-1050185\\\">\n      <id>Q8NBH6</id>\n    </interactant>\n    <organismsDiffer>false</organismsDiffer>\n    <experiments>1</experiments>\n  </comment>\n  <comment type=\\\"interaction\\\">\n    <interactant intactId=\\\"EBI-1043398\\\"/>\n    <interactant intactId=\\\"EBI-350350\\\">\n      <id>P21266</id>\n      <label>GSTM3</label>\n    </interactant>\n    <organismsDiffer>false</organismsDiffer>\n    <experiments>1</experiments>\n  </comment>\" \n= \n  ( \"CC   -!- INTERACTION:\n    |CC       Self; NbExp=1; IntAct=EBI-1043398, EBI-1043398;\n    |CC       Q8NBH6:-; NbExp=1; IntAct=EBI-1043398, EBI-1050185;\n    |CC       P21266:GSTM3; NbExp=1; IntAct=EBI-1043398, EBI-350350;\" . \n    NL )\n\ntest cc_interaction_block.create\n  (\"CC   -!- INTERACTION:\n   |CC       Self; NbExp=1; IntAct=EBI-476263, EBI-476263;\n   |CC       P31749:AKT1; NbExp=2; IntAct=EBI-476263, EBI-296087;\n   |CC       Q9UER7:DAXX; NbExp=3; IntAct=EBI-476263, EBI-77321;\n   |CC       P25445:FAS; NbExp=1; IntAct=EBI-476263, EBI-494743;\n   |CC       P15626:Gstm2 (xeno); NbExp=1; IntAct=EBI-476263, EBI-1209729;\n   |CC       P09211:GSTP1; NbExp=1; IntAct=EBI-476263, EBI-353467;\n   |CC       Q9WTR2:Map3k6 (xeno); NbExp=1; IntAct=EBI-476263, EBI-1254790;\n   |CC       O08815:Slk (xeno); NbExp=1; IntAct=EBI-476263, EBI-986112;\n   |CC       Q12933:TRAF2; NbExp=1; IntAct=EBI-476263, EBI-355744;\n   |CC       P63104:YWHAZ; NbExp=1; IntAct=EBI-476263, EBI-347088;\" . \n   NL)\n= \n  \"\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-296087\\\">\n  |      <id>P31749</id>\n  |      <label>AKT1</label>\n  |    </interactant>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>2</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-77321\\\">\n  |      <id>Q9UER7</id>\n  |      <label>DAXX</label>\n  |    </interactant>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>3</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-494743\\\">\n  |      <id>P25445</id>\n  |      <label>FAS</label>\n  |    </interactant>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-1209729\\\">\n  |      <id>P15626</id>\n  |      <label>Gstm2</label>\n  |    </interactant>\n  |    <organismsDiffer>true</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-353467\\\">\n  |      <id>P09211</id>\n  |      <label>GSTP1</label>\n  |    </interactant>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-1254790\\\">\n  |      <id>Q9WTR2</id>\n  |      <label>Map3k6</label>\n  |    </interactant>\n  |    <organismsDiffer>true</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-986112\\\">\n  |      <id>O08815</id>\n  |      <label>Slk</label>\n  |    </interactant>\n  |    <organismsDiffer>true</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-355744\\\">\n  |      <id>Q12933</id>\n  |      <label>TRAF2</label>\n  |    </interactant>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-476263\\\"/>\n  |    <interactant intactId=\\\"EBI-347088\\\">\n  |      <id>P63104</id>\n  |      <label>YWHAZ</label>\n  |    </interactant>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\"\n\nlet P12544_cc_interaction_ascii : string = \n  \"CC   -!- INTERACTION:\n  |CC       Self; NbExp=1; IntAct=EBI-519800, EBI-519800;\" . \n  NL\n\nlet P12544_cc_interaction_xml : string = \n  \"<comment type=\\\"interaction\\\">\n  |<interactant intactId=\\\"EBI-519800\\\" />\n  |<interactant intactId=\\\"EBI-519800\\\" />\n  |<organismsDiffer>false</organismsDiffer>\n  |<experiments>1</experiments>\n  |</comment>\" \n\nlet P12544_cc_interaction_xml_cn : string = \n  NL . \n  \"  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-519800\\\"/>\n  |    <interactant intactId=\\\"EBI-519800\\\"/>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\" \n\ntest cc_interaction_block.get \n  P12544_cc_interaction_xml = P12544_cc_interaction_ascii \n\ntest cc_interaction_block.create \n  P12544_cc_interaction_ascii = P12544_cc_interaction_xml_cn\n\n(* CC alternative products *)\ntest \"----- CC alternative products -----\" = ?\n\n(* Notes: this comment is a little tricky because the number of\n   isoforms needs to be counted and included in the view. We do this\n   using a Q-lens that duplicates the names. Edits to the number in\n   the view are discarded. *)\nlet cc_alternative_products_xml : lens = \n  let event : lens = \n    Xml.attr1_elt_no_kids NL2 \"event\" \"type\" \n      ( \"alternative promoter\"    <-> \"Alternative promoter usage\" \n      | \"alternative splicing\"    <-> \"Alternative splicing\"       \n      | \"alternative initiation\"  <-> \"Alternative initiation\"     \n      | \"ribosomal frameshifting\" <-> \"Ribosomal frameshifting\") in \n  let events : lens = ins cc_long_tag . ins \"Event=\" . iter_with_sqsp event . semi in \n  let generic (xml:string) (ascii:string) : lens = \n    ins ascii . ins \"=\" . \n      Xml.simple_elt NL2 xml esc_s . \n      semi in \n  let name : lens =     \n    let id : lens = Xml.simple_elt NL3 \"id\" esc_csp in \n    let synonyms : lens = \n      ins \"Synonyms=\" . \n        iter_with_sep (Xml.simple_elt NL3 \"name\" esc_csp) (comma . space) . \n        semi in\n    let sequence : lens = \n      let vsp : lens = \"VSP_\" . DIGIT+ in \n        ins \"Sequence=\" . \n          ( Xml.attr1_elt_no_kids NL3 \"sequence\" \"type\"\n              ( \"displayed\"     <-> \"Displayed\"\n              | \"external\"      <-> \"External\"\n              | \"not described\" <-> \"Not described\")\n          | Xml.slow_attr2_elt_no_kids NL3 \"sequence\" \n              \"type\" (del \"described\")\n              \"ref\"  (iter_with_sep vsp (comma . space)) ) . \n          semi in \n      Xml.elt NL2 \"isoform\" \n        begin \n          ((ins \"IsoId=\" . \n              iter_with_sep id (comma . space) . \n              semi . space ) ~\n             (ins \"Name=\" . \n                Xml.simple_elt NL3 \"name\" esc_csp . \n                semi . space . \n                (synonyms . space )? )) . \n            sequence . \n            (generic \"note\" \"Note\")? \n        end in \n  let prelude : lens = \n    ins cc_tag . ins cc_bang . \n      ins \"ALTERNATIVE_PRODUCTS:\" . nl in \n  let named_isos_regexp : regexp = \" Named isoforms=\" . NUMBER .  \";\" in\n  let names : lens = (nl . ins cc_long_tag . cc_fix70 name)* in \n  let comment : lens = (space . generic \"comment\" \"Comment\")? in \n  let preprocess : lens = \n     del (stype comment) . \n     copy (stype name)* in \n  let named_isos (s:string) = \n     \" Named isoforms=\" . \n     string_of_int (count (stype name) ((get preprocess) s)) . \n     \";\" in \n  let entry : lens = \n    prelude . \n      Xml.attr1_elt NL1 \"comment\" \"type\" (del \"alternative products\") \n      begin \n        events . \n        dup2 named_isos_regexp named_isos (comment . names) \n      end in \n  let canonizer_copy (R:regexp) = canonizer_of_lens (copy R) in \n  let cn : canonizer =\n    begin\n      canonizer_copy (vtype prelude) . \n      (columnize 70 \n         (vtype events . vtype named_isos_regexp . vtype comment)\n         ' ' (NL . cc_long_tag . \"  \")) .\n      canonizer_copy (vtype names)\n     end in\n    terminate (right_quot entry cn) \n\nlet cc_alternative_products_line : lens =   \n  cc_alternative_products_xml \n\n(* unit tests for CC alternative products *)\nlet cc_alternative_products_xml : string = \n  NL . \n  \"  <comment type=\\\"alternative products\\\">\n  |    <event type=\\\"alternative splicing\\\"/>\n  |    <comment>This is a rather lengthy comment.</comment>\n  |    <isoform>\n  |      <id>P48347-1</id>\n  |      <name>1</name>\n  |      <name>D</name>\n  |      <name>This is a really long synonym that should cause the line to break</name>\n  |      <name>E</name>\n  |      <sequence type=\\\"displayed\\\"/>\n  |    </isoform>\n  |    <isoform>\n  |      <id>P48347-2</id>\n  |      <name>2</name>\n  |      <sequence type=\\\"described\\\" ref=\\\"VSP_008972\\\"/>\n  |    </isoform>\n  |  </comment>\" \n\nlet cc_alternative_products_ascii : string =\n  \"CC   -!- ALTERNATIVE_PRODUCTS:\n  |CC       Event=Alternative splicing; Named isoforms=2; Comment=This is\n  |CC         a rather lengthy comment.;\n  |CC       Name=1; Synonyms=D, This is a really long synonym that should cause\n  |CC         the line to break, E; IsoId=P48347-1; Sequence=Displayed;\n  |CC       Name=2; IsoId=P48347-2; Sequence=VSP_008972;\" .\n  NL\n\ntest cc_alternative_products_line.get\n cc_alternative_products_xml = cc_alternative_products_ascii\n\ntest cc_alternative_products_line.create\n  cc_alternative_products_ascii =  cc_alternative_products_xml\n\n(* CC mass spectrometry line *)\ntest \"----- CC mass spectrometry line -----\" = ?\n\nlet cc_mass_spectrometry_xml : lens = \n  let src : lens = qins (WSP . \"Source=\" . raw . \";\")? \"\" in \n  ins cc_tag . ins cc_bang . \n  ins \"MASS SPECTROMETRY\" . colon . space . \n  ( ( Xml.slow_attr3_elt_open NL1 \"comment\" \n        \"type\" (del \"mass spectrometry\")    \n        \"mass\" (ins \"Mass=\" . FNUMBER . semi . space)\n        \"method\"  (ins \"Method=\" . esc_sq . semi . space) )\n  | ( Xml.slow_attr4_elt_open NL1 \"comment\" \n       \"type\" (del \"mass spectrometry\")    \n       \"mass\" (ins \"Mass=\" . FNUMBER . semi . space)\n       \"error \"(ins \"Mass_error=\" . FNUMBER . semi . space) \n       \"method\"  (ins \"Method=\" . esc_sq . semi . space) ) ) . \n  ins \"Range=\" . \n  Xml.raw_open NL2 \"location\" . \n  ( (Xml.attr \"sequence\" (qsp . parens esc_csp))? ~    \n    (Xml.close . \n     Xml.attr1_elt_no_kids NL3 \"begin\" \"position\" NUMBER . \n     dash . \n     Xml.attr1_elt_no_kids NL3 \"end\" \"position\" NUMBER) ) . \n  Xml.close_tag NL2 \"location\" . semi . space . \n  ins \"Note=\" . \n  Xml.simple_elt NL2 \"note\" esc_s . semi . \n  Xml.close_tag NL1 \"comment\" . \n  src\n\nlet cc_mass_spectrometry_line : lens = \n  split_terminate cc_long_tag cc_mass_spectrometry_xml\n\n(* CC mass spectrometry unit tests *)\nlet cc_mass_spectrometry_ascii : string = \n   \"CC   -!- MASS SPECTROMETRY: Mass=23290.2; Mass_error=2.9;\n   |CC       Method=Electrospray; Range=16-214 (P04653-2); Note=Allele D, with\n   |CC       6 phosphate groups; Source=PubMed:7601973;\" . \n   NL\n\nlet cc_mass_spectrometry_ascii_cn : string = \n   \"CC   -!- MASS SPECTROMETRY: Mass=23290.2; Mass_error=2.9;\n   |CC       Method=Electrospray; Range=16-214 (P04653-2); Note=Allele D, with\n   |CC       6 phosphate groups;\" . \n   NL\n\nlet cc_mass_spectrometry_xml : string = \n  NL . \n  \"  <comment type=\\\"mass spectrometry\\\" mass=\\\"23290.2\\\" error =\\\"2.9\\\" method=\\\"Electrospray\\\">\n  |    <location sequence=\\\"P04653-2\\\">\n  |      <begin position=\\\"16\\\"/>\n  |      <end position=\\\"214\\\"/>\n  |    </location>\n  |    <note>Allele D, with 6 phosphate groups</note>\n  |  </comment>\"\n\ntest cc_mass_spectrometry_line.get\n  cc_mass_spectrometry_xml = cc_mass_spectrometry_ascii_cn\n\ntest cc_mass_spectrometry_line.create\n  cc_mass_spectrometry_ascii = cc_mass_spectrometry_xml \n\n(* CC sequence caution line *)\ntest \"----- CC sequence caution -----\" = ?\nlet cc_sequence_caution_xml : lens = \n  ins cc_tag . ins cc_bang . \n  ins \"SEQUENCE CAUTION:\" . nl . \n  ins cc_long_tag . \n  Xml.attr1_elt NL1 \"comment\" \"type\" (del \"sequence caution\") \n    begin\n      ( (space . \n         ins \"Type=\" . \n         Xml.attr1_elt_open NL2 \"conflict\" \n           \"type\" ( \"frameshift\" <-> \"Frameshift\"\n                  | \"erroneous initiation\" <-> \"Erroneous initiation\"             \n                  | \"erroneous termination\" <-> \"Erroneous termination\" \n                  | \"erroneous gene model prediction\" <-> \"Erroneous gene model prediction\"\n                  | \"erroneous translation\" <-> \"Erroneous translation\"\n                  | \"miscellaneous discrepancy\" <-> \"Miscellaneous discrepancy\") . \n         semi) ~\n        (ins \"Sequence=\" . \n         Xml.attr3_elt_no_kids NL3 \"sequence\"\n           \"resource\" (del (\"EMBL-CDS\" | \"EMBL\"))\n           \"id\" esc_dq\n           \"version\" (dot . NUMBER) . \n         semi) ) . \n     Xml.close_tag NL2 \"conflict\" . \n     ( qins (WSP . \"Positions=Several;\")? \"\"\n     | space . ins \"Positions=\" . \n       Xml.elt NL2 \"location\"\n       begin           \n           iter_with_sep \n             (Xml.attr1_elt_no_kids NL3 \"position\" \"position\" NUMBER) \n             (comma . space)\n         end . \n       semi ) . \n     (space . ins \"Note=\" . \n     Xml.simple_elt NL2 \"note\" esc_s . \n     semi)?\n  end\n\n(* NB: CC sequence caution lines are not wrapped *)\nlet cc_sequence_caution_line : lens = \n  terminate cc_sequence_caution_xml\n\n(* unit tests for CC sequence caution *)\nlet cc_sequence_caution_xml : string = \n  NL . \n  \"  <comment type=\\\"sequence caution\\\">\n  |    <conflict type=\\\"erroneous termination\\\">\n  |      <sequence resource=\\\"EMBL\\\" id=\\\"AAN42076\\\" version=\\\"1\\\"/>\n  |    </conflict>\n  |    <location>\n  |      <position position=\\\"273\\\"/>\n  |    </location>\n  |    <note>Translated as Gln.</note>\n  |  </comment>\" \n\nlet cc_sequence_caution_ascii : string = \n  \"CC   -!- SEQUENCE CAUTION:\n  |CC       Sequence=AAN42076.1; Type=Erroneous termination; Positions=273; Note=Translated as Gln.;\" . \n  NL\n  \ntest cc_sequence_caution_line.get\n  cc_sequence_caution_xml = cc_sequence_caution_ascii\n\ntest cc_sequence_caution_line.create\n  cc_sequence_caution_ascii = cc_sequence_caution_xml\n\n(* CC web resource line *)\ntest \"----- CC web resource -----\" = ?\nlet cc_web_resource_xml : lens = \n  ins cc_tag . ins cc_bang . \n  ins \"WEB RESOURCE:\" . space . \n  Xml.slow_attr2_elt NL1 \"comment\" \n    \"type\" (del \"online information\") \n    \"name\" (ins \"Name=\" . esc_s . semi . space)\n    begin\n      let url : lens = \n        ins \"URL=\" . \n        Xml.attr1_elt_no_kids NL2 \"link\" \"uri\" (quotes esc_q) . \n        semi in \n      let note : lens = \n        ins \"Note=\" . \n        Xml.simple_elt NL2 \"note\" esc_s . \n        semi . space in \n      url ~ note\n    end\n\nlet cc_web_resource_line : lens = \n  terminate (cc_fix cc_web_resource_xml)\n\n(* unit tests for CC web resource *)\nlet cc_web_resource_xml : string = \n  NL . \n  \"  <comment type=\\\"online information\\\" name=\\\"IARC TP53 mutation database\\\">\n  |    <link uri=\\\"http://www-p53.iarc.fr/\\\"/>\n  |    <note>Somatic and germline TP53 mutations in human cancers</note>\n  |  </comment>\" \n\nlet cc_web_resource_ascii : string = \n  \"CC   -!- WEB RESOURCE: Name=IARC TP53 mutation database; Note=Somatic and\n  |CC         germline TP53 mutations in human cancers;\n  |CC         URL=\\\"http://www-p53.iarc.fr/\\\";\" .\n  NL\n\ntest cc_web_resource_line.get \n  cc_web_resource_xml = cc_web_resource_ascii\n\ntest cc_web_resource_line.create \n  cc_web_resource_ascii = cc_web_resource_xml\n\n(* CC Block *)\ntest \"----- CC block -----\" = ?\nlet cc_copyright : string = \n  \"CC   -----------------------------------------------------------------------\n  |CC   Copyrighted by the UniProt Consortium, see http://www.uniprot.org/terms\n  |CC   Distributed under the Creative Commons Attribution-NoDerivs License\n  |CC   -----------------------------------------------------------------------\" . \n  NL\n\nlet cc_block : lens = \n  let non_interaction : lens = \n      ( cc_unstructured_line \n      | cc_biophysicochemical_properties_line\n      | cc_alternative_products_line\n      | cc_mass_spectrometry_line\n      | cc_sequence_caution_line\n      | cc_web_resource_line) in\n  let non_interaction_s = non_interaction* in \n  let non_interaction_p = non_interaction_s . non_interaction in \n  let final_cc_block_fst = \n    ( non_interaction_p\n    | cc_interaction_block \n    | non_interaction_s . cc_interaction_block . non_interaction_p ) in\n  let res = final_cc_block_fst . ins cc_copyright in\n  res\n\n(* unit tests for CC block *)\nlet cc_block_ascii : string =\n  \"CC   -!- ALTERNATIVE_PRODUCTS:\n  |CC       Event=Alternative splicing; Named isoforms=2;\n  |CC         Comment=Additional isoforms seem to exist;\n  |CC       Name=1; Synonyms=Ash-L; IsoId=P62993-1, P29354-1; Sequence=Displayed;\n  |CC       Name=GRB3-3; IsoId=P62993-2, P29354-2; Sequence=VSP_001839;\n  |CC   -!- SUBCELLULAR LOCATION: Golgi apparatus (By similarity).\n  |CC   -!- DOMAIN: The SH3 domains mediate interaction with SHB.\n  |CC   -!- SIMILARITY: Belongs to the GRB2/sem-5/DRK family.\n  |CC   -----------------------------------------------------------------------\n  |CC   Copyrighted by the UniProt Consortium, see http://www.uniprot.org/terms\n  |CC   Distributed under the Creative Commons Attribution-NoDerivs License\n  |CC   -----------------------------------------------------------------------\" . \n  NL\n\nlet cc_block_xml : string = \n  NL . \n  \"  <comment type=\\\"alternative products\\\">\n  |    <event type=\\\"alternative splicing\\\"/>\n  |    <comment>Additional isoforms seem to exist</comment>\n  |    <isoform>\n  |      <id>P62993-1</id>\n  |      <id>P29354-1</id>\n  |      <name>1</name>\n  |      <name>Ash-L</name>\n  |      <sequence type=\\\"displayed\\\"/>\n  |    </isoform>\n  |    <isoform>\n  |      <id>P62993-2</id>\n  |      <id>P29354-2</id>\n  |      <name>GRB3-3</name>\n  |      <sequence type=\\\"described\\\" ref=\\\"VSP_001839\\\"/>\n  |    </isoform>\n  |  </comment>\n  |  <comment type=\\\"subcellular location\\\" status=\\\"by similarity\\\">\n  |    <text>Golgi apparatus</text>\n  |  </comment>\n  |  <comment type=\\\"domain\\\">\n  |    <text>The SH3 domains mediate interaction with SHB.</text>\n  |  </comment>\n  |  <comment type=\\\"similarity\\\">\n  |    <text>Belongs to the GRB2/sem-5/DRK family.</text>\n  |  </comment>\"\n\n(* test cc_block.get *)\n(*   cc_block_xml = cc_block_ascii  *)\n\n(* test cc_block.create *)\n(*   cc_block_ascii = cc_block_xml *)\n\nlet P12544_cc_block_ascii : string = \n  \"CC   -!- FUNCTION: This enzyme is necessary for target cell lysis in cell-\n  |CC       mediated immune responses. It cleaves after Lys or Arg. May be\n  |CC       involved in apoptosis.\n  |CC   -!- CATALYTIC ACTIVITY: Hydrolysis of proteins, including fibronectin,\n  |CC       type IV collagen and nucleolin. Preferential cleavage:\n  |CC       -Arg-|-Xaa-, -Lys-|-Xaa- >> -Phe-|-Xaa- in small molecule\n  |CC       substrates.\n  |CC   -!- SUBUNIT: Homodimer; disulfide-linked.\n  |CC   -!- INTERACTION:\n  |CC       Self; NbExp=1; IntAct=EBI-519800, EBI-519800;\n  |CC   -!- SUBCELLULAR LOCATION: Secreted. Cytoplasmic granule.\n  |CC   -!- SIMILARITY: Belongs to the peptidase S1 family. Granzyme\n  |CC       subfamily.\n  |CC   -!- SIMILARITY: Contains 1 peptidase S1 domain.\n  |CC   -----------------------------------------------------------------------\n  |CC   Copyrighted by the UniProt Consortium, see http://www.uniprot.org/terms\n  |CC   Distributed under the Creative Commons Attribution-NoDerivs License\n  |CC   -----------------------------------------------------------------------\" . \n  NL\n\nlet P12544_cc_block_xml : string = \n  NL . \n  \"  <comment type=\\\"function\\\">\n  |    <text>This enzyme is necessary for target cell lysis in cell- mediated immune responses. It cleaves after Lys or Arg. May be involved in apoptosis.</text>\n  |  </comment>\n  |  <comment type=\\\"catalytic activity\\\">\n  |    <text>Hydrolysis of proteins, including fibronectin, type IV collagen and nucleolin. Preferential cleavage: -Arg-|-Xaa-, -Lys-|-Xaa- &gt;&gt; -Phe-|-Xaa- in small molecule substrates.</text>\n  |  </comment>\n  |  <comment type=\\\"subunit\\\">\n  |    <text>Homodimer; disulfide-linked.</text>\n  |  </comment>\n  |  <comment type=\\\"interaction\\\">\n  |    <interactant intactId=\\\"EBI-519800\\\"/>\n  |    <interactant intactId=\\\"EBI-519800\\\"/>\n  |    <organismsDiffer>false</organismsDiffer>\n  |    <experiments>1</experiments>\n  |  </comment>\n  |  <comment type=\\\"subcellular location\\\">\n  |    <text>Secreted. Cytoplasmic granule.</text>\n  |  </comment>\n  |  <comment type=\\\"similarity\\\">\n  |    <text>Belongs to the peptidase S1 family. Granzyme subfamily.</text>\n  |  </comment>\n  |  <comment type=\\\"similarity\\\">\n  |    <text>Contains 1 peptidase S1 domain.</text>\n  |  </comment>\"\n\n(* test cc_block.get *)\n(*   P12544_cc_block_xml = P12544_cc_block_ascii *)\n\n(* test cc_block.create  *)\n(*   P12544_cc_block_ascii = P12544_cc_block_xml *)\n\n(* --------------------------------------------------------------------------- *)\n(* DR block *)\ntest \"----- DR block -----\" = ?\n\nlet semi_space_dash : lens = semi . space . dash \n\nlet start_dr (db:regexp) : lens = \n  Sort.perm_sort_concat\n    #{lens}[(Xml.attr \"type\" (db . semi . space));\n\t    (Xml.attr \"key\" (del NUMBER));\n\t    (Xml.attr \"id\" (esc_sq))]\n\nlet property (ty:string) : lens = \n  semi . space . \n  Xml.slow_attr2_elt_no_kids NL2 \"property\" \n    \"value\" esc_sq\n    \"type\" (del ty)\n\nlet optional_dr2 (db:regexp) (ty:string) : lens = \n    start_dr db . \n      ( (Xml.slash_close . semi_space_dash)\n      || (Xml.close . \n         property ty . \n         Xml.close_tag NL1 \"dbReference\") )\n\nlet optional_dr3 (db:regexp) (ty1:string) (ty2:string) : lens = \n  start_dr db . \n    ( (Xml.slash_close . semi_space_dash{2})\n    || (Xml.close . \n         ( (property ty1 . (property ty2 || semi_space_dash))\n         || (semi_space_dash || property ty2) ) . \n       Xml.close_tag NL1 \"dbReference\") )\n\nlet optional_dr4_a (db:regexp) (ty1:string) (ty2:string) (ty3:string) : lens = \n  let a : lens = space . ins \"A\" in \n  start_dr db . \n    ( (Xml.slash_close . semi_space_dash{3})\n    || (Xml.close . \n         ( (property ty1 . (property ty2 . a || semi_space_dash) . (property ty3 || semi_space_dash))\n         || (semi_space_dash . property ty2 . a . (property ty3 || semi_space_dash))\n         || (semi_space_dash{2} . property ty3) ) . \n       Xml.close_tag NL1 \"dbReference\") )\n\nlet optional_dr4 (db:regexp) (ty1:string) (ty2:string) (ty3:string) : lens = \n  start_dr db . \n    ( (Xml.slash_close . semi_space_dash{3})\n    || (Xml.close . \n         ( (property ty1 . (property ty2 || semi_space_dash) . (property ty3 || semi_space_dash))\n         || (semi_space_dash . property ty2 . (property ty3 || semi_space_dash))\n         || (semi_space_dash{2} . property ty3) ) . \n       Xml.close_tag NL1 \"dbReference\") )\n\nlet dr_2_1 =\n  optional_dr2 ( \"HIV\" | \"InterPro\" | \"PIR\" | \"PRINTS\" | \"REBASE\" | \"HGNC\")\n    \"entry name\"\n\nlet dr_2_1_3_1 =\n  optional_dr3 \n    (\"Gene3D\" | \"PANTHER\" | \"Pfam\" | \"ProDom\" | \"SMART\" | \"TIGRFAMs\") \n    \"entry name\" \"match status\"\n\nlet dr_2_2_3_3_4_1 = \n  optional_dr4_a \"PDB\" \"method\" \"resolution\" \"chains\"\n\nlet dr_2_3 =\n  optional_dr2 (\"DictyBase\" | \"EcoGene\" | \"FlyBase\" | \"MGI\" | \"RGD\" | \"SGD\" \n        | \"StyGene\" | \"SubtiList\" | \"WormBase\" | \"ZFIN\" ) \"gene designation\"\n\nlet dr_2_4_3_2 = \n  optional_dr3 \"GO\" \"term\" \"evidence\"\n\n(* look at dr   HAMAP; MF_01546; atypical; 1. *)\nlet dr_2_5_3_1 = \n  optional_dr3 \"HAMAP\" \"flag\" \"match status\"\n\nlet dr_2_6 = \n  optional_dr2 \"ECO2DBASE\" \"edition\"\n\nlet dr_2_7 = \n  optional_dr2 (\"Cornea-2DPAGE\" | \"DOSAC-COBS-2DPAGE\" | \"HSC-2DPAGE\" | \"REPRODUCTION-2DPAGE\" \n        | \"SWISS-2DPAGE\") \"organism name\"\n\nlet dr_2_8 = \n  optional_dr2 \"Ensembl\" \"organism name\"\n\nlet dr_2_9_3_1 = \n  optional_dr3 \"PIRSF\" \"entry name\" \"match status\"\n  \n\n(* no AARHUS exemple found *)\n(*let DR_2_10 = \n  optional_dr2 \"AARHUS/GHENT-2DPAGE\" \"\" *)\n  \nlet dr_2_11 = \n  optional_dr2 \"WormPep\" \"accession\"\n  \nlet dr_2_12 = \n  start_dr \n    (\"AGD\" | \"ANU-2DPAGE\" | \"ArrayExpress\" | \"BioCyc\" | \"CleanEx\" \n    | \"COMPLUYEAST-2DPAGE\" | \"CYGD\" | \"DIP\" | \"DisProt\" | \"EchoBASE\" \n    | \"GeneDB_Spombe\" | \"GeneID\" | \"GlycoSuiteDB\" | \"Gramene\" | \"H-InvDB\" \n    | \"HPA\" | \"IntAct\" | \"KEGG\" | \"LegioList\" | \"Leproma\" | \"LinkHub\" \n    | \"ListiList\" | \"MaizeGDB\" | \"MEROPS\" | \"MypuList\" | \"OGP\" | \"PeptideAtlas\" \n    | \"PDBsum\" | \"PharmGKB\" | \"PHCI-2DPAGE\" | \"PhosSite\" | \"PhotoList\" | \"PMMA-2DPAGE\" \n    | \"PptaseDB\" | \"PseudoCAP\" | \"Rat-heart-2DPAGE\" | \"RefSeq\" | \"SagaList\" \n    | \"Siena-2DPAGE\" | \"TAIR\" | \"TIGR\" | \"TRANSFAC\" | \"TubercuList\" | \"UniGene\") .\n  Xml.slash_close . \n  semi_space_dash\n\nlet dr_2_13 = \n  optional_dr2 \"HSSP\" \"PDB accession\"\n    \nlet dr_2_14 = \n  optional_dr2 \"GeneFarm\" \"family number\"\n    \nlet dr_2_15 = \n  optional_dr2 \"SMR\" \"residue range\"\n  \nlet dr_2_16 = \n  optional_dr2 \"MIM\" \"type\"\n  \n(* for now, the second identifier seems to be dropped away. I'm waiting for an answer of the uniprot help list *)\n(*let dr_2_17 = \n  optional_dr2 \"Orphanet\" \"\"*)\n  \nlet dr_2_18 = \n  optional_dr2 \"GenomeReviews\" \"gene designation\"\n  \nlet dr_2_19 = \n  optional_dr2 \"GermOnline\" \"organism name\"\n  \nlet dr_2_20 = \n  optional_dr2 \"PeroxiBase\" \"entry name\"\n  \nlet dr_2_21 = \n  optional_dr2 \"Reactome\" \"pathway name\"\n  \nlet dr_2_22 = \n  optional_dr2 \"DrugBank\" \"generic name\"\n  \nlet dr_EMBL = \n  optional_dr4 \"EMBL\" \"protein sequence ID\" \"status\" \"molecule type\"\n\nlet dr_PROSITE = \n  optional_dr3 \"PROSITE\" \"entry name\" \"match status\"\n\nlet dr_tag : string = tag \"DR\" \n\nlet dr_xml = \n  ins dr_tag . \n  Xml.raw_open NL1 \"dbReference\" . \n  ( dr_2_1 | dr_2_1_3_1 | dr_2_2_3_3_4_1 | dr_2_3 | dr_2_4_3_2 | dr_2_5_3_1 \n  | dr_2_6 | dr_2_7 | dr_2_8 | dr_2_9_3_1 | dr_2_11 | dr_2_12 | dr_2_13\n  | dr_2_14 | dr_2_15 | dr_2_16 | dr_2_18 | dr_2_19 | dr_2_20 | dr_2_21 \n  | dr_2_22 | dr_EMBL | dr_PROSITE) .\n  dot\n\nlet dr_block : lens = (terminate dr_xml)*\n\n(* unit tests for DR block *)\ntest dr_block.get \n  \"  <dbReference type=\\\"EMBL\\\" key=\\\"0\\\" id=\\\"X83468\\\">\n  |    <property value=\\\"CAA58470.1\\\" type=\\\"protein sequence ID\\\"/>\n  |    <property value=\\\"JOINED\\\" type=\\\"status\\\"/>\n  |    <property value=\\\"Genomic_DNA\\\" type=\\\"molecule type\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PROSITE\\\" key=\\\"0\\\" id=\\\"PS00940\\\">\n  |    <property value=\\\"GAMMA_THIONIN\\\" type=\\\"entry name\\\"/>\n  |    <property value=\\\"1\\\" type=\\\"match status\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"EMBL\\\" key=\\\"0\\\" id=\\\"CR940353\\\">\n  |    <property value=\\\"CAI76474.1\\\" type=\\\"protein sequence ID\\\"/>\n  |    <property value=\\\"Genomic_DNA\\\" type=\\\"molecule type\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"KEGG\\\" key=\\\"0\\\" id=\\\"tan:TA08425\\\"/>\n  |  <dbReference type=\\\"InterPro\\\" key=\\\"0\\\" id=\\\"IPR007480\\\">\n  |    <property value=\\\"DUF529\\\" type=\\\"entry name\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"Pfam\\\" key=\\\"0\\\" id=\\\"PF04385\\\">\n  |    <property value=\\\"FAINT\\\" type=\\\"entry name\\\"/>\n  |    <property value=\\\"4\\\" type=\\\"match status\\\"/>\n  |  </dbReference>\" \n= \n  ( \"DR   EMBL; X83468; CAA58470.1; JOINED; Genomic_DNA.\n    |DR   PROSITE; PS00940; GAMMA_THIONIN; 1.\n    |DR   EMBL; CR940353; CAI76474.1; -; Genomic_DNA.\n    |DR   KEGG; tan:TA08425; -.\n    |DR   InterPro; IPR007480; DUF529.\n    |DR   Pfam; PF04385; FAINT; 4.\" . \n    NL )\n\ntest dr_block.create \n  (\"DR   EMBL; X83467; CAA58470.1; -; Genomic_DNA.\" . \n   NL)\n= \n  \"\n  |  <dbReference type=\\\"EMBL\\\" key=\\\"0\\\" id=\\\"X83467\\\">\n  |    <property value=\\\"CAA58470.1\\\" type=\\\"protein sequence ID\\\"/>\n  |    <property value=\\\"-\\\" type=\\\"status\\\"/>\n  |    <property value=\\\"Genomic_DNA\\\" type=\\\"molecule type\\\"/>\n  |  </dbReference>\"\n\nlet P12544_dr_block_ascii : string =   \n  \"DR   EMBL; M18737; AAA52647.1; -; mRNA.\n  |DR   EMBL; CR456968; CAG33249.1; -; mRNA.\n  |DR   EMBL; BC015739; AAH15739.1; -; mRNA.\n  |DR   EMBL; U40006; AAD00009.1; -; Genomic_DNA.\n  |DR   PIR; A31372; A31372.\n  |DR   RefSeq; NP_006135.1; -.\n  |DR   UniGene; Hs.90708; -.\n  |DR   PDB; 1HF1; Model; -; A=29-262.\n  |DR   PDB; 1OP8; X-ray; 2.50 A; A/B/C/D/E/F=29-262.\n  |DR   PDB; 1ORF; X-ray; 2.40 A; A=29-262.\n  |DR   PDBsum; 1HF1; -.\n  |DR   PDBsum; 1OP8; -.\n  |DR   PDBsum; 1ORF; -.\n  |DR   IntAct; P12544; -.\n  |DR   MEROPS; S01.135; -.\n  |DR   Ensembl; ENSG00000145649; Homo sapiens.\n  |DR   GeneID; 3001; -.\n  |DR   KEGG; hsa:3001; -.\n  |DR   H-InvDB; HIX0004862; -.\n  |DR   HGNC; HGNC:4708; GZMA.\n  |DR   MIM; 140050; gene.\n  |DR   PharmGKB; PA29086; -.\n  |DR   LinkHub; P12544; -.\n  |DR   ArrayExpress; P12544; -.\n  |DR   CleanEx; HS_GZMA; -.\n  |DR   GermOnline; ENSG00000145649; Homo sapiens.\n  |DR   GO; GO:0001772; C:immunological synapse; TAS:UniProtKB.\n  |DR   GO; GO:0005634; C:nucleus; TAS:UniProtKB.\n  |DR   GO; GO:0004277; F:granzyme A activity; IDA:UniProtKB.\n  |DR   GO; GO:0042803; F:protein homodimerization activity; IDA:UniProtKB.\n  |DR   GO; GO:0006922; P:cleavage of lamin; IDA:UniProtKB.\n  |DR   GO; GO:0006955; P:immune response; TAS:UniProtKB.\n  |DR   InterPro; IPR001254; Peptidase_S1_S6.\n  |DR   InterPro; IPR001314; Peptidase_S1A.\n  |DR   Pfam; PF00089; Trypsin; 1.\n  |DR   PRINTS; PR00722; CHYMOTRYPSIN.\n  |DR   SMART; SM00020; Tryp_SPc; 1.\n  |DR   PROSITE; PS50240; TRYPSIN_DOM; 1.\n  |DR   PROSITE; PS00134; TRYPSIN_HIS; 1.\n  |DR   PROSITE; PS00135; TRYPSIN_SER; 1.\" . \n  NL\n\n(* differs from UniProtKB version in that: order of attrs canonized,\n   key attrs set to \"0\", whitepsace canonized. *)\nlet P12544_dr_block_xml_cn : string = \n  NL . \n  \"  <dbReference type=\\\"EMBL\\\" key=\\\"0\\\" id=\\\"M18737\\\">\n  |    <property value=\\\"AAA52647.1\\\" type=\\\"protein sequence ID\\\"/>\n  |    <property value=\\\"-\\\" type=\\\"status\\\"/>\n  |    <property value=\\\"mRNA\\\" type=\\\"molecule type\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"EMBL\\\" key=\\\"0\\\" id=\\\"CR456968\\\">\n  |    <property value=\\\"CAG33249.1\\\" type=\\\"protein sequence ID\\\"/>\n  |    <property value=\\\"-\\\" type=\\\"status\\\"/>\n  |    <property value=\\\"mRNA\\\" type=\\\"molecule type\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"EMBL\\\" key=\\\"0\\\" id=\\\"BC015739\\\">\n  |    <property value=\\\"AAH15739.1\\\" type=\\\"protein sequence ID\\\"/>\n  |    <property value=\\\"-\\\" type=\\\"status\\\"/>\n  |    <property value=\\\"mRNA\\\" type=\\\"molecule type\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"EMBL\\\" key=\\\"0\\\" id=\\\"U40006\\\">\n  |    <property value=\\\"AAD00009.1\\\" type=\\\"protein sequence ID\\\"/>\n  |    <property value=\\\"-\\\" type=\\\"status\\\"/>\n  |    <property value=\\\"Genomic_DNA\\\" type=\\\"molecule type\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PIR\\\" key=\\\"0\\\" id=\\\"A31372\\\">\n  |    <property value=\\\"A31372\\\" type=\\\"entry name\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"RefSeq\\\" key=\\\"0\\\" id=\\\"NP_006135.1\\\"/>\n  |  <dbReference type=\\\"UniGene\\\" key=\\\"0\\\" id=\\\"Hs.90708\\\"/>\n  |  <dbReference type=\\\"PDB\\\" key=\\\"0\\\" id=\\\"1HF1\\\">\n  |    <property value=\\\"Model\\\" type=\\\"method\\\"/>\n  |    <property value=\\\"A=29-262\\\" type=\\\"chains\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PDB\\\" key=\\\"0\\\" id=\\\"1OP8\\\">\n  |    <property value=\\\"X-ray\\\" type=\\\"method\\\"/>\n  |    <property value=\\\"2.50\\\" type=\\\"resolution\\\"/>\n  |    <property value=\\\"A/B/C/D/E/F=29-262\\\" type=\\\"chains\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PDB\\\" key=\\\"0\\\" id=\\\"1ORF\\\">\n  |    <property value=\\\"X-ray\\\" type=\\\"method\\\"/>\n  |    <property value=\\\"2.40\\\" type=\\\"resolution\\\"/>\n  |    <property value=\\\"A=29-262\\\" type=\\\"chains\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PDBsum\\\" key=\\\"0\\\" id=\\\"1HF1\\\"/>\n  |  <dbReference type=\\\"PDBsum\\\" key=\\\"0\\\" id=\\\"1OP8\\\"/>\n  |  <dbReference type=\\\"PDBsum\\\" key=\\\"0\\\" id=\\\"1ORF\\\"/>\n  |  <dbReference type=\\\"IntAct\\\" key=\\\"0\\\" id=\\\"P12544\\\"/>\n  |  <dbReference type=\\\"MEROPS\\\" key=\\\"0\\\" id=\\\"S01.135\\\"/>\n  |  <dbReference type=\\\"Ensembl\\\" key=\\\"0\\\" id=\\\"ENSG00000145649\\\">\n  |    <property value=\\\"Homo sapiens\\\" type=\\\"organism name\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"GeneID\\\" key=\\\"0\\\" id=\\\"3001\\\"/>\n  |  <dbReference type=\\\"KEGG\\\" key=\\\"0\\\" id=\\\"hsa:3001\\\"/>\n  |  <dbReference type=\\\"H-InvDB\\\" key=\\\"0\\\" id=\\\"HIX0004862\\\"/>\n  |  <dbReference type=\\\"HGNC\\\" key=\\\"0\\\" id=\\\"HGNC:4708\\\">\n  |    <property value=\\\"GZMA\\\" type=\\\"entry name\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"MIM\\\" key=\\\"0\\\" id=\\\"140050\\\">\n  |    <property value=\\\"gene\\\" type=\\\"type\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PharmGKB\\\" key=\\\"0\\\" id=\\\"PA29086\\\"/>\n  |  <dbReference type=\\\"LinkHub\\\" key=\\\"0\\\" id=\\\"P12544\\\"/>\n  |  <dbReference type=\\\"ArrayExpress\\\" key=\\\"0\\\" id=\\\"P12544\\\"/>\n  |  <dbReference type=\\\"CleanEx\\\" key=\\\"0\\\" id=\\\"HS_GZMA\\\"/>\n  |  <dbReference type=\\\"GermOnline\\\" key=\\\"0\\\" id=\\\"ENSG00000145649\\\">\n  |    <property value=\\\"Homo sapiens\\\" type=\\\"organism name\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"GO\\\" key=\\\"0\\\" id=\\\"GO:0001772\\\">\n  |    <property value=\\\"C:immunological synapse\\\" type=\\\"term\\\"/>\n  |    <property value=\\\"TAS:UniProtKB\\\" type=\\\"evidence\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"GO\\\" key=\\\"0\\\" id=\\\"GO:0005634\\\">\n  |    <property value=\\\"C:nucleus\\\" type=\\\"term\\\"/>\n  |    <property value=\\\"TAS:UniProtKB\\\" type=\\\"evidence\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"GO\\\" key=\\\"0\\\" id=\\\"GO:0004277\\\">\n  |    <property value=\\\"F:granzyme A activity\\\" type=\\\"term\\\"/>\n  |    <property value=\\\"IDA:UniProtKB\\\" type=\\\"evidence\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"GO\\\" key=\\\"0\\\" id=\\\"GO:0042803\\\">\n  |    <property value=\\\"F:protein homodimerization activity\\\" type=\\\"term\\\"/>\n  |    <property value=\\\"IDA:UniProtKB\\\" type=\\\"evidence\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"GO\\\" key=\\\"0\\\" id=\\\"GO:0006922\\\">\n  |    <property value=\\\"P:cleavage of lamin\\\" type=\\\"term\\\"/>\n  |    <property value=\\\"IDA:UniProtKB\\\" type=\\\"evidence\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"GO\\\" key=\\\"0\\\" id=\\\"GO:0006955\\\">\n  |    <property value=\\\"P:immune response\\\" type=\\\"term\\\"/>\n  |    <property value=\\\"TAS:UniProtKB\\\" type=\\\"evidence\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"InterPro\\\" key=\\\"0\\\" id=\\\"IPR001254\\\">\n  |    <property value=\\\"Peptidase_S1_S6\\\" type=\\\"entry name\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"InterPro\\\" key=\\\"0\\\" id=\\\"IPR001314\\\">\n  |    <property value=\\\"Peptidase_S1A\\\" type=\\\"entry name\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"Pfam\\\" key=\\\"0\\\" id=\\\"PF00089\\\">\n  |    <property value=\\\"Trypsin\\\" type=\\\"entry name\\\"/>\n  |    <property value=\\\"1\\\" type=\\\"match status\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PRINTS\\\" key=\\\"0\\\" id=\\\"PR00722\\\">\n  |    <property value=\\\"CHYMOTRYPSIN\\\" type=\\\"entry name\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"SMART\\\" key=\\\"0\\\" id=\\\"SM00020\\\">\n  |    <property value=\\\"Tryp_SPc\\\" type=\\\"entry name\\\"/>\n  |    <property value=\\\"1\\\" type=\\\"match status\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PROSITE\\\" key=\\\"0\\\" id=\\\"PS50240\\\">\n  |    <property value=\\\"TRYPSIN_DOM\\\" type=\\\"entry name\\\"/>\n  |    <property value=\\\"1\\\" type=\\\"match status\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PROSITE\\\" key=\\\"0\\\" id=\\\"PS00134\\\">\n  |    <property value=\\\"TRYPSIN_HIS\\\" type=\\\"entry name\\\"/>\n  |    <property value=\\\"1\\\" type=\\\"match status\\\"/>\n  |  </dbReference>\n  |  <dbReference type=\\\"PROSITE\\\" key=\\\"0\\\" id=\\\"PS00135\\\">\n  |    <property value=\\\"TRYPSIN_SER\\\" type=\\\"entry name\\\"/>\n  |    <property value=\\\"1\\\" type=\\\"match status\\\"/>\n  |  </dbReference>\"\n\n    test dr_block.get \n    P12544_dr_block_xml_cn = P12544_dr_block_ascii\n\n  test dr_block.create \n  P12544_dr_block_ascii = P12544_dr_block_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* PE line *)\ntest \"----- PE line-----\" = ?\n\nlet pe_tag : string = tag \"PE\"\n\nlet pe_xml : lens = \n  ins pe_tag . \n  Xml.attr1_elt_no_kids NL1 \"proteinExistence\" \n    \"type\" \n    ( \"Evidence at protein level\"    <-> \"1: Evidence at protein level\"   \n    | \"Evidence at transcript level\" <-> \"2: Evidence at transcript level\"\n    | \"Inferred from homology\"       <-> \"3: Inferred from homology\"      \n    | \"Predicted\"                    <-> \"4: Predicted\"                   \n    | \"Uncertain\"                    <-> \"5: Uncertain\"                   ) . \n  semi \n\nlet pe_line : lens = terminate pe_xml\n\n(* unit tests for PE line *)\nlet pe_ascii : string = \n  \"PE   5: Uncertain;\" . NL\n\nlet pe_xml : string = \n  NL . \n  \"  <proteinExistence type=\\\"Uncertain\\\"/>\"\n\ntest pe_line.get \n  pe_xml = pe_ascii\n\ntest pe_line.create \n  pe_ascii = pe_xml\n\nlet P12544_pe_ascii : string = \n  \"PE   1: Evidence at protein level;\" . \n  NL\n\nlet P12544_pe_xml_cn : string = \n  NL . \n  \"  <proteinExistence type=\\\"Evidence at protein level\\\"/>\" \n\ntest pe_line.get\n  P12544_pe_xml_cn = P12544_pe_ascii\n\ntest pe_line.create\n  P12544_pe_ascii = P12544_pe_xml_cn\n\n(* --------------------------------------------------------------------------- *)\n(* KW line *)\ntest \"----- KW line-----\" = ?\n\nlet kw_trans : lens = \n  let mid = del \"\\\">\" in \n  ( del \"KW-0001\" . mid . \"2Fe-2S\"\n  | del \"KW-0002\" . mid . \"3D-structure\"\n  | del \"KW-0003\" . mid . \"3Fe-4S\"\n  | del \"KW-0004\" . mid . \"4Fe-4S\"\n  | del \"KW-0937\" . mid . \"Abscisic acid biosynthesis\"\n  | del \"KW-0938\" . mid . \"Abscisic acid signaling pathway\"\n  | del \"KW-0005\" . mid . \"Acetoin biosynthesis\"\n  | del \"KW-0006\" . mid . \"Acetoin catabolism\"\n  | del \"KW-0007\" . mid . \"Acetylation\"\n  | del \"KW-0008\" . mid . \"Acetylcholine receptor inhibitor\"\n  | del \"KW-0009\" . mid . \"Actin-binding\"\n  | del \"KW-0117\" . mid . \"Actin capping\"\n  | del \"KW-0010\" . mid . \"Activator\"\n  | del \"KW-0011\" . mid . \"Acute phase\"\n  | del \"KW-0012\" . mid . \"Acyltransferase\"\n  | del \"KW-0013\" . mid . \"ADP-ribosylation\"\n  | del \"KW-0913\" . mid . \"Age-related macular degeneration\"\n  | del \"KW-0948\" . mid . \"Aicardi-Goutieres syndrome\"\n  | del \"KW-0014\" . mid . \"AIDS\"\n  | del \"KW-0015\" . mid . \"Albinism\"\n  | del \"KW-0016\" . mid . \"Alginate biosynthesis\"\n  | del \"KW-0017\" . mid . \"Alkaloid metabolism\"\n  | del \"KW-0019\" . mid . \"Alkylphosphonate uptake\"\n  | del \"KW-0020\" . mid . \"Allergen\"\n  | del \"KW-0021\" . mid . \"Allosteric enzyme\"\n  | del \"KW-0022\" . mid . \"Alpha-amylase inhibitor\"\n  | del \"KW-0023\" . mid . \"Alport syndrome\"\n  | del \"KW-0024\" . mid . \"Alternative initiation\"\n  | del \"KW-0877\" . mid . \"Alternative promoter usage\"\n  | del \"KW-0025\" . mid . \"Alternative splicing\"\n  | del \"KW-0026\" . mid . \"Alzheimer disease\"\n  | del \"KW-0027\" . mid . \"Amidation\"\n  | del \"KW-0028\" . mid . \"Amino-acid biosynthesis\"\n  | del \"KW-0029\" . mid . \"Amino-acid transport\"\n  | del \"KW-0030\" . mid . \"Aminoacyl-tRNA synthetase\"\n  | del \"KW-0031\" . mid . \"Aminopeptidase\"\n  | del \"KW-0032\" . mid . \"Aminotransferase\"\n  | del \"KW-0924\" . mid . \"Ammonia transport\"\n  | del \"KW-0878\" . mid . \"Amphibian defense peptide\"\n  | del \"KW-0034\" . mid . \"Amyloid\"\n  | del \"KW-0035\" . mid . \"Amyloplast\"\n  | del \"KW-0036\" . mid . \"Amyotrophic lateral sclerosis\"\n  | del \"KW-0037\" . mid . \"Angiogenesis\"\n  | del \"KW-0039\" . mid . \"Anion exchange\"\n  | del \"KW-0040\" . mid . \"ANK repeat\"\n  | del \"KW-0041\" . mid . \"Annexin\"\n  | del \"KW-0042\" . mid . \"Antenna complex\"\n  | del \"KW-0045\" . mid . \"Antibiotic biosynthesis\"\n  | del \"KW-0044\" . mid . \"Antibiotic\"\n  | del \"KW-0046\" . mid . \"Antibiotic resistance\"\n  | del \"KW-0047\" . mid . \"Antifreeze protein\"\n  | del \"KW-0929\" . mid . \"Antimicrobial\"\n  | del \"KW-0043\" . mid . \"Anti-oncogene\"\n  | del \"KW-0049\" . mid . \"Antioxidant\"\n  | del \"KW-0050\" . mid . \"Antiport\"\n  | del \"KW-0051\" . mid . \"Antiviral defense\"\n  | del \"KW-0930\" . mid . \"Antiviral protein\"\n  | del \"KW-0933\" . mid . \"Apicoplast\"\n  | del \"KW-0052\" . mid . \"Apoplast\"\n  | del \"KW-0053\" . mid . \"Apoptosis\"\n  | del \"KW-0054\" . mid . \"Arabinose catabolism\"\n  | del \"KW-0055\" . mid . \"Arginine biosynthesis\"\n  | del \"KW-0056\" . mid . \"Arginine metabolism\"\n  | del \"KW-0057\" . mid . \"Aromatic amino acid biosynthesis\"\n  | del \"KW-0058\" . mid . \"Aromatic hydrocarbons catabolism\"\n  | del \"KW-0059\" . mid . \"Arsenical resistance\"\n  | del \"KW-0060\" . mid . \"Ascorbate biosynthesis\"\n  | del \"KW-0061\" . mid . \"Asparagine biosynthesis\"\n  | del \"KW-0062\" . mid . \"Aspartic protease inhibitor\"\n  | del \"KW-0063\" . mid . \"Aspartyl esterase\"\n  | del \"KW-0064\" . mid . \"Aspartyl protease\"\n  | del \"KW-0065\" . mid . \"Atherosclerosis\"\n  | del \"KW-0067\" . mid . \"ATP-binding\"\n  | del \"KW-0066\" . mid . \"ATP synthesis\"\n  | del \"KW-0068\" . mid . \"Autocatalytic cleavage\"\n  | del \"KW-0069\" . mid . \"Autoimmune encephalomyelitis\"\n  | del \"KW-0070\" . mid . \"Autoimmune uveitis\"\n  | del \"KW-0071\" . mid . \"Autoinducer synthesis\"\n  | del \"KW-0072\" . mid . \"Autophagy\"\n  | del \"KW-0073\" . mid . \"Auxin biosynthesis\"\n  | del \"KW-0927\" . mid . \"Auxin signaling pathway\"\n  | del \"KW-0875\" . mid . \"Bacterial capsule\"\n  | del \"KW-0077\" . mid . \"Bacteriochlorophyll biosynthesis\"\n  | del \"KW-0076\" . mid . \"Bacteriochlorophyll\"\n  | del \"KW-0871\" . mid . \"Bacteriocin biosynthesis\"\n  | del \"KW-0079\" . mid . \"Bacteriocin immunity\"\n  | del \"KW-0078\" . mid . \"Bacteriocin\"\n  | del \"KW-0080\" . mid . \"Bacteriocin transport\"\n  | del \"KW-0081\" . mid . \"Bacteriolytic enzyme\"\n  | del \"KW-0082\" . mid . \"Bait region\"\n  | del \"KW-0083\" . mid . \"Bardet-Biedl syndrome\"\n  | del \"KW-0910\" . mid . \"Bartter syndrome\"\n  | del \"KW-0084\" . mid . \"Basement membrane\"\n  | del \"KW-0075\" . mid . \"B-cell activation\"\n  | del \"KW-0085\" . mid . \"Behavior\"\n  | del \"KW-0086\" . mid . \"Bence-Jones protein\"\n  | del \"KW-0087\" . mid . \"Bernard Soulier syndrome\"\n  | del \"KW-0088\" . mid . \"Bile acid catabolism\"\n  | del \"KW-0089\" . mid . \"Bile pigment\"\n  | del \"KW-0090\" . mid . \"Biological rhythms\"\n  | del \"KW-0091\" . mid . \"Biomineralization\"\n  | del \"KW-0093\" . mid . \"Biotin biosynthesis\"\n  | del \"KW-0092\" . mid . \"Biotin\"\n  | del \"KW-0094\" . mid . \"Blood coagulation\"\n  | del \"KW-0095\" . mid . \"Blood group antigen\"\n  | del \"KW-0100\" . mid . \"Branched-chain amino acid biosynthesis\"\n  | del \"KW-0101\" . mid . \"Branched-chain amino acid catabolism\"\n  | del \"KW-0102\" . mid . \"Bromination\"\n  | del \"KW-0103\" . mid . \"Bromodomain\"\n  | del \"KW-0104\" . mid . \"Cadmium\"\n  | del \"KW-0105\" . mid . \"Cadmium resistance\"\n  | del \"KW-0108\" . mid . \"Calcium channel inhibitor\"\n  | del \"KW-0107\" . mid . \"Calcium channel\"\n  | del \"KW-0106\" . mid . \"Calcium\"\n  | del \"KW-0111\" . mid . \"Calcium/phospholipid-binding\"\n  | del \"KW-0109\" . mid . \"Calcium transport\"\n  | del \"KW-0112\" . mid . \"Calmodulin-binding\"\n  | del \"KW-0113\" . mid . \"Calvin cycle\"\n  | del \"KW-0116\" . mid . \"cAMP-binding\"\n  | del \"KW-0115\" . mid . \"cAMP biosynthesis\"\n  | del \"KW-0114\" . mid . \"cAMP\"\n  | del \"KW-0118\" . mid . \"Capsid assembly\"\n  | del \"KW-0917\" . mid . \"Capsid maturation\"\n  | del \"KW-0167\" . mid . \"Capsid protein\"\n  | del \"KW-0119\" . mid . \"Carbohydrate metabolism\"\n  | del \"KW-0120\" . mid . \"Carbon dioxide fixation\"\n  | del \"KW-0121\" . mid . \"Carboxypeptidase\"\n  | del \"KW-0122\" . mid . \"Cardiomyopathy\"\n  | del \"KW-0123\" . mid . \"Cardiotoxin\"\n  | del \"KW-0124\" . mid . \"Carnitine biosynthesis\"\n  | del \"KW-0125\" . mid . \"Carotenoid biosynthesis\"\n  | del \"KW-0898\" . mid . \"Cataract\"\n  | del \"KW-0127\" . mid . \"Catecholamine biosynthesis\"\n  | del \"KW-0128\" . mid . \"Catecholamine metabolism\"\n  | del \"KW-0129\" . mid . \"CBS domain\"\n  | del \"KW-0130\" . mid . \"Cell adhesion\"\n  | del \"KW-0131\" . mid . \"Cell cycle\"\n  | del \"KW-0132\" . mid . \"Cell division\"\n  | del \"KW-0133\" . mid . \"Cell shape\"\n  | del \"KW-0135\" . mid . \"Cellulose biosynthesis\"\n  | del \"KW-0136\" . mid . \"Cellulose degradation\"\n  | del \"KW-0134\" . mid . \"Cell wall\"\n  | del \"KW-0137\" . mid . \"Centromere\"\n  | del \"KW-0138\" . mid . \"CF(0)\"\n  | del \"KW-0139\" . mid . \"CF(1)\"\n  | del \"KW-0142\" . mid . \"cGMP-binding\"\n  | del \"KW-0141\" . mid . \"cGMP biosynthesis\"\n  | del \"KW-0140\" . mid . \"cGMP\"\n  | del \"KW-0143\" . mid . \"Chaperone\"\n  | del \"KW-0144\" . mid . \"Charcot-Marie-Tooth disease\"\n  | del \"KW-0145\" . mid . \"Chemotaxis\"\n  | del \"KW-0147\" . mid . \"Chitin-binding\"\n  | del \"KW-0146\" . mid . \"Chitin degradation\"\n  | del \"KW-0870\" . mid . \"Chloride channel inhibitor\"\n  | del \"KW-0869\" . mid . \"Chloride channel\"\n  | del \"KW-0868\" . mid . \"Chloride\"\n  | del \"KW-0149\" . mid . \"Chlorophyll biosynthesis\"\n  | del \"KW-0881\" . mid . \"Chlorophyll catabolism\"\n  | del \"KW-0148\" . mid . \"Chlorophyll\"\n  | del \"KW-0150\" . mid . \"Chloroplast\"\n  | del \"KW-0151\" . mid . \"Chlorosome\"\n  | del \"KW-0152\" . mid . \"Cholesterol biosynthesis\"\n  | del \"KW-0153\" . mid . \"Cholesterol metabolism\"\n  | del \"KW-0891\" . mid . \"Chondrogenesis\"\n  | del \"KW-0155\" . mid . \"Chromate resistance\"\n  | del \"KW-0156\" . mid . \"Chromatin regulator\"\n  | del \"KW-0157\" . mid . \"Chromophore\"\n  | del \"KW-0957\" . mid . \"Chromoplast\"\n  | del \"KW-0158\" . mid . \"Chromosomal protein\"\n  | del \"KW-0160\" . mid . \"Chromosomal rearrangement\"\n  | del \"KW-0159\" . mid . \"Chromosome partition\"\n  | del \"KW-0161\" . mid . \"Chronic granulomatous disease\"\n  | del \"KW-0162\" . mid . \"Chylomicron\"\n  | del \"KW-0163\" . mid . \"Citrate utilization\"\n  | del \"KW-0164\" . mid . \"Citrullination\"\n  | del \"KW-0165\" . mid . \"Cleavage on pair of basic residues\"\n  | del \"KW-0168\" . mid . \"Coated pits\"\n  | del \"KW-0169\" . mid . \"Cobalamin biosynthesis\"\n  | del \"KW-0846\" . mid . \"Cobalamin\"\n  | del \"KW-0170\" . mid . \"Cobalt\"\n  | del \"KW-0171\" . mid . \"Cobalt transport\"\n  | del \"KW-0172\" . mid . \"Cockayne syndrome\"\n  | del \"KW-0173\" . mid . \"Coenzyme A biosynthesis\"\n  | del \"KW-0174\" . mid . \"Coenzyme M biosynthesis\"\n  | del \"KW-0175\" . mid . \"Coiled coil\"\n  | del \"KW-0177\" . mid . \"Collagen degradation\"\n  | del \"KW-0176\" . mid . \"Collagen\"\n  | del \"KW-0178\" . mid . \"Competence\"\n  | del \"KW-0179\" . mid . \"Complement alternate pathway\"\n  | del \"KW-0180\" . mid . \"Complement pathway\"\n  | del \"KW-0181\" . mid . \"Complete proteome\"\n  | del \"KW-0182\" . mid . \"Cone-rod dystrophy\"\n  | del \"KW-0954\" . mid . \"Congenital adrenal hyperplasia\"\n  | del \"KW-0900\" . mid . \"Congenital disorder of glycosylation\"\n  | del \"KW-0912\" . mid . \"Congenital muscular dystrophy\"\n  | del \"KW-0183\" . mid . \"Conidiation\"\n  | del \"KW-0184\" . mid . \"Conjugation\"\n  | del \"KW-0186\" . mid . \"Copper\"\n  | del \"KW-0187\" . mid . \"Copper transport\"\n  | del \"KW-0188\" . mid . \"Copulatory plug\"\n  | del \"KW-0189\" . mid . \"Core protein\"\n  | del \"KW-0190\" . mid . \"Covalent protein-DNA linkage\"\n  | del \"KW-0191\" . mid . \"Covalent protein-RNA linkage\"\n  | del \"KW-0192\" . mid . \"Crown gall tumor\"\n  | del \"KW-0885\" . mid . \"CTQ\"\n  | del \"KW-0193\" . mid . \"Cuticle\"\n  | del \"KW-0194\" . mid . \"Cyanelle\"\n  | del \"KW-0195\" . mid . \"Cyclin\"\n  | del \"KW-0196\" . mid . \"Cycloheximide resistance\"\n  | del \"KW-0197\" . mid . \"Cyclosporin\"\n  | del \"KW-0198\" . mid . \"Cysteine biosynthesis\"\n  | del \"KW-0199\" . mid . \"Cystinuria\"\n  | del \"KW-0200\" . mid . \"Cytadherence\"\n  | del \"KW-0201\" . mid . \"Cytochrome c-type biogenesis\"\n  | del \"KW-0202\" . mid . \"Cytokine\"\n  | del \"KW-0203\" . mid . \"Cytokinin biosynthesis\"\n  | del \"KW-0932\" . mid . \"Cytokinin signaling pathway\"\n  | del \"KW-0204\" . mid . \"Cytolysis\"\n  | del \"KW-0205\" . mid . \"Cytosine metabolism\"\n  | del \"KW-0206\" . mid . \"Cytoskeleton\"\n  | del \"KW-0208\" . mid . \"D-amino acid\"\n  | del \"KW-0209\" . mid . \"Deafness\"\n  | del \"KW-0210\" . mid . \"Decarboxylase\"\n  | del \"KW-0211\" . mid . \"Defensin\"\n  | del \"KW-0213\" . mid . \"Dejerine-Sottas syndrome\"\n  | del \"KW-0214\" . mid . \"Dental caries\"\n  | del \"KW-0215\" . mid . \"Deoxyribonucleotide synthesis\"\n  | del \"KW-0911\" . mid . \"Desmin-related myopathy\"\n  | del \"KW-0216\" . mid . \"Detoxification\"\n  | del \"KW-0217\" . mid . \"Developmental protein\"\n  | del \"KW-0218\" . mid . \"Diabetes insipidus\"\n  | del \"KW-0219\" . mid . \"Diabetes mellitus\"\n  | del \"KW-0220\" . mid . \"Diaminopimelate biosynthesis\"\n  | del \"KW-0221\" . mid . \"Differentiation\"\n  | del \"KW-0222\" . mid . \"Digestion\"\n  | del \"KW-0223\" . mid . \"Dioxygenase\"\n  | del \"KW-0224\" . mid . \"Dipeptidase\"\n  | del \"KW-0903\" . mid . \"Direct protein sequencing\"\n  | del \"KW-0225\" . mid . \"Disease mutation\"\n  | del \"KW-0238\" . mid . \"DNA-binding\"\n  | del \"KW-0226\" . mid . \"DNA condensation\"\n  | del \"KW-0227\" . mid . \"DNA damage\"\n  | del \"KW-0239\" . mid . \"DNA-directed DNA polymerase\"\n  | del \"KW-0240\" . mid . \"DNA-directed RNA polymerase\"\n  | del \"KW-0228\" . mid . \"DNA excision\"\n  | del \"KW-0229\" . mid . \"DNA integration\"\n  | del \"KW-0230\" . mid . \"DNA invertase\"\n  | del \"KW-0231\" . mid . \"DNA packaging\"\n  | del \"KW-0233\" . mid . \"DNA recombination\"\n  | del \"KW-0234\" . mid . \"DNA repair\"\n  | del \"KW-0236\" . mid . \"DNA replication inhibitor\"\n  | del \"KW-0235\" . mid . \"DNA replication\"\n  | del \"KW-0237\" . mid . \"DNA synthesis\"\n  | del \"KW-0241\" . mid . \"Down syndrome\"\n  | del \"KW-0242\" . mid . \"Dwarfism\"\n  | del \"KW-0243\" . mid . \"Dynein\"\n  | del \"KW-0244\" . mid . \"Early protein\"\n  | del \"KW-0038\" . mid . \"Ectodermal dysplasia\"\n  | del \"KW-0245\" . mid . \"EGF-like domain\"\n  | del \"KW-0248\" . mid . \"Ehlers-Danlos syndrome\"\n  | del \"KW-0249\" . mid . \"Electron transport\"\n  | del \"KW-0250\" . mid . \"Elliptocytosis\"\n  | del \"KW-0251\" . mid . \"Elongation factor\"\n  | del \"KW-0254\" . mid . \"Endocytosis\"\n  | del \"KW-0255\" . mid . \"Endonuclease\"\n  | del \"KW-0256\" . mid . \"Endoplasmic reticulum\"\n  | del \"KW-0257\" . mid . \"Endorphin\"\n  | del \"KW-0259\" . mid . \"Enterobactin biosynthesis\"\n  | del \"KW-0260\" . mid . \"Enterotoxin\"\n  | del \"KW-0261\" . mid . \"Envelope protein\"\n  | del \"KW-0263\" . mid . \"Epidermolysis bullosa\"\n  | del \"KW-0887\" . mid . \"Epilepsy\"\n  | del \"KW-0931\" . mid . \"ER-Golgi transport\"\n  | del \"KW-0895\" . mid . \"ERV\"\n  | del \"KW-0265\" . mid . \"Erythrocyte maturation\"\n  | del \"KW-0266\" . mid . \"Ethylene biosynthesis\"\n  | del \"KW-0936\" . mid . \"Ethylene signaling pathway\"\n  | del \"KW-0267\" . mid . \"Excision nuclease\"\n  | del \"KW-0268\" . mid . \"Exocytosis\"\n  | del \"KW-0269\" . mid . \"Exonuclease\"\n  | del \"KW-0270\" . mid . \"Exopolysaccharide synthesis\"\n  | del \"KW-0271\" . mid . \"Exosome\"\n  | del \"KW-0952\" . mid . \"Extinct organism protein\"\n  | del \"KW-0272\" . mid . \"Extracellular matrix\"\n  | del \"KW-0273\" . mid . \"Eye lens protein\"\n  | del \"KW-0274\" . mid . \"FAD\"\n  | del \"KW-0951\" . mid . \"Familial hemophagocytic lymphohistiocytosis\"\n  | del \"KW-0923\" . mid . \"Fanconi anemia\"\n  | del \"KW-0275\" . mid . \"Fatty acid biosynthesis\"\n  | del \"KW-0276\" . mid . \"Fatty acid metabolism\"\n  | del \"KW-0278\" . mid . \"Fertilization\"\n  | del \"KW-0279\" . mid . \"Fiber protein\"\n  | del \"KW-0280\" . mid . \"Fibrinolysis\"\n  | del \"KW-0281\" . mid . \"Fimbria\"\n  | del \"KW-0283\" . mid . \"Flagellar rotation\"\n  | del \"KW-0282\" . mid . \"Flagellum\"\n  | del \"KW-0284\" . mid . \"Flavonoid biosynthesis\"\n  | del \"KW-0285\" . mid . \"Flavoprotein\"\n  | del \"KW-0286\" . mid . \"Flight\"\n  | del \"KW-0287\" . mid . \"Flowering\"\n  | del \"KW-0288\" . mid . \"FMN\"\n  | del \"KW-0290\" . mid . \"Folate-binding\"\n  | del \"KW-0289\" . mid . \"Folate biosynthesis\"\n  | del \"KW-0291\" . mid . \"Formylation\"\n  | del \"KW-0293\" . mid . \"Fruiting body\"\n  | del \"KW-0292\" . mid . \"Fruit ripening\"\n  | del \"KW-0294\" . mid . \"Fucose metabolism\"\n  | del \"KW-0295\" . mid . \"Fungicide\"\n  | del \"KW-0296\" . mid . \"Fusion protein\"\n  | del \"KW-0298\" . mid . \"Galactitol metabolism\"\n  | del \"KW-0299\" . mid . \"Galactose metabolism\"\n  | del \"KW-0301\" . mid . \"Gamma-carboxyglutamic acid\"\n  | del \"KW-0303\" . mid . \"Gap junction\"\n  | del \"KW-0302\" . mid . \"Gap protein\"\n  | del \"KW-0305\" . mid . \"Gaseous exchange\"\n  | del \"KW-0306\" . mid . \"Gastrulation\"\n  | del \"KW-0304\" . mid . \"Gas vesicle\"\n  | del \"KW-0307\" . mid . \"Gaucher disease\"\n  | del \"KW-0308\" . mid . \"Genetically modified food\"\n  | del \"KW-0309\" . mid . \"Germination\"\n  | del \"KW-0939\" . mid . \"Gibberellin signaling pathway\"\n  | del \"KW-0955\" . mid . \"Glaucoma\"\n  | del \"KW-0311\" . mid . \"Gluconate utilization\"\n  | del \"KW-0312\" . mid . \"Gluconeogenesis\"\n  | del \"KW-0313\" . mid . \"Glucose metabolism\"\n  | del \"KW-0314\" . mid . \"Glutamate biosynthesis\"\n  | del \"KW-0315\" . mid . \"Glutamine amidotransferase\"\n  | del \"KW-0316\" . mid . \"Glutaricaciduria\"\n  | del \"KW-0317\" . mid . \"Glutathione biosynthesis\"\n  | del \"KW-0318\" . mid . \"Glutathionylation\"\n  | del \"KW-0319\" . mid . \"Glycerol metabolism\"\n  | del \"KW-0320\" . mid . \"Glycogen biosynthesis\"\n  | del \"KW-0321\" . mid . \"Glycogen metabolism\"\n  | del \"KW-0322\" . mid . \"Glycogen storage disease\"\n  | del \"KW-0323\" . mid . \"Glycolate pathway\"\n  | del \"KW-0324\" . mid . \"Glycolysis\"\n  | del \"KW-0325\" . mid . \"Glycoprotein\"\n  | del \"KW-0326\" . mid . \"Glycosidase\"\n  | del \"KW-0327\" . mid . \"Glycosome\"\n  | del \"KW-0328\" . mid . \"Glycosyltransferase\"\n  | del \"KW-0329\" . mid . \"Glyoxylate bypass\"\n  | del \"KW-0330\" . mid . \"Glyoxysome\"\n  | del \"KW-0331\" . mid . \"GM2-gangliosidosis\"\n  | del \"KW-0332\" . mid . \"GMP biosynthesis\"\n  | del \"KW-0333\" . mid . \"Golgi apparatus\"\n  | del \"KW-0334\" . mid . \"Gonadal differentiation\"\n  | del \"KW-0335\" . mid . \"Gout\"\n  | del \"KW-0337\" . mid . \"GPI-anchor biosynthesis\"\n  | del \"KW-0336\" . mid . \"GPI-anchor\"\n  | del \"KW-0297\" . mid . \"G-protein coupled receptor\"\n  | del \"KW-0338\" . mid . \"Growth arrest\"\n  | del \"KW-0340\" . mid . \"Growth factor binding\"\n  | del \"KW-0339\" . mid . \"Growth factor\"\n  | del \"KW-0341\" . mid . \"Growth regulation\"\n  | del \"KW-0343\" . mid . \"GTPase activation\"\n  | del \"KW-0342\" . mid . \"GTP-binding\"\n  | del \"KW-0344\" . mid . \"Guanine-nucleotide releasing factor\"\n  | del \"KW-0345\" . mid . \"HDL\"\n  | del \"KW-0347\" . mid . \"Helicase\"\n  | del \"KW-0348\" . mid . \"Hemagglutinin\"\n  | del \"KW-0350\" . mid . \"Heme biosynthesis\"\n  | del \"KW-0349\" . mid . \"Heme\"\n  | del \"KW-0351\" . mid . \"Hemoglobin-binding\"\n  | del \"KW-0353\" . mid . \"Hemolymph clotting\"\n  | del \"KW-0354\" . mid . \"Hemolysis\"\n  | del \"KW-0355\" . mid . \"Hemophilia\"\n  | del \"KW-0356\" . mid . \"Hemostasis\"\n  | del \"KW-0357\" . mid . \"Heparan sulfate\"\n  | del \"KW-0358\" . mid . \"Heparin-binding\"\n  | del \"KW-0359\" . mid . \"Herbicide resistance\"\n  | del \"KW-0360\" . mid . \"Hereditary hemolytic anemia\"\n  | del \"KW-0361\" . mid . \"Hereditary multiple exostoses\"\n  | del \"KW-0362\" . mid . \"Hereditary nonpolyposis colorectal cancer\"\n  | del \"KW-0890\" . mid . \"Hereditary spastic paraplegia\"\n  | del \"KW-0363\" . mid . \"Hermansky-Pudlak syndrome\"\n  | del \"KW-0364\" . mid . \"Heterocyst\"\n  | del \"KW-0366\" . mid . \"Hexon-associated protein\"\n  | del \"KW-0365\" . mid . \"Hexon protein\"\n  | del \"KW-0909\" . mid . \"Hibernation\"\n  | del \"KW-0367\" . mid . \"Hirschsprung disease\"\n  | del \"KW-0368\" . mid . \"Histidine biosynthesis\"\n  | del \"KW-0369\" . mid . \"Histidine metabolism\"\n  | del \"KW-0370\" . mid . \"Holoprosencephaly\"\n  | del \"KW-0371\" . mid . \"Homeobox\"\n  | del \"KW-0372\" . mid . \"Hormone\"\n  | del \"KW-0945\" . mid . \"Host-virus interaction\"\n  | del \"KW-0373\" . mid . \"Hyaluronic acid\"\n  | del \"KW-0374\" . mid . \"Hybridoma\"\n  | del \"KW-0375\" . mid . \"Hydrogen ion transport\"\n  | del \"KW-0377\" . mid . \"Hydrogenosome\"\n  | del \"KW-0376\" . mid . \"Hydrogen peroxide\"\n  | del \"KW-0378\" . mid . \"Hydrolase\"\n  | del \"KW-0379\" . mid . \"Hydroxylation\"\n  | del \"KW-0380\" . mid . \"Hyperlipidemia\"\n  | del \"KW-0928\" . mid . \"Hypersensitive response elicitation\"\n  | del \"KW-0381\" . mid . \"Hypersensitive response\"\n  | del \"KW-0382\" . mid . \"Hypotensive agent\"\n  | del \"KW-0384\" . mid . \"Hypothetical protein\"\n  | del \"KW-0386\" . mid . \"Hypusine biosynthesis\"\n  | del \"KW-0385\" . mid . \"Hypusine\"\n  | del \"KW-0387\" . mid . \"Ice nucleation\"\n  | del \"KW-0388\" . mid . \"IgA-binding protein\"\n  | del \"KW-0389\" . mid . \"IgE-binding protein\"\n  | del \"KW-0390\" . mid . \"IgG-binding protein\"\n  | del \"KW-0391\" . mid . \"Immune response\"\n  | del \"KW-0392\" . mid . \"Immunoglobulin C region\"\n  | del \"KW-0393\" . mid . \"Immunoglobulin domain\"\n  | del \"KW-0394\" . mid . \"Immunoglobulin V region\"\n  | del \"KW-0395\" . mid . \"Inflammatory response\"\n  | del \"KW-0396\" . mid . \"Initiation factor\"\n  | del \"KW-0399\" . mid . \"Innate immunity\"\n  | del \"KW-0397\" . mid . \"Inner membrane\"\n  | del \"KW-0398\" . mid . \"Inositol biosynthesis\"\n  | del \"KW-0401\" . mid . \"Integrin\"\n  | del \"KW-0922\" . mid . \"Interferon antiviral system evasion\"\n  | del \"KW-0402\" . mid . \"Interferon induction\"\n  | del \"KW-0403\" . mid . \"Intermediate filament\"\n  | del \"KW-0404\" . mid . \"Intron homing\"\n  | del \"KW-0405\" . mid . \"Iodination\"\n  | del \"KW-0872\" . mid . \"Ionic channel inhibitor\"\n  | del \"KW-0407\" . mid . \"Ionic channel\"\n  | del \"KW-0406\" . mid . \"Ion transport\"\n  | del \"KW-0408\" . mid . \"Iron\"\n  | del \"KW-0409\" . mid . \"Iron storage\"\n  | del \"KW-0411\" . mid . \"Iron-sulfur\"\n  | del \"KW-0410\" . mid . \"Iron transport\"\n  | del \"KW-0412\" . mid . \"Isoleucine biosynthesis\"\n  | del \"KW-0413\" . mid . \"Isomerase\"\n  | del \"KW-0414\" . mid . \"Isoprene biosynthesis\"\n  | del \"KW-0956\" . mid . \"Kallmann syndrome\"\n  | del \"KW-0415\" . mid . \"Karyogamy\"\n  | del \"KW-0880\" . mid . \"Kelch repeat\"\n  | del \"KW-0417\" . mid . \"Keratinization\"\n  | del \"KW-0416\" . mid . \"Keratin\"\n  | del \"KW-0418\" . mid . \"Kinase\"\n  | del \"KW-0419\" . mid . \"Kinetoplast\"\n  | del \"KW-0420\" . mid . \"Kringle\"\n  | del \"KW-0953\" . mid . \"Lacrimo-auriculo-dento-digital syndrome\"\n  | del \"KW-0421\" . mid . \"Lactation\"\n  | del \"KW-0422\" . mid . \"Lactose biosynthesis\"\n  | del \"KW-0423\" . mid . \"Lactose metabolism\"\n  | del \"KW-0424\" . mid . \"Laminin EGF-like domain\"\n  | del \"KW-0425\" . mid . \"Lantibiotic\"\n  | del \"KW-0426\" . mid . \"Late protein\"\n  | del \"KW-0427\" . mid . \"LDL\"\n  | del \"KW-0428\" . mid . \"Leader peptide\"\n  | del \"KW-0901\" . mid . \"Leber congenital amaurosis\"\n  | del \"KW-0429\" . mid . \"Leber hereditary optic neuropathy\"\n  | del \"KW-0430\" . mid . \"Lectin\"\n  | del \"KW-0431\" . mid . \"Leigh syndrome\"\n  | del \"KW-0432\" . mid . \"Leucine biosynthesis\"\n  | del \"KW-0433\" . mid . \"Leucine-rich repeat\"\n  | del \"KW-0434\" . mid . \"Leukotriene biosynthesis\"\n  | del \"KW-0435\" . mid . \"Li-Fraumeni syndrome\"\n  | del \"KW-0436\" . mid . \"Ligase\"\n  | del \"KW-0437\" . mid . \"Light-harvesting polypeptide\"\n  | del \"KW-0438\" . mid . \"Lignin biosynthesis\"\n  | del \"KW-0439\" . mid . \"Lignin degradation\"\n  | del \"KW-0947\" . mid . \"Limb-girdle muscular dystrophy\"\n  | del \"KW-0440\" . mid . \"LIM domain\"\n  | del \"KW-0441\" . mid . \"Lipid A biosynthesis\"\n  | del \"KW-0446\" . mid . \"Lipid-binding\"\n  | del \"KW-0442\" . mid . \"Lipid degradation\"\n  | del \"KW-0443\" . mid . \"Lipid metabolism\"\n  | del \"KW-0444\" . mid . \"Lipid synthesis\"\n  | del \"KW-0445\" . mid . \"Lipid transport\"\n  | del \"KW-0448\" . mid . \"Lipopolysaccharide biosynthesis\"\n  | del \"KW-0449\" . mid . \"Lipoprotein\"\n  | del \"KW-0450\" . mid . \"Lipoyl\"\n  | del \"KW-0451\" . mid . \"Lissencephaly\"\n  | del \"KW-0452\" . mid . \"Lithium\"\n  | del \"KW-0454\" . mid . \"Long QT syndrome\"\n  | del \"KW-0886\" . mid . \"LTQ\"\n  | del \"KW-0455\" . mid . \"Luminescence\"\n  | del \"KW-0456\" . mid . \"Lyase\"\n  | del \"KW-0457\" . mid . \"Lysine biosynthesis\"\n  | del \"KW-0458\" . mid . \"Lysosome\"\n  | del \"KW-0460\" . mid . \"Magnesium\"\n  | del \"KW-0461\" . mid . \"Malaria\"\n  | del \"KW-0462\" . mid . \"Maltose metabolism\"\n  | del \"KW-0463\" . mid . \"Mandelate pathway\"\n  | del \"KW-0464\" . mid . \"Manganese\"\n  | del \"KW-0465\" . mid . \"Mannose-binding\"\n  | del \"KW-0466\" . mid . \"Maple syrup urine disease\"\n  | del \"KW-0467\" . mid . \"Mast cell degranulation\"\n  | del \"KW-0469\" . mid . \"Meiosis\"\n  | del \"KW-0470\" . mid . \"Melanin biosynthesis\"\n  | del \"KW-0867\" . mid . \"MELAS syndrome\"\n  | del \"KW-0471\" . mid . \"Melatonin biosynthesis\"\n  | del \"KW-0473\" . mid . \"Membrane attack complex\"\n  | del \"KW-0472\" . mid . \"Membrane\"\n  | del \"KW-0474\" . mid . \"Menaquinone biosynthesis\"\n  | del \"KW-0475\" . mid . \"Mercuric resistance\"\n  | del \"KW-0476\" . mid . \"Mercury\"\n  | del \"KW-0477\" . mid . \"Merozoite\"\n  | del \"KW-0478\" . mid . \"Metachromatic leukodystrophy\"\n  | del \"KW-0479\" . mid . \"Metal-binding\"\n  | del \"KW-0481\" . mid . \"Metalloenzyme inhibitor\"\n  | del \"KW-0483\" . mid . \"Metalloprotease inhibitor\"\n  | del \"KW-0482\" . mid . \"Metalloprotease\"\n  | del \"KW-0480\" . mid . \"Metal-thiolate cluster\"\n  | del \"KW-0484\" . mid . \"Methanogenesis\"\n  | del \"KW-0485\" . mid . \"Methanol utilization\"\n  | del \"KW-0486\" . mid . \"Methionine biosynthesis\"\n  | del \"KW-0487\" . mid . \"Methotrexate resistance\"\n  | del \"KW-0488\" . mid . \"Methylation\"\n  | del \"KW-0489\" . mid . \"Methyltransferase\"\n  | del \"KW-0491\" . mid . \"MHC II\"\n  | del \"KW-0490\" . mid . \"MHC I\"\n  | del \"KW-0492\" . mid . \"Microsome\"\n  | del \"KW-0493\" . mid . \"Microtubule\"\n  | del \"KW-0494\" . mid . \"Milk protein\"\n  | del \"KW-0495\" . mid . \"Mineral balance\"\n  | del \"KW-0496\" . mid . \"Mitochondrion\"\n  | del \"KW-0497\" . mid . \"Mitogen\"\n  | del \"KW-0498\" . mid . \"Mitosis\"\n  | del \"KW-0499\" . mid . \"Mobility protein\"\n  | del \"KW-0501\" . mid . \"Molybdenum cofactor biosynthesis\"\n  | del \"KW-0500\" . mid . \"Molybdenum\"\n  | del \"KW-0502\" . mid . \"Monoclonal antibody\"\n  | del \"KW-0503\" . mid . \"Monooxygenase\"\n  | del \"KW-0504\" . mid . \"Morphogen\"\n  | del \"KW-0505\" . mid . \"Motor protein\"\n  | del \"KW-0506\" . mid . \"mRNA capping\"\n  | del \"KW-0507\" . mid . \"mRNA processing\"\n  | del \"KW-0508\" . mid . \"mRNA splicing\"\n  | del \"KW-0509\" . mid . \"mRNA transport\"\n  | del \"KW-0942\" . mid . \"Mucolipidosis\"\n  | del \"KW-0510\" . mid . \"Mucopolysaccharidosis\"\n  | del \"KW-0511\" . mid . \"Multifunctional enzyme\"\n  | del \"KW-0514\" . mid . \"Muscle protein\"\n  | del \"KW-0515\" . mid . \"Mutator protein\"\n  | del \"KW-0517\" . mid . \"Myogenesis\"\n  | del \"KW-0518\" . mid . \"Myosin\"\n  | del \"KW-0959\" . mid . \"Myotoxin\"\n  | del \"KW-0519\" . mid . \"Myristate\"\n  | del \"KW-0520\" . mid . \"NAD\"\n  | del \"KW-0521\" . mid . \"NADP\"\n  | del \"KW-0166\" . mid . \"Nematocyst\"\n  | del \"KW-0523\" . mid . \"Neurodegeneration\"\n  | del \"KW-0524\" . mid . \"Neurogenesis\"\n  | del \"KW-0525\" . mid . \"Neuronal ceroid lipofuscinosis\"\n  | del \"KW-0527\" . mid . \"Neuropeptide\"\n  | del \"KW-0528\" . mid . \"Neurotoxin\"\n  | del \"KW-0530\" . mid . \"Neurotransmitter biosynthesis\"\n  | del \"KW-0531\" . mid . \"Neurotransmitter degradation\"\n  | del \"KW-0529\" . mid . \"Neurotransmitter\"\n  | del \"KW-0532\" . mid . \"Neurotransmitter transport\"\n  | del \"KW-0533\" . mid . \"Nickel\"\n  | del \"KW-0921\" . mid . \"Nickel transport\"\n  | del \"KW-0534\" . mid . \"Nitrate assimilation\"\n  | del \"KW-0944\" . mid . \"Nitration\"\n  | del \"KW-0535\" . mid . \"Nitrogen fixation\"\n  | del \"KW-0536\" . mid . \"Nodulation\"\n  | del \"KW-0866\" . mid . \"Nonsense-mediated mRNA decay\"\n  | del \"KW-0914\" . mid . \"Notch signaling pathway\"\n  | del \"KW-0906\" . mid . \"Nuclear pore complex\"\n  | del \"KW-0539\" . mid . \"Nuclear protein\"\n  | del \"KW-0540\" . mid . \"Nuclease\"\n  | del \"KW-0542\" . mid . \"Nucleomorph\"\n  | del \"KW-0544\" . mid . \"Nucleosome core\"\n  | del \"KW-0547\" . mid . \"Nucleotide-binding\"\n  | del \"KW-0545\" . mid . \"Nucleotide biosynthesis\"\n  | del \"KW-0546\" . mid . \"Nucleotide metabolism\"\n  | del \"KW-0548\" . mid . \"Nucleotidyltransferase\"\n  | del \"KW-0549\" . mid . \"Nylon degradation\"\n  | del \"KW-0550\" . mid . \"Obesity\"\n  | del \"KW-0551\" . mid . \"Oil body\"\n  | del \"KW-0552\" . mid . \"Olfaction\"\n  | del \"KW-0553\" . mid . \"Oncogene\"\n  | del \"KW-0554\" . mid . \"One-carbon metabolism\"\n  | del \"KW-0896\" . mid . \"Oogenesis\"\n  | del \"KW-0555\" . mid . \"Opioid peptide\"\n  | del \"KW-0556\" . mid . \"Organic radical\"\n  | del \"KW-0892\" . mid . \"Osteogenesis\"\n  | del \"KW-0557\" . mid . \"Outer membrane\"\n  | del \"KW-0558\" . mid . \"Oxidation\"\n  | del \"KW-0560\" . mid . \"Oxidoreductase\"\n  | del \"KW-0561\" . mid . \"Oxygen transport\"\n  | del \"KW-0925\" . mid . \"Oxylipin biosynthesis\"\n  | del \"KW-0563\" . mid . \"Paired box\"\n  | del \"KW-0562\" . mid . \"Pair-rule protein\"\n  | del \"KW-0564\" . mid . \"Palmitate\"\n  | del \"KW-0566\" . mid . \"Pantothenate biosynthesis\"\n  | del \"KW-0907\" . mid . \"Parkinson disease\"\n  | del \"KW-0908\" . mid . \"Parkinsonism\"\n  | del \"KW-0568\" . mid . \"Pathogenesis-related protein\"\n  | del \"KW-0570\" . mid . \"Pentose shunt\"\n  | del \"KW-0571\" . mid . \"Peptide transport\"\n  | del \"KW-0572\" . mid . \"Peptidoglycan-anchor\"\n  | del \"KW-0573\" . mid . \"Peptidoglycan synthesis\"\n  | del \"KW-0574\" . mid . \"Periplasmic\"\n  | del \"KW-0575\" . mid . \"Peroxidase\"\n  | del \"KW-0958\" . mid . \"Peroxisome biogenesis disorder\"\n  | del \"KW-0576\" . mid . \"Peroxisome\"\n  | del \"KW-0577\" . mid . \"PHA biosynthesis\"\n  | del \"KW-0578\" . mid . \"Phage lysis protein\"\n  | del \"KW-0579\" . mid . \"Phage maturation\"\n  | del \"KW-0580\" . mid . \"Phage recognition\"\n  | del \"KW-0581\" . mid . \"Phagocytosis\"\n  | del \"KW-0582\" . mid . \"Pharmaceutical\"\n  | del \"KW-0583\" . mid . \"PHB biosynthesis\"\n  | del \"KW-0584\" . mid . \"Phenylalanine biosynthesis\"\n  | del \"KW-0585\" . mid . \"Phenylalanine catabolism\"\n  | del \"KW-0586\" . mid . \"Phenylketonuria\"\n  | del \"KW-0587\" . mid . \"Phenylpropanoid metabolism\"\n  | del \"KW-0590\" . mid . \"Pheromone-binding\"\n  | del \"KW-0588\" . mid . \"Pheromone\"\n  | del \"KW-0589\" . mid . \"Pheromone response\"\n  | del \"KW-0591\" . mid . \"Phorbol-ester binding\"\n  | del \"KW-0592\" . mid . \"Phosphate transport\"\n  | del \"KW-0593\" . mid . \"Phospholipase A2 inhibitor\"\n  | del \"KW-0594\" . mid . \"Phospholipid biosynthesis\"\n  | del \"KW-0595\" . mid . \"Phospholipid degradation\"\n  | del \"KW-0918\" . mid . \"Phosphonate transport\"\n  | del \"KW-0596\" . mid . \"Phosphopantetheine\"\n  | del \"KW-0597\" . mid . \"Phosphorylation\"\n  | del \"KW-0598\" . mid . \"Phosphotransferase system\"\n  | del \"KW-0599\" . mid . \"Photoprotein\"\n  | del \"KW-0600\" . mid . \"Photoreceptor protein\"\n  | del \"KW-0601\" . mid . \"Photorespiration\"\n  | del \"KW-0602\" . mid . \"Photosynthesis\"\n  | del \"KW-0604\" . mid . \"Photosystem II\"\n  | del \"KW-0603\" . mid . \"Photosystem I\"\n  | del \"KW-0605\" . mid . \"Phycobilisome\"\n  | del \"KW-0607\" . mid . \"Phytochrome signaling pathway\"\n  | del \"KW-0608\" . mid . \"Pigment\"\n  | del \"KW-0611\" . mid . \"Plant defense\"\n  | del \"KW-0612\" . mid . \"Plant toxin\"\n  | del \"KW-0615\" . mid . \"Plasmid copy control\"\n  | del \"KW-0614\" . mid . \"Plasmid\"\n  | del \"KW-0616\" . mid . \"Plasmid partition\"\n  | del \"KW-0617\" . mid . \"Plasminogen activation\"\n  | del \"KW-0934\" . mid . \"Plastid\"\n  | del \"KW-0618\" . mid . \"Plastoquinone\"\n  | del \"KW-0620\" . mid . \"Polyamine biosynthesis\"\n  | del \"KW-0621\" . mid . \"Polymorphism\"\n  | del \"KW-0622\" . mid . \"Polyneuropathy\"\n  | del \"KW-0624\" . mid . \"Polysaccharide degradation\"\n  | del \"KW-0625\" . mid . \"Polysaccharide transport\"\n  | del \"KW-0626\" . mid . \"Porin\"\n  | del \"KW-0627\" . mid . \"Porphyrin biosynthesis\"\n  | del \"KW-0628\" . mid . \"Postsynaptic membrane\"\n  | del \"KW-0629\" . mid . \"Postsynaptic neurotoxin\"\n  | del \"KW-0632\" . mid . \"Potassium channel inhibitor\"\n  | del \"KW-0631\" . mid . \"Potassium channel\"\n  | del \"KW-0630\" . mid . \"Potassium\"\n  | del \"KW-0633\" . mid . \"Potassium transport\"\n  | del \"KW-0884\" . mid . \"PQQ biosynthesis\"\n  | del \"KW-0634\" . mid . \"PQQ\"\n  | del \"KW-0635\" . mid . \"Pregnancy\"\n  | del \"KW-0636\" . mid . \"Prenylation\"\n  | del \"KW-0637\" . mid . \"Prenyltransferase\"\n  | del \"KW-0638\" . mid . \"Presynaptic neurotoxin\"\n  | del \"KW-0905\" . mid . \"Primary microcephaly\"\n  | del \"KW-0639\" . mid . \"Primosome\"\n  | del \"KW-0640\" . mid . \"Prion\"\n  | del \"KW-0935\" . mid . \"Progressive external ophthalmoplegia\"\n  | del \"KW-0641\" . mid . \"Proline biosynthesis\"\n  | del \"KW-0642\" . mid . \"Proline metabolism\"\n  | del \"KW-0643\" . mid . \"Prostaglandin biosynthesis\"\n  | del \"KW-0644\" . mid . \"Prostaglandin metabolism\"\n  | del \"KW-0646\" . mid . \"Protease inhibitor\"\n  | del \"KW-0645\" . mid . \"Protease\"\n  | del \"KW-0647\" . mid . \"Proteasome\"\n  | del \"KW-0648\" . mid . \"Protein biosynthesis\"\n  | del \"KW-0649\" . mid . \"Protein kinase inhibitor\"\n  | del \"KW-0650\" . mid . \"Protein phosphatase inhibitor\"\n  | del \"KW-0904\" . mid . \"Protein phosphatase\"\n  | del \"KW-0651\" . mid . \"Protein splicing\"\n  | del \"KW-0652\" . mid . \"Protein synthesis inhibitor\"\n  | del \"KW-0653\" . mid . \"Protein transport\"\n  | del \"KW-0654\" . mid . \"Proteoglycan\"\n  | del \"KW-0655\" . mid . \"Prothrombin activator\"\n  | del \"KW-0656\" . mid . \"Proto-oncogene\"\n  | del \"KW-0657\" . mid . \"Pseudohermaphroditism\"\n  | del \"KW-0658\" . mid . \"Purine biosynthesis\"\n  | del \"KW-0659\" . mid . \"Purine metabolism\"\n  | del \"KW-0660\" . mid . \"Purine salvage\"\n  | del \"KW-0661\" . mid . \"Putrescine biosynthesis\"\n  | del \"KW-0662\" . mid . \"Pyridine nucleotide biosynthesis\"\n  | del \"KW-0663\" . mid . \"Pyridoxal phosphate\"\n  | del \"KW-0664\" . mid . \"Pyridoxine biosynthesis\"\n  | del \"KW-0665\" . mid . \"Pyrimidine biosynthesis\"\n  | del \"KW-0666\" . mid . \"Pyrogen\"\n  | del \"KW-0668\" . mid . \"Pyropoikilocytosis\"\n  | del \"KW-0873\" . mid . \"Pyrrolidone carboxylic acid\"\n  | del \"KW-0669\" . mid . \"Pyrrolysine\"\n  | del \"KW-0670\" . mid . \"Pyruvate\"\n  | del \"KW-0671\" . mid . \"Queuosine biosynthesis\"\n  | del \"KW-0672\" . mid . \"Quinate metabolism\"\n  | del \"KW-0874\" . mid . \"Quinone\"\n  | del \"KW-0673\" . mid . \"Quorum sensing\"\n  | del \"KW-0674\" . mid . \"Reaction center\"\n  | del \"KW-0675\" . mid . \"Receptor\"\n  | del \"KW-0676\" . mid . \"Redox-active center\"\n  | del \"KW-0677\" . mid . \"Repeat\"\n  | del \"KW-0678\" . mid . \"Repressor\"\n  | del \"KW-0679\" . mid . \"Respiratory chain\"\n  | del \"KW-0680\" . mid . \"Restriction system\"\n  | del \"KW-0681\" . mid . \"Retinal protein\"\n  | del \"KW-0682\" . mid . \"Retinitis pigmentosa\"\n  | del \"KW-0683\" . mid . \"Retinol-binding\"\n  | del \"KW-0684\" . mid . \"Rhamnose metabolism\"\n  | del \"KW-0685\" . mid . \"Rhizomelic chondrodysplasia punctata\"\n  | del \"KW-0686\" . mid . \"Riboflavin biosynthesis\"\n  | del \"KW-0687\" . mid . \"Ribonucleoprotein\"\n  | del \"KW-0688\" . mid . \"Ribosomal frameshift\"\n  | del \"KW-0689\" . mid . \"Ribosomal protein\"\n  | del \"KW-0690\" . mid . \"Ribosome biogenesis\"\n  | del \"KW-0694\" . mid . \"RNA-binding\"\n  | del \"KW-0695\" . mid . \"RNA-directed DNA polymerase\"\n  | del \"KW-0696\" . mid . \"RNA-directed RNA polymerase\"\n  | del \"KW-0691\" . mid . \"RNA editing\"\n  | del \"KW-0943\" . mid . \"RNA-mediated gene silencing\"\n  | del \"KW-0692\" . mid . \"RNA repair\"\n  | del \"KW-0693\" . mid . \"RNA replication\"\n  | del \"KW-0697\" . mid . \"Rotamase\"\n  | del \"KW-0699\" . mid . \"rRNA-binding\"\n  | del \"KW-0698\" . mid . \"rRNA processing\"\n  | del \"KW-0949\" . mid . \"S-adenosyl-L-methionine\"\n  | del \"KW-0703\" . mid . \"Sarcoplasmic reticulum\"\n  | del \"KW-0704\" . mid . \"Schiff base\"\n  | del \"KW-0705\" . mid . \"SCID\"\n  | del \"KW-0964\" . mid . \"Secreted\"\n  | del \"KW-0708\" . mid . \"Seed storage protein\"\n  | del \"KW-0709\" . mid . \"Segmentation polarity protein\"\n  | del \"KW-0711\" . mid . \"Selenium\"\n  | del \"KW-0712\" . mid . \"Selenocysteine\"\n  | del \"KW-0713\" . mid . \"Self-incompatibility\"\n  | del \"KW-0716\" . mid . \"Sensory transduction\"\n  | del \"KW-0717\" . mid . \"Septation\"\n  | del \"KW-0718\" . mid . \"Serine biosynthesis\"\n  | del \"KW-0719\" . mid . \"Serine esterase\"\n  | del \"KW-0721\" . mid . \"Serine protease homolog\"\n  | del \"KW-0722\" . mid . \"Serine protease inhibitor\"\n  | del \"KW-0720\" . mid . \"Serine protease\"\n  | del \"KW-0723\" . mid . \"Serine/threonine-protein kinase\"\n  | del \"KW-0724\" . mid . \"Serotonin biosynthesis\"\n  | del \"KW-0726\" . mid . \"Sexual differentiation\"\n  | del \"KW-0727\" . mid . \"SH2 domain\"\n  | del \"KW-0729\" . mid . \"SH3-binding\"\n  | del \"KW-0728\" . mid . \"SH3 domain\"\n  | del \"KW-0940\" . mid . \"Short QT syndrome\"\n  | del \"KW-0730\" . mid . \"Sialic acid\"\n  | del \"KW-0731\" . mid . \"Sigma factor\"\n  | del \"KW-0735\" . mid . \"Signal-anchor\"\n  | del \"KW-0732\" . mid . \"Signal\"\n  | del \"KW-0736\" . mid . \"Signalosome\"\n  | del \"KW-0733\" . mid . \"Signal recognition particle\"\n  | del \"KW-0734\" . mid . \"Signal transduction inhibitor\"\n  | del \"KW-0737\" . mid . \"Silk protein\"\n  | del \"KW-0701\" . mid . \"S-layer\"\n  | del \"KW-0702\" . mid . \"S-nitrosylation\"\n  | del \"KW-0738\" . mid . \"Sodium channel inhibitor\"\n  | del \"KW-0894\" . mid . \"Sodium channel\"\n  | del \"KW-0915\" . mid . \"Sodium\"\n  | del \"KW-0740\" . mid . \"Sodium/potassium transport\"\n  | del \"KW-0739\" . mid . \"Sodium transport\"\n  | del \"KW-0741\" . mid . \"SOS mutagenesis\"\n  | del \"KW-0742\" . mid . \"SOS response\"\n  | del \"KW-0744\" . mid . \"Spermatogenesis\"\n  | del \"KW-0745\" . mid . \"Spermidine biosynthesis\"\n  | del \"KW-0746\" . mid . \"Sphingolipid metabolism\"\n  | del \"KW-0950\" . mid . \"Spinocerebellar ataxia\"\n  | del \"KW-0747\" . mid . \"Spliceosome\"\n  | del \"KW-0748\" . mid . \"Sporozoite\"\n  | del \"KW-0749\" . mid . \"Sporulation\"\n  | del \"KW-0750\" . mid . \"Starch biosynthesis\"\n  | del \"KW-0751\" . mid . \"Stargardt disease\"\n  | del \"KW-0754\" . mid . \"Steroid-binding\"\n  | del \"KW-0752\" . mid . \"Steroid biosynthesis\"\n  | del \"KW-0753\" . mid . \"Steroid metabolism\"\n  | del \"KW-0755\" . mid . \"Steroidogenesis\"\n  | del \"KW-0756\" . mid . \"Sterol biosynthesis\"\n  | del \"KW-0757\" . mid . \"Stickler syndrome\"\n  | del \"KW-0758\" . mid . \"Storage protein\"\n  | del \"KW-0759\" . mid . \"Streptomycin biosynthesis\"\n  | del \"KW-0346\" . mid . \"Stress response\"\n  | del \"KW-0760\" . mid . \"Structural protein\"\n  | del \"KW-0762\" . mid . \"Sugar transport\"\n  | del \"KW-0763\" . mid . \"Sulfate respiration\"\n  | del \"KW-0764\" . mid . \"Sulfate transport\"\n  | del \"KW-0765\" . mid . \"Sulfation\"\n  | del \"KW-0766\" . mid . \"Superantigen\"\n  | del \"KW-0941\" . mid . \"Suppressor of RNA silencing\"\n  | del \"KW-0767\" . mid . \"Surface film\"\n  | del \"KW-0768\" . mid . \"Sushi\"\n  | del \"KW-0769\" . mid . \"Symport\"\n  | del \"KW-0770\" . mid . \"Synapse\"\n  | del \"KW-0771\" . mid . \"Synaptosome\"\n  | del \"KW-0772\" . mid . \"Systemic lupus erythematosus\"\n  | del \"KW-0919\" . mid . \"Taste\"\n  | del \"KW-0776\" . mid . \"Taste-modifying protein\"\n  | del \"KW-0876\" . mid . \"Taxol biosynthesis\"\n  | del \"KW-0920\" . mid . \"Tegument protein\"\n  | del \"KW-0777\" . mid . \"Teichoic acid biosynthesis\"\n  | del \"KW-0778\" . mid . \"Tellurium resistance\"\n  | del \"KW-0779\" . mid . \"Telomere\"\n  | del \"KW-0780\" . mid . \"Terminal addition\"\n  | del \"KW-0783\" . mid . \"Tetrahydrobiopterin biosynthesis\"\n  | del \"KW-0784\" . mid . \"Thiamine biosynthesis\"\n  | del \"KW-0785\" . mid . \"Thiamine catabolism\"\n  | del \"KW-0786\" . mid . \"Thiamine pyrophosphate\"\n  | del \"KW-0787\" . mid . \"Thick filament\"\n  | del \"KW-0882\" . mid . \"Thioester bond\"\n  | del \"KW-0883\" . mid . \"Thioether bond\"\n  | del \"KW-0789\" . mid . \"Thiol protease inhibitor\"\n  | del \"KW-0788\" . mid . \"Thiol protease\"\n  | del \"KW-0791\" . mid . \"Threonine biosynthesis\"\n  | del \"KW-0888\" . mid . \"Threonine protease\"\n  | del \"KW-0792\" . mid . \"Thrombophilia\"\n  | del \"KW-0793\" . mid . \"Thylakoid\"\n  | del \"KW-0795\" . mid . \"Thyroid hormone\"\n  | del \"KW-0893\" . mid . \"Thyroid hormones biosynthesis\"\n  | del \"KW-0796\" . mid . \"Tight junction\"\n  | del \"KW-0797\" . mid . \"Tissue remodeling\"\n  | del \"KW-0798\" . mid . \"TonB box\"\n  | del \"KW-0799\" . mid . \"Topoisomerase\"\n  | del \"KW-0800\" . mid . \"Toxin\"\n  | del \"KW-0801\" . mid . \"TPQ\"\n  | del \"KW-0802\" . mid . \"TPR repeat\"\n  | del \"KW-0889\" . mid . \"Transcription antitermination\"\n  | del \"KW-0804\" . mid . \"Transcription\"\n  | del \"KW-0805\" . mid . \"Transcription regulation\"\n  | del \"KW-0806\" . mid . \"Transcription termination\"\n  | del \"KW-0807\" . mid . \"Transducer\"\n  | del \"KW-0808\" . mid . \"Transferase\"\n  | del \"KW-0809\" . mid . \"Transit peptide\"\n  | del \"KW-0810\" . mid . \"Translation regulation\"\n  | del \"KW-0811\" . mid . \"Translocation\"\n  | del \"KW-0812\" . mid . \"Transmembrane\"\n  | del \"KW-0813\" . mid . \"Transport\"\n  | del \"KW-0814\" . mid . \"Transposable element\"\n  | del \"KW-0815\" . mid . \"Transposition\"\n  | del \"KW-0816\" . mid . \"Tricarboxylic acid cycle\"\n  | del \"KW-0817\" . mid . \"Trimethoprim resistance\"\n  | del \"KW-0818\" . mid . \"Triplet repeat expansion\"\n  | del \"KW-0820\" . mid . \"tRNA-binding\"\n  | del \"KW-0819\" . mid . \"tRNA processing\"\n  | del \"KW-0821\" . mid . \"Trypanosomiasis\"\n  | del \"KW-0822\" . mid . \"Tryptophan biosynthesis\"\n  | del \"KW-0823\" . mid . \"Tryptophan catabolism\"\n  | del \"KW-0824\" . mid . \"TTQ\"\n  | del \"KW-0825\" . mid . \"Tumor antigen\"\n  | del \"KW-0826\" . mid . \"Tungsten\"\n  | del \"KW-0902\" . mid . \"Two-component regulatory system\"\n  | del \"KW-0827\" . mid . \"Tyrosine biosynthesis\"\n  | del \"KW-0828\" . mid . \"Tyrosine catabolism\"\n  | del \"KW-0829\" . mid . \"Tyrosine-protein kinase\"\n  | del \"KW-0831\" . mid . \"Ubiquinone biosynthesis\"\n  | del \"KW-0830\" . mid . \"Ubiquinone\"\n  | del \"KW-0832\" . mid . \"Ubl conjugation\"\n  | del \"KW-0833\" . mid . \"Ubl conjugation pathway\"\n  | del \"KW-0834\" . mid . \"Unfolded protein response\"\n  | del \"KW-0835\" . mid . \"Urea cycle\"\n  | del \"KW-0836\" . mid . \"Usher syndrome\"\n  | del \"KW-0926\" . mid . \"Vacuole\"\n  | del \"KW-0837\" . mid . \"Vanadium\"\n  | del \"KW-0838\" . mid . \"Vasoactive\"\n  | del \"KW-0839\" . mid . \"Vasoconstrictor\"\n  | del \"KW-0840\" . mid . \"Vasodilator\"\n  | del \"KW-0899\" . mid . \"Viral immunoevasion\"\n  | del \"KW-0468\" . mid . \"Viral matrix protein\"\n  | del \"KW-0916\" . mid . \"Viral movement protein\"\n  | del \"KW-0543\" . mid . \"Viral nucleoprotein\"\n  | del \"KW-0842\" . mid . \"Viral occlusion body\"\n  | del \"KW-0946\" . mid . \"Virion protein\"\n  | del \"KW-0843\" . mid . \"Virulence\"\n  | del \"KW-0844\" . mid . \"Vision\"\n  | del \"KW-0845\" . mid . \"Vitamin A\"\n  | del \"KW-0847\" . mid . \"Vitamin C\"\n  | del \"KW-0848\" . mid . \"Vitamin D\"\n  | del \"KW-0850\" . mid . \"VLDL\"\n  | del \"KW-0851\" . mid . \"Voltage-gated channel\"\n  | del \"KW-0852\" . mid . \"von Willebrand disease\"\n  | del \"KW-0897\" . mid . \"Waardenburg syndrome\"\n  | del \"KW-0853\" . mid . \"WD repeat\"\n  | del \"KW-0855\" . mid . \"Whooping cough\"\n  | del \"KW-0856\" . mid . \"Williams-Beuren syndrome\"\n  | del \"KW-0879\" . mid . \"Wnt signaling pathway\"\n  | del \"KW-0857\" . mid . \"Xeroderma pigmentosum\"\n  | del \"KW-0858\" . mid . \"Xylan degradation\"\n  | del \"KW-0859\" . mid . \"Xylose metabolism\"\n  | del \"KW-0861\" . mid . \"Zellweger syndrome\"\n  | del \"KW-0863\" . mid . \"Zinc-finger\"\n  | del \"KW-0862\" . mid . \"Zinc\"\n  | del \"KW-0864\" . mid . \"Zinc transport\"\n  | del \"KW-0865\" . mid . \"Zymogen\" )\n\nlet kw_tag : string = tag \"KW\" \n\nlet kw_xml : lens = \n  let kw : lens = \n    Xml.raw_open NL1 \"keyword\" . \n    qdel SP \" \" . \n    del \"id=\\\"\" . kw_trans . \n    Xml.simple_close_tag \"keyword\" in\n  ins kw_tag . \n  iter_with_sqsp kw . \n  dot \n\nlet kw_line : lens = split_terminate kw_tag kw_xml\n\n(* unit tests for KW line *)\nlet kw_ascii : string = \n  \"KW   Complete proteome; Differentiation; Viral movement protein; Zymogen;\n  |KW   2Fe-2S.\" . \n  NL\n\nlet kw_xml : string = \n  NL . \n  \"  <keyword id=\\\"KW-0181\\\">Complete proteome</keyword>\n  |  <keyword id=\\\"KW-0221\\\">Differentiation</keyword>\n  |  <keyword id=\\\"KW-0916\\\">Viral movement protein</keyword>\n  |  <keyword id=\\\"KW-0865\\\">Zymogen</keyword>\n  |  <keyword id=\\\"KW-0001\\\">2Fe-2S</keyword>\"\n\ntest kw_line.get \n  kw_xml = kw_ascii\n\ntest kw_line.create \n  kw_ascii = kw_xml\n\nlet P12544_kw_ascii : string = \n  \"KW   3D-structure; Apoptosis; Cytolysis; Direct protein sequencing;\n  |KW   Glycoprotein; Hydrolase; Polymorphism; Protease; Secreted; Serine\n  |KW   protease; Signal; Zymogen.\" . \n  NL\n\nlet P12544_kw_xml : string = \n  NL . \n  \"  <keyword id=\\\"KW-0002\\\">3D-structure</keyword>\n  |  <keyword id=\\\"KW-0053\\\">Apoptosis</keyword>\n  |  <keyword id=\\\"KW-0204\\\">Cytolysis</keyword>\n  |  <keyword id=\\\"KW-0903\\\">Direct protein sequencing</keyword>\n  |  <keyword id=\\\"KW-0325\\\">Glycoprotein</keyword>\n  |  <keyword id=\\\"KW-0378\\\">Hydrolase</keyword>\n  |  <keyword id=\\\"KW-0621\\\">Polymorphism</keyword>\n  |  <keyword id=\\\"KW-0645\\\">Protease</keyword>\n  |  <keyword id=\\\"KW-0964\\\">Secreted</keyword>\n  |  <keyword id=\\\"KW-0720\\\">Serine protease</keyword>\n  |  <keyword id=\\\"KW-0732\\\">Signal</keyword>\n  |  <keyword id=\\\"KW-0865\\\">Zymogen</keyword>\"\n\ntest kw_line.get \n  P12544_kw_xml = P12544_kw_ascii\n\ntest kw_line.create \n  P12544_kw_ascii = P12544_kw_xml\n\n(* --------------------------------------------------------------------------- *)\n(* FT line *)\n(*** START \n\ntest \"----- FT line-----\" = ?\n\nlet ft_tag : string = tag \"FT\" \n\nlet num (sym:string) : lens = \n  ( space{4} . ins sym . DIGIT\n  || space{3} . ins sym . DIGIT{2}\n  || space{2} . ins sym . DIGIT{3}\n  || space{1} . ins sym . DIGIT{4}\n  ||            ins sym . DIGIT{5} ) \n\nlet ft_bound (name:string) : lens = \n  Xml.attrs_elt_no_kids NL3 name\n    ( Sort.perm_sort\n        #{lens}[(Xml.attr \"status\" (del \"less than\"));\n                (Xml.attr \"position\" (num \"<\"))]\n    || Sort.perm_sort\n        #{lens}[(Xml.attr \"status\" (del \"greater than\"));\n                (Xml.attr \"position\" (num \">\"))]\n    || Sort.perm_sort\n        #{lens}[(Xml.attr \"status\" (del \"uncertain\"));\n                (Xml.attr \"position\" (num \"?\"))]\n    || Xml.attr \"position\" (num \" \") )\n\nlet single_pos_cn : canonizer = \n  let NUM : regexp = stype (num \" \") in\n  canonizer_of_lens\n    begin\n      WS . \n      (\"<position\" <-> \"<begin\").\n      WSP . \n      \"position=\\\"\" . \n      dup1 NUM \n        (\"\\\"/><end position=\\\"\" . NUM)\n        (fun (s:string) -> \"\\\"/><end position=\\\"\" . s) . \n      \"\\\"/>\" \n    end\n\n(* clever position canonizer :-) *)\nlet double_pos : lens = ( ft_bound \"begin\" . space . ft_bound \"end\" )  \n\nlet pos_cn : canonizer = (canonizer_of_lens (stype double_pos)) | (single_pos_cn)\n\nlet ft_bounds : lens = \n  Xml.elt NL2 \"location\" \n    (left_quot pos_cn double_pos)\n\ntest ft_bounds.get\n  \"    <location>\n  |      <begin position=\\\"243\\\"/>\n  |      <end position=\\\"244\\\"/>\n  |    </location>\" \n= \"   243    244\"\n\ntest ft_bounds.get\n  \"    <location>\n  |       <position position=\\\"243\\\"/>\n  |    </location>\" \n= \"   243    243\"\n\nlet s7 : lens = ins \"       \"\n\nlet ft_original_variation : lens = \n  s7 . \n  ( Xml.simple_elt NL2 \"original\" UALPHANUMCHAR . \n    ins \" -> \" . \n    Xml.simple_elt NL2 \"variation\" UALPHANUMCHAR \n  | ins \"Missing\" ) . \n  space \n\nlet ft_normal_type : lens = \n  ( \"active site\"                         <-> \"ACT_SITE\" \n  | \"binding site\"                        <-> \"BINDING \" \n  | \"calcium-binding region\"              <-> \"CA_BIND \" \n  | \"chain\"                               <-> \"CHAIN   \" \n  | \"coiled-coil region\"                  <-> \"COILED  \" \n  | \"compositionally biased region\"       <-> \"COMPBIAS\" \n  | \"cross-link\"                          <-> \"CROSSLNK\" \n  | \"disulfide bond\"                      <-> \"DISULFID\" \n  | \"DNA-binding region\"                  <-> \"DNA_BIND\" \n  | \"domain\"                              <-> \"DOMAIN  \" \n  | \"glycosylation site\"                  <-> \"CARBOHYD\" \n  | \"helix\"                               <-> \"HELIX   \" \n  | \"initiator methionine\"                <-> \"INIT_MET\" \n  | \"lipid moiety-binding region\"         <-> \"LIPID   \" \n  | \"metal ion-binding site\"              <-> \"METAL   \" \n  | \"modified residue\"                    <-> \"MOD_RES \" \n  | \"non-consecutive residues\"            <-> \"NON_CONS\" \n  | \"non-terminal residue\"                <-> \"NON_TER \" \n  | \"nucleotide phosphate-binding region\" <-> \"NP_BIND \" \n  | \"peptide\"                             <-> \"PEPTIDE \" \n  | \"propeptide\"                          <-> \"PROPEP  \" \n  | \"region of interest\"                  <-> \"REGION  \" \n  | \"repeat\"                              <-> \"REPEAT  \" \n  | \"selenocysteine\"                      <-> \"SE_CYS  \" \n  | \"short sequence motif\"                <-> \"MOTIF   \" \n  | \"signal peptide\"                      <-> \"SIGNAL  \" \n  | \"site\"                                <-> \"SITE    \" \n  | \"strand\"                              <-> \"STRAND  \" \n  | \"topological domain\"                  <-> \"TOPO_DOM\" \n  | \"transit peptide\"                     <-> \"TRANSIT \" \n  | \"transmembrane region\"                <-> \"TRANSMEM\" \n  | \"turn\"                                <-> \"TURN    \" \n  | \"unsure residue\"                      <-> \"UNSURE  \" \n  | \"zinc finger region\"                  <-> \"ZN_FING \") . \n  space\n\nlet ft_variation_type : lens = \n  ( \"mutagenesis site\"  <-> \"MUTAGEN \" \n  | \"sequence conflict\" <-> \"CONFLICT\" \n  | \"sequence variant\"  <-> \"VARIANT \" \n  | \"splice variant\"    <-> \"VAR_SEQ \") . \n  space\n\nlet s29 : lens = ins \"                             \"\n\nlet ft_id : lens = \n  nl . ins ft_tag . s29 . \n  ins \"/FTId=\" . \n  [A-Z]{3} . \"_\" . [0-9]{6,10} . \n  dot\n\nlet ft_status : lens = \n    qualifiers . dot\n\nlet ft_description : lens =   \n  (* HACK !*)\n  [^<>\"\".&\\n]+ - (containing (vtype qualifiers))\n\nlet ft_aux (l:lens) (ty:lens) (body:lens) :  lens = \n  ( Xml.slow_attr4_elt_swap2 NL1 \"feature\"\n      \"type\" ty \n      \"description\" (l . ft_description)\n      \"status\" ft_status\n      \"id\" ft_id \n      body\n  | Xml.slow_attr3_elt_swap2 NL1 \"feature\"\n      \"type\" ty\n      \"description\" (l . ft_description . dot)\n      \"id\" ft_id\n      body\n  | Xml.slow_attr3_elt_swap2 NL1 \"feature\"\n      \"type\" ty\n      \"description\" (l . ft_description)\n      \"status\" ft_status\n      body\n  | Xml.slow_attr2_elt_swap2 NL1 \"feature\"\n      \"type\" ty\n      \"description\" (l . ft_description . dot)\n      body\n  | Xml.slow_attr2_elt_swap2 NL1 \"feature\"\n      \"type\" ty\n      \"id\" ft_id\n      body\n  | Xml.attr1_elt NL1 \"feature\"\n      \"type\" ty\n      body\n  )\n\nlet ft_xml : lens = \n  ins ft_tag . \n  ( ft_aux s7 ft_normal_type ft_bounds \n  | ft_aux \"\" ft_variation_type (ft_original_variation ~ ft_bounds) )\n\nlet ft_line : lens = terminate ft_xml \n\nlet ft_block : lens = ft_line*\n\n(* unit tests for FT line *)\nlet ft_ascii1 : string = \n  \"FT   CONFLICT     27     27       S -> E (in Ref 2).\n  |FT                                /FTId=VSP_123456.\" . \n  NL\n\nlet ft_ascii2 : string = \n  \"FT   VAR_SEQ     243    244       Missing (in isoform 2).\n  |FT                                /FTId=VSP_008971.\" . \n  NL\n\nlet ft_xml1 : string = \n  NL . \n  \"  <feature type=\\\"sequence conflict\\\" description=\\\"(in Ref 2)\\\" id=\\\"VSP_123456\\\">\n  |    <original>S</original>\n  |    <variation>E</variation>\n  |    <location>\n  |      <begin position=\\\"27\\\"/>\n  |      <end position=\\\"27\\\"/>\n  |    </location>\n  |  </feature>\"\n\nlet ft_xml2 : string = \n  NL . \n  \"  <feature type=\\\"splice variant\\\" description=\\\"(in isoform 2)\\\" id=\\\"VSP_008971\\\">\n  |    <location>\n  |      <begin position=\\\"243\\\"/>\n  |      <end position=\\\"244\\\"/>\n  |    </location>\n  |  </feature>\" \n\ntest ft_line.get \n  ft_xml1 = ft_ascii1\n\ntest ft_line.get \n  ft_xml2 = ft_ascii2\n\ntest ft_line.create \n  ft_ascii1 = ft_xml1\n\ntest ft_line.create \n  ft_ascii2 = ft_xml2\n\nlet P12544_ft_ascii : string = \n  \"FT   SIGNAL        1     26\n  |FT   PROPEP       27     28       Activation peptide.\n  |FT                                /FTId=PRO_0000027393.\n  |FT   CHAIN        29    262       Granzyme A.\n  |FT                                /FTId=PRO_0000027394.\n  |FT   DOMAIN       29    259       Peptidase S1.\n  |FT   ACT_SITE     69     69       Charge relay system.\n  |FT   ACT_SITE    114    114       Charge relay system.\n  |FT   ACT_SITE    212    212       Charge relay system.\n  |FT   CARBOHYD    170    170       N-linked (GlcNAc,,,) (Potential).\n  |FT   DISULFID     54     70\n  |FT   DISULFID    148    218\n  |FT   DISULFID    179    197\n  |FT   DISULFID    208    234\n  |FT   VARIANT     121    121       T -> M In dbSNP:rs3104233.\n  |FT                                /FTId=VAR_024291.\n  |FT   STRAND       43     47\n  |FT   STRAND       49     51\n  |FT   STRAND       53     60\n  |FT   STRAND       63     66\n  |FT   STRAND       77     81\n  |FT   STRAND       83     87\n  |FT   STRAND       93     95\n  |FT   STRAND       97    102\n  |FT   TURN        108    110\n  |FT   STRAND      116    122\n  |FT   STRAND      127    130\n  |FT   STRAND      147    154\n  |FT   STRAND      156    160\n  |FT   STRAND      167    174\n  |FT   HELIX       176    179\n  |FT   TURN        186    189\n  |FT   STRAND      195    199\n  |FT   STRAND      215    218\n  |FT   STRAND      221    228\n  |FT   STRAND      241    245\n  |FT   HELIX       251    258\" . \n  NL\n\nlet P12544_ft_xml : string = \n  NL . \n  \"  <feature type=\\\"signal peptide\\\">\n  |    <location>\n  |      <begin position=\\\"1\\\"/>\n  |      <end position=\\\"26\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"propeptide\\\" description=\\\"Activation peptide\\\" id=\\\"PRO_0000027393\\\">\n  |    <location>\n  |      <begin position=\\\"27\\\"/>\n  |      <end position=\\\"28\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"chain\\\" description=\\\"Granzyme A\\\" id=\\\"PRO_0000027394\\\">\n  |    <location>\n  |      <begin position=\\\"29\\\"/>\n  |      <end position=\\\"262\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"domain\\\" description=\\\"Peptidase S1\\\">\n  |    <location>\n  |      <begin position=\\\"29\\\"/>\n  |      <end position=\\\"259\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"active site\\\" description=\\\"Charge relay system\\\">\n  |    <location>\n  |  <position position=\\\"69\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"active site\\\" description=\\\"Charge relay system\\\">\n  |    <location>\n  |  <position position=\\\"114\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"active site\\\" description=\\\"Charge relay system\\\">\n  |    <location>\n  |  <position position=\\\"212\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"glycosylation site\\\" description=\\\"N-linked (GlcNAc,,,)\\\" status=\\\"potential\\\">\n  |    <location>\n  |  <position position=\\\"170\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"disulfide bond\\\">\n  |    <location>\n  |      <begin position=\\\"54\\\"/>\n  |      <end position=\\\"70\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"disulfide bond\\\">\n  |    <location>\n  |      <begin position=\\\"148\\\"/>\n  |      <end position=\\\"218\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"disulfide bond\\\">\n  |    <location>\n  |      <begin position=\\\"179\\\"/>\n  |      <end position=\\\"197\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"disulfide bond\\\">\n  |    <location>\n  |      <begin position=\\\"208\\\"/>\n  |      <end position=\\\"234\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"sequence variant\\\" description=\\\"In dbSNP:rs3104233\\\" id=\\\"VAR_024291\\\">\n  |  <original>T</original>\n  |  <variation>M</variation>\n  |    <location>\n  |  <position position=\\\"121\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"43\\\"/>\n  |      <end position=\\\"47\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"49\\\"/>\n  |      <end position=\\\"51\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"53\\\"/>\n  |      <end position=\\\"60\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"63\\\"/>\n  |      <end position=\\\"66\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"77\\\"/>\n  |      <end position=\\\"81\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"83\\\"/>\n  |      <end position=\\\"87\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"93\\\"/>\n  |      <end position=\\\"95\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"97\\\"/>\n  |      <end position=\\\"102\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"turn\\\">\n  |    <location>\n  |      <begin position=\\\"108\\\"/>\n  |      <end position=\\\"110\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"116\\\"/>\n  |      <end position=\\\"122\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"127\\\"/>\n  |      <end position=\\\"130\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"147\\\"/>\n  |      <end position=\\\"154\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"156\\\"/>\n  |      <end position=\\\"160\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"167\\\"/>\n  |      <end position=\\\"174\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"helix\\\">\n  |    <location>\n  |      <begin position=\\\"176\\\"/>\n  |      <end position=\\\"179\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"turn\\\">\n  |    <location>\n  |      <begin position=\\\"186\\\"/>\n  |      <end position=\\\"189\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"195\\\"/>\n  |      <end position=\\\"199\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"215\\\"/>\n  |      <end position=\\\"218\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"221\\\"/>\n  |      <end position=\\\"228\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"241\\\"/>\n  |      <end position=\\\"245\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"helix\\\">\n  |    <location>\n  |      <begin position=\\\"251\\\"/>\n  |      <end position=\\\"258\\\"/>\n  |    </location>\n  |  </feature>\"\n\nlet P12544_ft_xml_cn : string = \n  NL . \n  \"  <feature type=\\\"signal peptide\\\">\n  |    <location>\n  |      <begin position=\\\"1\\\"/>\n  |      <end position=\\\"26\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"propeptide\\\" description=\\\"Activation peptide\\\" id=\\\"PRO_0000027393\\\">\n  |    <location>\n  |      <begin position=\\\"27\\\"/>\n  |      <end position=\\\"28\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"chain\\\" description=\\\"Granzyme A\\\" id=\\\"PRO_0000027394\\\">\n  |    <location>\n  |      <begin position=\\\"29\\\"/>\n  |      <end position=\\\"262\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"domain\\\" description=\\\"Peptidase S1\\\">\n  |    <location>\n  |      <begin position=\\\"29\\\"/>\n  |      <end position=\\\"259\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"active site\\\" description=\\\"Charge relay system\\\">\n  |    <location>\n  |      <begin position=\\\"69\\\"/>\n  |      <end position=\\\"69\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"active site\\\" description=\\\"Charge relay system\\\">\n  |    <location>\n  |      <begin position=\\\"114\\\"/>\n  |      <end position=\\\"114\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"active site\\\" description=\\\"Charge relay system\\\">\n  |    <location>\n  |      <begin position=\\\"212\\\"/>\n  |      <end position=\\\"212\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"glycosylation site\\\" description=\\\"N-linked (GlcNAc,,,)\\\" status=\\\"potential\\\">\n  |    <location>\n  |      <begin position=\\\"170\\\"/>\n  |      <end position=\\\"170\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"disulfide bond\\\">\n  |    <location>\n  |      <begin position=\\\"54\\\"/>\n  |      <end position=\\\"70\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"disulfide bond\\\">\n  |    <location>\n  |      <begin position=\\\"148\\\"/>\n  |      <end position=\\\"218\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"disulfide bond\\\">\n  |    <location>\n  |      <begin position=\\\"179\\\"/>\n  |      <end position=\\\"197\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"disulfide bond\\\">\n  |    <location>\n  |      <begin position=\\\"208\\\"/>\n  |      <end position=\\\"234\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"sequence variant\\\" description=\\\"In dbSNP:rs3104233\\\" id=\\\"VAR_024291\\\">\n  |    <original>T</original>\n  |    <variation>M</variation>\n  |    <location>\n  |      <begin position=\\\"121\\\"/>\n  |      <end position=\\\"121\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"43\\\"/>\n  |      <end position=\\\"47\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"49\\\"/>\n  |      <end position=\\\"51\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"53\\\"/>\n  |      <end position=\\\"60\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"63\\\"/>\n  |      <end position=\\\"66\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"77\\\"/>\n  |      <end position=\\\"81\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"83\\\"/>\n  |      <end position=\\\"87\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"93\\\"/>\n  |      <end position=\\\"95\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"97\\\"/>\n  |      <end position=\\\"102\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"turn\\\">\n  |    <location>\n  |      <begin position=\\\"108\\\"/>\n  |      <end position=\\\"110\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"116\\\"/>\n  |      <end position=\\\"122\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"127\\\"/>\n  |      <end position=\\\"130\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"147\\\"/>\n  |      <end position=\\\"154\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"156\\\"/>\n  |      <end position=\\\"160\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"167\\\"/>\n  |      <end position=\\\"174\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"helix\\\">\n  |    <location>\n  |      <begin position=\\\"176\\\"/>\n  |      <end position=\\\"179\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"turn\\\">\n  |    <location>\n  |      <begin position=\\\"186\\\"/>\n  |      <end position=\\\"189\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"195\\\"/>\n  |      <end position=\\\"199\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"215\\\"/>\n  |      <end position=\\\"218\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"221\\\"/>\n  |      <end position=\\\"228\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"strand\\\">\n  |    <location>\n  |      <begin position=\\\"241\\\"/>\n  |      <end position=\\\"245\\\"/>\n  |    </location>\n  |  </feature>\n  |  <feature type=\\\"helix\\\">\n  |    <location>\n  |      <begin position=\\\"251\\\"/>\n  |      <end position=\\\"258\\\"/>\n  |    </location>\n  |  </feature>\"\n\ntest ft_block.get \n  P12544_ft_xml = P12544_ft_ascii\ntest ft_block.create\n  P12544_ft_ascii = P12544_ft_xml_cn\n\n***)\n\n(* --------------------------------------------------------------------------- *)\n(* SQ line *)\ntest \"----- SQ line-----\" = ?\n\nlet sq_tag : string = tag \"SQ\" \n\nlet sq_start_xml (flen:regexp -> lens) (fmass:regexp -> lens) (fcheck:regexp -> lens) : lens = \n  ins sq_tag . \n  ins \"SEQUENCE   \" . \n  Xml.raw_open NL1 \"sequence\" . \n    Sort.sort_concat #{lens}[(Xml.attr \"length\" (flen NUMBER));\n\t\t\t     (Xml.attr \"mass\" (fmass NUMBER));\n\t\t\t     (Xml.attr \"checksum\" (fcheck UALPHANUMCHAR+))]\n\nlet dt_tag : string = tag \"DT\" \n\nlet sq_mid_xml : lens = \n  let l : lens = \n    ins dt_tag . \n    Sort.sort_concat #{lens}[(Xml.attr \"modified\" (date . comma . space));\n\t\t\t     (Xml.attr \"version\" (ins \"sequence version\" . space . NUMBER . dot)) . \n\t\t\t       Xml.close] in \n  terminate l \n\n\nlet R1 = (UALPHACHAR{10}){0,5}\nlet R2 = (UALPHACHAR{1,10})\n\nlet sq_rest_xml : lens = \n  let block : lens = space . UALPHACHAR{10} in \n  let full_line : lens = ins \"    \" . block{6} . ins \"\\n\" in \n  let part_line : lens = \n    ins \"    \" . block{0,5} . \n    (space . UALPHACHAR{1,10}) . \n    nl in\n  let l : lens = \n    full_line* . part_line . \n    ins \"//\" . \n    Xml.simple_close_tag \"sequence\" in \n  terminate l \n\nlet sq_block : lens = \n  sq_start_xml \n    (fun (l:regexp) -> l . ins \" AA;  \")\n    (fun (l:regexp) -> l . ins \" MW;  \") \n    (fun (l:regexp) -> l . ins \" CRC64;\\n\") . \n  sq_mid_xml . \n  sq_rest_xml\n\n(* unit tests for SQ block *)\nlet sq_ascii : string = \n  \"SQ   SEQUENCE   893 AA;  101921 MW;  2F67CEB3B02E7AC1 CRC64;\n  |DT   01-JAN-2007, sequence version 15.\n  |     MKFLVLLFNI LCLFPILGAD ELVMSPIPTT DVQPKVTFDI NSEVSSGPLY LNPVEMAGVK\n  |     YLQLQRQPGV QVHKVVEGDI VIWENEEMPL YTCAIVTQNE VPYMAYVELL EDPDLIFFLK\n  |     EGDQWAPIPE DQYLARLQQL RQQIHTESFF SLNLSFQHEN YKYEMVSSFQ HSIKMVVFTP\n  |     KNGHICKMVY DKNIRIFKAL YNEYVTSVIG FFRGLKLLLL NIFVIDDRGM IGNKYFQLLD\n  |     DKYAPISVQG YVATIPKLKD FAEPYHPIIL DISDIDYVNF YLGDATYHDP GFKIVPKTPQ\n  |     CITKVVDGNE VIYESSNPSV ECVYKVTYYD KKNESMLRLD LNHSPPSYTS YYAKREGVWV\n  |     TSTYIDLEEK IEELQDHRST ELDVMFMSDK DLNVVPLTNG NLEYFMVTPK PHRDIIIVFD\n  |     GSEVLWYYEG LENHLVCTWI YVTEGAPRLV HLRVKDRIPQ NTDIYMVKFG EYWVRISKTQ\n  |     YTQEIKKLIK KSKKKLPSIE EEDSDKHGGP PKGPEPPTGP GHSSSESKEH EDSKESKEPK\n  |     EHGSPKETKE GEVTKKPGPA KEHKPSKIPV YTKRPEFPKK SKSPKRPESP KSPKRPVSPQ\n  |     RPVSPKSPKR PESLDIPKSP KRPESPKSPK RPVSPQRPVS PRRPESPKSP KSPKSPKSPK\n  |     VPFDPKFKEK LYDSYLDKAA KTKETVTLPP VLPTDESFTH TPIGEPTAEQ PDDIEPIEES\n  |     VFIKETGILT EEVKTEDIHS ETGEPEEPKR PDSPTKHSPK PTGTHPSMPK KRRRSDGLAL\n  |     STTDLESEAG RILRDPTGKI VTMKRSKSFD DLTTVREKEH MGAEIRKIVV DDDGTEADDE\n  |     DTHPSKEKHL STVRRRRPRP KKSSKSSKPR KPDSAFVPSI IFIFLVSLIV GIL\n  |//\" . \n  NL\n\nlet sq_xml : string = \n  NL . \n  \"  <sequence mass=\\\"101921\\\" length=\\\"893\\\" checksum=\\\"2F67CEB3B02E7AC1\\\" modified=\\\"2007-01-01\\\" version=\\\"15\\\">MKFLVLLFNILCLFPILGADELVMSPIPTTDVQPKVTFDINSEVSSGPLYLNPVEMAGVKYLQLQRQPGVQVHKVVEGDIVIWENEEMPLYTCAIVTQNEVPYMAYVELLEDPDLIFFLKEGDQWAPIPEDQYLARLQQLRQQIHTESFFSLNLSFQHENYKYEMVSSFQHSIKMVVFTPKNGHICKMVYDKNIRIFKALYNEYVTSVIGFFRGLKLLLLNIFVIDDRGMIGNKYFQLLDDKYAPISVQGYVATIPKLKDFAEPYHPIILDISDIDYVNFYLGDATYHDPGFKIVPKTPQCITKVVDGNEVIYESSNPSVECVYKVTYYDKKNESMLRLDLNHSPPSYTSYYAKREGVWVTSTYIDLEEKIEELQDHRSTELDVMFMSDKDLNVVPLTNGNLEYFMVTPKPHRDIIIVFDGSEVLWYYEGLENHLVCTWIYVTEGAPRLVHLRVKDRIPQNTDIYMVKFGEYWVRISKTQYTQEIKKLIKKSKKKLPSIEEEDSDKHGGPPKGPEPPTGPGHSSSESKEHEDSKESKEPKEHGSPKETKEGEVTKKPGPAKEHKPSKIPVYTKRPEFPKKSKSPKRPESPKSPKRPVSPQRPVSPKSPKRPESLDIPKSPKRPESPKSPKRPVSPQRPVSPRRPESPKSPKSPKSPKSPKVPFDPKFKEKLYDSYLDKAAKTKETVTLPPVLPTDESFTHTPIGEPTAEQPDDIEPIEESVFIKETGILTEEVKTEDIHSETGEPEEPKRPDSPTKHSPKPTGTHPSMPKKRRRSDGLALSTTDLESEAGRILRDPTGKIVTMKRSKSFDDLTTVREKEHMGAEIRKIVVDDDGTEADDEDTHPSKEKHLSTVRRRRPRPKKSSKSSKPRKPDSAFVPSIIFIFLVSLIVGIL</sequence>\"\n\ntest sq_block.get sq_xml = sq_ascii \n\n(* (\\* --------------------------------------------------------------------------- *\\) *)\n(* (\\* UniProtKB entry *\\) *)\n\n(* let id_rest : lens =  *)\n(*   sq_start_xml  *)\n(*     (fun (l:regexp) -> l . ins \" AA; \") *)\n(*     (fun (l:regexp) -> del l) *)\n(*     (fun (l:regexp) -> del l) *)\n\n(* let sq_start : lens =  *)\n(*   sq_start_xml  *)\n(*     (fun (l:regexp) -> l . ins \" AA;  \") *)\n(*     (fun (l:regexp) -> l . ins \" MW;  \") *)\n(*     (fun (l:regexp) -> l . ins \" CRC64;\\n\")  *)\n\n(* let uniprot_entry : lens =  *)\n(*   let pass1 : lens =  *)\n(*     ( (dt_lines SwissProt .  *)\n(*        ac_line?) ~ *)\n(*       (id_xml_start SwissProt) ) .  *)\n(*     de_line .  *)\n(*     gn_line .  *)\n(*     organism_block .  *)\n(*     reference_block .  *)\n(*     cc_block .  *)\n(*     dr_block .  *)\n(*     pe_line? .  *)\n(*     kw_line? .  *)\n(*     ft_block .  *)\n(*     dup_snd id_rest sq_start .  *)\n(*     sq_mid_xml .  *)\n(*     sq_rest_xml in  *)\n(*   pass1 *)\n"
let _ = Hashtbl.add items "core" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2008                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /lenses/core.boom                                                          *)\n(* Imports natively-defined primitives                                        *)\n(* $Id: core.boom 4998 2011-03-16 21:53:34Z mgree $ *)\n(******************************************************************************)\n\nmodule Core = \n\n#{@}\n\n\\section{The Core Definitions}\n\nThe first module, @Core@, imports primitive values (defined in the\nhost language, OCaml) to Boomerang. In @Core@, we do not use any\noverloaded or infix operators (e.g., @.@, @|@, @~@, @-@, @*@) because\nthe Boomerang type checker resolves these symbols to applications of\nfunctions defined in @Core@. (We do this because it facilitates \nchecking the preconditions on primitive values using dependent \nrefinement types.)\n\nValues defined in @Core@ are available by default in every Boomerang \nprogram.\n\n\\subsection{Equality}\n\n\\LENSSECTION{@equals@} The polymorphic @equals@ operator is partial: \ncomparing function, lens, or canonizer values raises a run-time \nexception. The infix @=@ operator desugars into @equals@, instantiated \nwith appropriate type arguments.\n\n#* let equals : forall 'a => 'a -> 'a -> bool \n## = Native.Prelude.poly_equal\n\n#* test equals{string} \"ABC\" \"ABC\" = true\n#* test equals{string} \"ABC\" \"123\" = false\n#* test equals{char} 'A' '\\065' = true \n#* test equals{string -> string} \n#*   (fun (x:string) -> x) (fun (y:string) -> y) = error\n\n\\subsection{Booleans}\n\n\\LENSSECTION{@land@, @lor@, @not@, @implies@} These operators are the \nstandard functions on booleans. The infix operators @&&@ and @||@ resolve \nto  @land@ and @lor@ respectively.\n\n#* let land : bool -> bool -> bool \n## = Native.Prelude.land\n#* let lor : bool -> bool -> bool \n## = Native.Prelude.lor\n#* let not : bool -> bool\n## = Native.Prelude.not\n#* let implies : bool -> bool -> bool \n## = (fun (b1:bool) -> (fun (b2:bool) -> lor b2 (not b1)))\n\n\\subsection{Integers}\n\n\\LENSSECTION{@string_of_int@} The operator @string_of_int@ converts an \ninteger to the corresponding (decimal) string.\n\n#* let string_of_int : int -> string \n## = Native.Prelude.string_of_int\n\n\\LENSSECTION{@bgt@, @blt@, @bgeq@, @bleq@} These operators are the\nstandard comparisons on integers. Infix operators @gt@, @lt@, @geq@,\n@leq@ resolve to these operators. In this module, we use names like\n@bgt@ here because @gt@ is a reserved keyword.\n\n#* let bgt : int -> int -> bool\n## = Native.Prelude.gt\n#* let blt : int -> int -> bool\n## = Native.Prelude.lt\n#* let bgeq : int -> int -> bool \n## = Native.Prelude.geq\n#* let bleq : int -> int -> bool \n## = Native.Prelude.leq\n\n## test bgt 1 0 = true\n## test blt 1 0 = false\n## test bgeq 1 1 = true\n## test bgeq 1 0 = true\n## test bgeq 0 1 = false\n## test bleq 3 4 = true\n\n\\LENSSECTION{@plus@, @minus@, @times@, @div@, @mod@} \nThese operators are the standard arithmetic functions on integers.\n\n#* let plus : int -> int -> int \n## = Native.Prelude.plus\n#* let minus : int -> int -> int \n## = Native.Prelude.minus\n#* let times : int -> int -> int \n## = Native.Prelude.times\n#* let div : int -> int -> int \n## = Native.Prelude.div\n#* let mod : int -> int -> int \n## = Native.Prelude.mod\n\n\\subsection{Characters}\n\n\\LENSSECTION{@code@} The @code@ function converts a @char@ to its\nASCII code.\n\n#* let code : char -> int\n## = Native.Prelude.code\n\n\\LENSSECTION{@chr@} The @chr@ function converts an integer in the range \n@0@ to @255@ to the corresponding @char@.\n\n#* let chr : (n:int where! land (bleq 0 n) (bgeq 255 n)) -> char\n## = Native.Prelude.chr\n\n\\LENSSECTION{@string_of_char@} The @string_of_char@ function converts \na character to a string.\n\n#* let string_of_char : char -> string \n## = Native.Prelude.string_of_char\n\n\\subsection{Strings}\n\n\\LENSSECTION{@length@} The @length@ function computes the length of a string.\n\n#* let length : string -> int \n## = Native.Prelude.length\n\n#* test length \"\" = 0\n#* test length \"Boomerang\" = 9\n\n\\LENSSECTION{@get_char@} The @get_char@ function gets  \na character from a string.\n\n#* let get_char : (s:string -> \n#*                (n:int where! land (bleq 0 n) (bgt (length s) n)) -> \n#*                char)\n## = Native.Prelude.get_char\n\n#* test get_char \"Boomerang\" 0 = 'B'\n#* test get_char \"Boomerang\" 1 = 'o'\n#* test get_char \"Boomerang\" 2 = 'o'\n#* test get_char \"Boomerang\" 3 = 'm'\n#* test get_char \"Boomerang\" 8 = 'g'\n#* test get_char \"Boomerang\" 9 = error\n\n\\LENSSECTION{@string_concat@} The @string_concat@ operator is the \nstandard string concatenation function. The overloaded infix @.@ operator \nresolves to @string_concat@ when it is applied to strings.\n\n#* let string_concat : string -> string -> string \n## = Native.Prelude.string_concat \n\n#* test string_concat \"\" \"\" = \"\"\n#* test string_concat \"Boom\" \"erang\" = \"Boomerang\"\n#* test string_concat \"\" \"Boomerang\" = \"Boomerang\"\n\n\\subsection{Regular Expressions}\n\n\\LENSSECTION{@str@} The @str@ function converts a @string@ to the singleton \n@regexp@ containing it. This coercion is automatically inserted by the type \nchecker on programs that use subtyping. However, it is occasionally useful \nto explicitly promote strings to regexps, so we include it here. \n\n#* let regexp_of_string : string -> regexp\n## = Native.Prelude.regexp_of_string\n\n\\LENSSECTION{@EMPTY@}\nThe regular expression @empty@ denotes the empty set of strings.\n\n#* let EMPTY : regexp = []\n\n\\LENSSECTION{@EPSILON@}\nThe regular expression @epsilon@ denotes the singleton set containing the \nempty string.\n\n#* let EPSILON : regexp = (regexp_of_string \"\")\n\n\\LENSSECTION{@string_of_regexp@} The @string_of_regexp@ function \nrepresents a regular expression as a string.\n\n#* let string_of_regexp : regexp -> string \n## = Native.Prelude.string_of_regexp\n\n\\LENSSECTION{@regexp_union@} The @regexp_union@ operator forms the union \nof two regular expressions. The overloaded infix symbol @|@ desugars into \n@regexp_union@ when used with values of type @regexp@.\n\n#* let regexp_union : regexp -> regexp -> regexp \n## = Native.Prelude.regexp_union\n\n\\LENSSECTION{@regexp_concat@} The @regexp_concat@ operator forms the \nconcatenation of two regular expressions. The overloaded infix symbol @.@ \ndesugars into @regexp_concat@ when used with values of type @regexp@.\n\n#* let regexp_concat : regexp -> regexp -> regexp\n## = Native.Prelude.regexp_concat \n\n\\LENSSECTION{@regexp_iter@} The @regexp_iter@ operator iterates a regular \nexpression. The overloaded symbols @*@, @+@, and @?@, as well as iterations \n@{n,m}@ and @{n,}@ all desugar into @regexp_iter@ when used with values of \ntype @regexp@. If the second argument is negative, then the iteration is \nunbounded. For example,  @R*@ desugars into @regexp_iter R 0 (-1)@.\n\n#* let regexp_iter : regexp -> int -> int -> regexp \n## = Native.Prelude.regexp_iter\n\n#* let regexp_star (r : regexp) : regexp =\n#*   regexp_iter r 0 (minus 0 1)\n\n#* let regexp_plus (r : regexp) : regexp =\n#*   regexp_iter r 1 (minus 0 1)\n\n#* let regexp_option (r : regexp) : regexp =\n#*   regexp_iter r 0 1\n\n\\LENSSECTION{@inter@} The @inter@ operator forms the intersection of two \nregular expressions. The infix symbol @&@ desugars into @inter@.\n\n#* let inter : regexp -> regexp -> regexp \n## = Native.Prelude.inter\n\n\\LENSSECTION{@diff@} The @diff@ operator forms the difference of two regular \nexpressions. The infix symbol @-@ desugars into @diff@.\n\n#* let diff : regexp -> regexp -> regexp \n## = Native.Prelude.diff\n\n\\LENSSECTION{@matches@,@matches_cex@} The @matches@ function tests if a string\nbelongs to the language denoted by a regular expression.\n\n#* let matches : regexp -> string -> bool \n## = Native.Prelude.matches\n#* let matches_cex : regexp -> string -> bool \n## = Native.Prelude.matches_cex\n\n#* test matches [A-Z] \"A\" = true\n#* test matches [A-Z] \"0\" = false\n#* test matches (diff [^] [A-Z]) \"X\" = false\n#* test matches (diff [^] [A-Z]) \"0\" = true\n\n\\LENSSECTION{@representative@} The function @representative@ computes a \n(typically shortest) representative of a regular expression.\n\n#* let representative : (r:regexp -> (s:string where! matches_cex r s))\n## = Native.Prelude.representative\n\nIf the regular expression denotes the empty language, an exception is raised, \nas the unit test below illustrates.\n\n#* test representative (regexp_iter [A-Z] 1 3) = \"A\"\n#* test representative [] = error\n\n\\LENSSECTION{@is_empty@} The @is_empty@ function tests if a regular \nexpression denotes the empty language.\n\n#* let is_empty : regexp -> bool \n## = Native.Prelude.is_empty\n\n#* test is_empty [] = true\n#* test is_empty [A-Z] = false\n#* test is_empty (diff [A-Z] [^]) = true\n\n\\LENSSECTION{@equiv@,@equiv_cex@} The @equiv@ function tests if two regular \nexpressions denote the same language.\n\n#* let equiv : regexp -> regexp -> bool\n## = Native.Prelude.equiv\n#* let equiv_cex : regexp -> regexp -> bool\n## = Native.Prelude.equiv_cex\n\n#* test equiv [A-Z] [\\065-\\090] = true\n\n\\LENSSECTION{@disjoint@,@disjoint_cex@} The @disjoint@ function tests whether\ntwo regular expressions denote disjoint languages.\n\n#* let disjoint : regexp -> regexp -> bool\n##   = Native.Prelude.disjoint\n\n#* let disjoint_cex : regexp -> regexp -> bool\n##   = Native.Prelude.disjoint_cex\n\n#* test disjoint [A-Z] [0-9] = true\n#* test disjoint [A-Z] [M] = false\n\n\\LENSSECTION{@splittable@,@splittable_cex@} The @splittable@ function tests \nwhether the concatenation of two regular expressions is ambiguous.\n\n#* let splittable : regexp -> regexp -> bool \n## = Native.Prelude.splittable\n\n#* let splittable_cex : regexp -> regexp -> bool\n## = Native.Prelude.splittable_cex\n\n#* test splittable (regexp_iter [A] 0 1) (regexp_iter [A] 0 1) = false\n#* test splittable (regexp_iter [A] 1 1) (regexp_iter [A] 0 1) = true\n\n\\LENSSECTION{@iterable@,@iterable_cex@} The @iterable@ function tests \nwhether the iteration of a regular expression is ambiguous.\n\n#* let iterable : regexp -> bool \n## = Native.Prelude.iterable\n\n#* let iterable_cex : regexp -> bool\n## = Native.Prelude.iterable_cex\n\n#* test iterable (regexp_iter [A] 0 1) = false\n#* test iterable (regexp_iter [A] 1 1) = true\n\n\\LENSSECTION{@count@} The @count@ function takes as arguments a regular \nexpression @R@ and a string @w@. It returns the maximum number of times \nthat @w@ can be split into substrings, such that each substring belongs \nto @R@.\n\n#* let count : (r:regexp -> \n#*             (s:string where! matches_cex (regexp_star r) s) ->\n#*             int)\n## = Native.Prelude.count\n\n#* test count [A-Z] \"\" = 0\n#* test count [A-Z] \"ABC\" = 3\n#* test count (regexp_option [A-Z]) \"ABC\" = 3\n#* test count (regexp_option [A-Z]) \"123\" = error\n\n\\subsection{Tags}\n\n\\LENSSECTION{@species@,@predicate@,@key@,@tag@} A tag is a type defined\nby the Core module and used by the match functions (@aregexp_match@ and\n@lens_match@). The @key_annotation@ is used to set the default\nannotation for the chunk: with @Key@ everything without annotations are\nkey, while with @NoKey@ they are not.\n\n#* type species = Positional | Diffy of bool | Greedy | Setlike\n#* type predicate = Threshold of (t:int where! land (bgeq t 0) (bleq t 100))\n#* type key_annotation = Key | NoKey\n#* type tag = Tag of species * predicate * key_annotation * string\n\n#* let diffy (name:string) : tag\n#* = Tag (Diffy true, Threshold 0, Key, name)\n#* let positional (name:string) : tag\n#* = Tag (Positional, Threshold 0, NoKey, name)\n#* let greedy (t:int where land (bgeq t 0) (bleq t 100)) (name:string) : tag\n#* = Tag (Greedy, Threshold t, NoKey, name)\n#* let dictionary (name:string) : tag\n#* = Tag (Greedy, Threshold 100, NoKey, name)\n#* let setlike (t:int where land (bgeq t 0) (bleq t 100)) (name:string) : tag\n#* = Tag (Setlike, Threshold t, NoKey, name)\n\n\\subsection{Annotated Regular Expressions}\n\n\\LENSSECTION{@rxlift@} The @rxlift@ function converts a @regexp@ to\nan equivalent annotated regular expression. This coercion is automatically\ninserted by the type checker on programs that use subtyping.\n\n#* let rxlift : regexp -> aregexp\n## = Native.Prelude.rxlift\n\n\\LENSSECTION{@rxdrop@} The @rxdrop@ function drops the annotation of\nan annotated regular expressions.\n\n#* let rxdrop : aregexp -> regexp\n## = Native.Prelude.rxdrop\n\n#* test equiv (rxdrop (rxlift [a-z])) [a-z] = true\n\n\\LENSSECTION{@aequiv@,@aequiv_cex@} The @aequiv@ function tests if two annotated\nregular expressions denote the same chunk structured language.  It's conservative.\n\\SHOWCOMMENT{writting something better...}\n\n#* let aequiv : aregexp -> aregexp -> bool\n## = Native.Prelude.aequiv\n#* let aequiv_cex : aregexp -> aregexp -> bool\n## = Native.Prelude.aequiv_cex\n\n#* let aregexp_match_compatible_cex : tag -> aregexp -> bool\n## = Native.Prelude.aregexp_match_compatible_cex\n#* let aregexp_compatible_cex : aregexp -> aregexp -> bool\n## = Native.Prelude.aregexp_compatible_cex\n\n\\LENSSECTION{@aregexp_concat@} The @aregexp_concat@ operator forms the \nconcatenation of two annotated regular expressions. The overloaded infix symbol @.@ \ndesugars into @aregexp_concat@ when used with values of type @aregexp@.\n\n#* let aregexp_concat (a1:aregexp)\n#*                    (a2:aregexp where! aregexp_compatible_cex a1 a2)\n#*   : aregexp\n## = Native.Prelude.aregexp_concat a1 a2\n\n## test aequiv (rxlift (regexp_concat [a-z] [a-z])) (aregexp_concat (rxlift [a-z]) (rxlift [a-z])) = true\n\n\\LENSSECTION{@aregexp_union@} The @aregexp_union@ operator forms the union \nof two regular expressions. The overloaded infix symbol @|@ desugars into \n@aregexp_union@ when used with values of type @aregexp@.\n\n#* let aregexp_union (a1:aregexp)\n#*                   (a2:aregexp where! land (disjoint_cex (rxdrop a1) (rxdrop a2))\n#*                                          (aregexp_compatible_cex a1 a2))\n#*   : aregexp\n## = Native.Prelude.aregexp_union a1 a2\n\n\\LENSSECTION{@aregexp_iter@} The @aregexp_iter@ operator iterates an annotated regular \nexpression. The overloaded symbols @*@, @+@, and @?@, as well as iterations \n@{n,m}@ and @{n,}@ all desugar into @aregexp_iter@ when used with values of \ntype @aregexp@. If the second argument is negative, then the iteration is \nunbounded. For example,  @R*@ desugars into @aregexp_iter R 0 (-1)@.\n\n## (* this needs a contract! --MMG *)\n#* let aregexp_iter : aregexp -> int -> int -> aregexp \n## = Native.Prelude.aregexp_iter\n\n#* let aregexp_star (r : aregexp) : aregexp =\n#*   aregexp_iter r 0 (minus 0 1)\n\n#* let aregexp_plus (r : aregexp) : aregexp =\n#*   aregexp_iter r 1 (minus 0 1)\n\n#* let aregexp_option (r : aregexp) : aregexp =\n#*   aregexp_iter r 0 1\n\n## test aequiv (rxlift (regexp_concat [a-z] (regexp_star [a-z]))) (aregexp_plus (rxlift [a-z])) = true\n## test aequiv (rxlift (regexp_concat [a-z] (regexp_iter [a-z] 2 4))) (aregexp_iter (rxlift [a-z]) 3 5) = true\n\n\\LENSSECTION{@aregexp_match@} The @aregexp_match@ function add a chunk\nannotation with tag defined by the string to the annotated regular\nexpression. The operator @<aregexp>@ and @<tag:aregexp>@ desugars into\n@aregexp_match@.\n\n#* let aregexp_match (t:tag) (a:aregexp where! aregexp_match_compatible_cex t a)\n#* : aregexp\n## = Native.Prelude.aregexp_match t a\n\n## test aequiv (rxlift [a-z]) (aregexp_match (positional \"\") (rxlift [a-z])) = false\n## test equiv [a-z] (rxdrop (aregexp_match (positional \"\") (rxlift [a-z]))) = true\n## test aequiv (aregexp_match (positional \"\") (rxlift [a-z]))   (aregexp_match (positional \"\") (rxlift [a-z])) = true\n## test aequiv (aregexp_match (positional \"t1\") (rxlift [a-z])) (aregexp_match (positional \"t2\") (rxlift [a-z])) = false\n\n\\LENSSECTION{@no_chunks@} The @no_chunks@ function tests if an\nannotated regular expressions contains chunk annotations.\n\n#* let no_chunks : aregexp -> bool\n## = Native.Prelude.no_chunks\n\n#* test no_chunks (rxlift [a-z]) = true\n#* test no_chunks (aregexp_match (positional \"\") (rxlift [a-z])) = false\n\n\\subsection{Equivalence Relations}\n\n\\LENSSECTION{@rel@} The @rel@ datatype splits the equivalence relations on\nlens (concreate/abstract) domains into two types: identity equivalences, and \nunknown equivalences.\n\n#* type rel = Identity | Unknown\n\n## let rel_of_is_id (b:bool) : rel = match b with\n##   | true -> Identity\n##   | false -> Unknown\n\n#* let rel_is_id (r:rel) : bool = \n#*   equals{rel} r Identity\n\n\\subsection{Lens Components}\n\n\\LENSSECTION{@stype@} The @stype@ function extracts the dropped\nconcrete type component (i.e., the type of the domain of its $\\GET$\nfunction) of a lens.  The record-style projection notation @l.stype@\nand @l.domain_type@ both desugar into @stype@.\n\n#* let stype : lens -> regexp \n## = Native.Prelude.stype\n\n\\LENSSECTION{@astype@} The @astype@ function extracts the concrete type\ncomponent of a lens.  The record-style projection notation @l.astype@\ndesugars into @astype@.\n\n#* let astype : lens -> aregexp \n## = Native.Prelude.astype\n\n\\LENSSECTION{@vtype@} The @vtype@ function extracts the dropped\nabstract type component (i.e., the type of the codomain of its $\\GET$\nfunction) of a lens.  The record-style projection notation @l.vtype@\nand @l.codomain_type@ both desugar into @vtype@.\n\n#* let vtype : lens -> regexp \n## = Native.Prelude.vtype\n\n\\LENSSECTION{@avtype@} The @avtype@ function extracts the abstract type\ncomponent of a lens.  The record-style projection notation @l.avtype@\ndesugars into @avtype@.\n\n#* let avtype : lens -> aregexp \n## = Native.Prelude.avtype\n\n\\LENSSECTION{@ktype@} The @ktype@ function extracts the complement\ntype component.\n\n#* let ktype : lens -> skeleton_set\n## = Native.Prelude.ktype\n\n\\LENSSECTION{@mtype@} The @mtype@ function extracts the resource\ntype component.\n\n#* let mtype : lens -> resource_set\n## = Native.Prelude.mtype\n\n\\LENSSECTION{@mtype_compatible_cex@} The @mtype_compatible_cex@\nfunction returns @true@ if the two types can be used for union or\nconcat.\n\n#* let mtype_compatible_cex : resource_set -> resource_set -> bool\n## = Native.Prelude.mtype_compatible_cex\n\n\\LENSSECTION{@mtype_match_compatible_cex@} The\n@mtype_match_compatible_cex@ function returns @true@ if the tag @t@\nwith the ktype @k@ can be used with the mtype @m@ for match.\n\n#* let mtype_match_compatible_cex : tag -> skeleton_set -> resource_set -> bool\n## = Native.Prelude.mtype_match_compatible_cex\n\n\\LENSSECTION{@mtype_domain_equal@} The @mtype_domain_equal@ function\nreturns @true@ if the two types have the same domain.  It's used for\ncompose.\n\n#* let mtype_domain_equal : resource_set -> resource_set -> bool\n## = Native.Prelude.mtype_domain_equal\n\n\\LENSSECTION{@vrep@,@srep@}\n\n#* let vrep : lens -> string -> string\n## = Native.Prelude.vrep\n#* let srep : lens -> string -> string\n## = Native.Prelude.srep\n\n\\LENSSECTION{@sequiv@} The @sequiv@ function extracts the equivalence relation\non the concrete domain (@astype@) of a lens.\n\n#* let sequiv : lens -> rel\n## = fun (l:lens) -> rel_of_is_id (Native.Prelude.sequiv_identity l)\n\n\\LENSSECTION{@vequiv@} The @vequiv@ function extracts the equivalence relation\non the abstract domain (@avtype@) of a lens.\n\n#* let vequiv : lens -> rel\n## = fun (l:lens) -> rel_of_is_id (Native.Prelude.vequiv_identity l)\n\n\\LENSSECTION{@bij@} The @bij@ function tests whether a lens is bijective. \nThe record-style projection notation @l.bij@ desugars into @bij@.\n\n#* let bij : lens -> bool \n## = Native.Prelude.bij\n\n\\LENSSECTION{@is_basic@} The @is_basic@ function tests whether a lens\nis a basic lens (i.e. does not contain any chunk).\n\n#* let is_basic (l:lens) : bool =\n#*   no_chunks (avtype l)\n\n\\LENSSECTION{@in_lens_type@} The @in_lens_type@ function tests whether a lens\nis in a given @stype@ and @vtype@.  The @lens in S <-> V@ notation desugars \ninto @in_lens_type@.\n\n#* let in_lens_type (l:lens) (s:regexp) (v:regexp) : bool =\n#*   (land (equiv_cex (stype l) s) (equiv_cex (vtype l) v))\n\n\\LENSSECTION{@in_bij_lens_type@} The @in_lens_type@ function tests whether a \nlens is bijective in a given @stype@ and @vtype@. The @lens in S <=> V@ \nnotation desugars into @in_bij_lens_type@.\n\n#* let in_bij_lens_type (l:lens) (S:regexp) (V:regexp) : bool =\n#*   (land (in_lens_type l S V) (bij l))\n\n\\LENSSECTION{@get@} The @get@ function extracts the $\\GET$ component of a lens. The record-style \nprojection notation @l.get@ desugars into @get@.\n\n#* let get : (l:lens -> \n#*           (s:string where! matches_cex (stype l) s) ->\n#*           (s':string where! matches_cex (vtype l) s'))\n## = Native.Prelude.get\n\n\\LENSSECTION{@put@} The @put@ function extracts the $\\PUT$ component of a lens. \nThe record-style projection notation @l.put v into s@ desugars into @put@.\n\n#* let put : (l:lens ->\n#*           (v:string where! matches_cex (vtype l) v) -> \n#*           (s:string where! matches_cex (stype l) s) -> \n#*           (s':string where! matches_cex (stype l) s'))\n## = Native.Prelude.put \n\n\\LENSSECTION{@create@} The @create@ function extracts the $\\CREATE$ \ncomponent of a lens. The record-style projection notation @l.create@ \ndesugars into @create@.\n\n#* let create : (l:lens -> \n#*              (v:string where! matches_cex (vtype l) v) -> \n#*              (s:string where! matches_cex (stype l) s))\n## = Native.Prelude.create \n\n\\subsection{Lenses}\n\n\\LENSSECTION{@copy@} The @copy@ lens takes a regular expression @R@ as\nan argument and copies strings belonging to @R@ in both directions.\n\n#* let copy (R:regexp) : (l:lens where! in_bij_lens_type l R R)\n## = Native.Prelude.copy R\n\n#* test get (copy [A-Z]) \"A\" = \"A\"\n#* test put (copy [A-Z]) \"B\" \"A\" = \"B\"\n#* test create (copy [A-Z]) \"Z\" = \"Z\"\n#* test get (copy [A-Z]) \"1\" = error\n#* test stype (copy [A-Z]) = [A-Z]\n#* test vtype (copy [A-Z]) = stype (copy [A-Z])\n\n\n\\LENSSECTION{@clobber@} The @clobber@ lens takes as arguments a\nregular expression @R@, a string @u@, and a function from strings to\nstrings @f@.  Its $\\GET$ function is the constant function that\nreturns @u@, its $\\PUT$ function restores its concrete argument, and\nits $\\CREATE$ function returns the string @f u@.\n\n#* let clobber \n#*     (R:regexp) (u:string) (f:string -> (s:string where! matches_cex R s))\n#*   : (l:lens where! in_lens_type l R (regexp_of_string u))\n##   = Native.Prelude.clobber R u f \n\n#* test get (clobber [A-Z] \"\" (fun (s:string) -> \"B\")) \"A\" = \"\"\n#* test put (clobber [A-Z] \"\" (fun (s:string) -> \"B\")) \"\" \"A\" = \"A\"\n#* test create (clobber [A-Z] \"\" (fun (s:string) -> \"B\")) \"\" = \"B\"\n\n\\LENSSECTION{@const@} The @const@ lens behaves like @clobber@ but \nhas a $\\CREATE$ function that always returns a default string @v@.\n\n#* let const (R:regexp) (u:string) (v:string where matches_cex R v)\n#*   : (l:lens where in_lens_type l R (regexp_of_string u))\n##   = clobber R u (fun (s:string) -> v)\n\n#* test get (const [A-Z] \"x\" \"B\") \"A\" = \"x\"\n#* test put (const [A-Z] \"x\" \"B\") \"x\" \"A\" = \"A\"\n#* test create (const [A-Z] \"x\" \"B\") \"x\" = \"B\"\n\n\n\\LENSSECTION{@set@} The @set@ derived lens is like @const@ but uses an arbitrary representative \nof @R@ as the default string. The infix operator @<->@ desugars to @set@.\n\n#* let set (R:regexp) (s:string) : (l:lens where in_lens_type l R (regexp_of_string s))\n#*   = const R s (representative R)\n\n\\LENSSECTION{@rewrite@} The @rewrite@ derived lens is like @set@ but only rewrites strings, and so \nis bijective. The infix operator @<=>@ desugars to @rewrite@.\n\n#* let rewrite (s1:string) (s2:string) \n#*   : (l:lens where in_bij_lens_type l (regexp_of_string s1) (regexp_of_string s2))\n#*   = const (regexp_of_string s1) s2 s1 \n\n\\LENSSECTION{@lens_union@} The @lens_union@ operator forms the union of \ntwo lenses. The concrete types of the two lenses must be disjoint. The \noverloaded infix operator @||@ desugars into @lens_union@ when applied \nto lens values.\n\n#* let lens_union \n#*     (l1:lens where! land (rel_is_id (vequiv l1))\n#*                         (is_basic l1))\n#*     (l2:lens where! land (rel_is_id (vequiv l2))\n#*                   (land (is_basic l2)\n%                    (land (mtype_compatible_cex (mtype l1) (mtype l2))\n#*                         (disjoint_cex (stype l1) (stype l2))))\n#*   : (l:lens where! in_lens_type l \n#*          (regexp_union (stype l1) (stype l2))\n#*          (regexp_union (vtype l1) (vtype l2)))\n## = Native.Prelude.lens_union l1 l2\n\n#* test get (lens_union (copy [A-Z]) (copy [0-9])) \"A\" = \"A\"\n#* test get (lens_union (copy [A-Z]) (copy [0-9])) \"0\" = \"0\"\n#* test create (lens_union (copy [A-Z]) (copy [0-9])) \"A\" = \"A\"\n#* test lens_union (copy [A-Z]) (copy [^]) = error\n\n\\LENSSECTION{@lens_disjoint_union@} The @lens_disjoint_union@ operator  \nalso forms the union of two lenses. However, it requires that the concrete \nand abstract types of the two lenses be disjoint. The overloaded infix \noperator @|@ desugars into @lens_disjoint_union@ when applied to lens values.\n\n#* let lens_disjoint_union_contract (l1:lens) (l2:lens) : bool\n#* = land (mtype_compatible_cex (mtype l1) (mtype l2))\n#*          (land (disjoint_cex (stype l1) (stype l2))\n#*                (disjoint_cex (vtype l1) (vtype l2)))\n\n#* let lens_disjoint_union \n#*     (l1:lens) \n#*     (l2:lens where! lens_disjoint_union_contract l1 l2)\n#*   : (l:lens where! in_lens_type l\n#*          (regexp_union (stype l1) (stype l2))\n#*          (regexp_union (vtype l1) (vtype l2)))\n## = Native.Prelude.lens_union l1 l2\n\n#* test get (lens_disjoint_union (copy [A-Z]) (copy [0-9])) \"A\" = \"A\"\n#* test get (lens_disjoint_union (copy [A-Z]) (copy [0-9])) \"0\" = \"0\"\n#* test lens_disjoint_union (copy [A-Z]) (const [0-9] \"A\" \"0\") = error\n\n\\LENSSECTION{@lens_concat@} The @lens_concat@ operator forms the \nconcatenation of two lenses. The concrete and abstract types of the two \nlenses must each be unambiguously concatenable. The overloaded infix \noperator @.@ desugars into @lens_concat@ when applied to lens values.\n\n#* let lens_concat_contract (l1:lens) (l2:lens) : bool\n#* = land (mtype_compatible_cex (mtype l1) (mtype l2))\n#*        (land (splittable_cex (stype l1) (stype l2)) \n#*              (splittable_cex (vtype l1) (vtype l2)))\n\n#* let lens_concat\n#*     (l1:lens) \n#*     (l2:lens where! lens_concat_contract l1 l2)\n#*   : (l:lens where! in_lens_type l (regexp_concat (stype l1) (stype l2))\n#*                                  (regexp_concat (vtype l1) (vtype l2)))\n## = Native.Prelude.lens_concat l1 l2\n\n#* test get (lens_concat (copy [A-Z]) (copy [0-9])) \"A1\" = \"A1\"\n#* test put (lens_concat (copy [A-Z]) (copy [0-9])) \"B2\" \"A1\" = \"B2\"\n#* test create (lens_concat (copy [A-Z]) (copy [0-9])) \"B2\" = \"B2\"\n\n\n\\LENSSECTION{@compose@} The @compose@ operator puts two lenses\nin sequence. The abstract type of the lens on the left and the \nconcrete type of the lens on the right must be identical.\n\n#* let compose \n#*     (l1:lens where! rel_is_id (vequiv l1))\n#*     (l2:lens where! land (aequiv (avtype l1) (astype l2))\n#*                         (rel_is_id (sequiv l2)))\n#*   : (l:lens where! in_lens_type l (stype l1) (vtype l2))\n## = Native.Prelude.compose l1 l2\n\n#* test get (compose (const [A-Z] \"Z\" \"A\") \n#*                   (const [Z] \"X\" \"Z\")) \"A\" = \"X\"\n\n\\LENSSECTION{@lens_swap@} The @lens_swap@ operator also concatenates lenses. \nHowever, it swaps the order of the strings it creates on the abstract side. \nAs with @lens_concat@, the concrete and abstract types of the two lenses must \neach be unambiguously concatenable. The overloaded infix operator @~@ desugars \ninto @lens_swap@ when applied to lens values.\n\n#* let lens_swap_contract (l1:lens) (l2:lens) : bool\n#* = land (mtype_compatible_cex (mtype l1) (mtype l2))\n#*        (land (splittable_cex (stype l1) (stype l2)) \n#*              (splittable_cex (vtype l2) (vtype l1)))\n\n#* let lens_swap\n#*     (l1:lens) \n#*     (l2:lens where! lens_swap_contract l1 l2)\n#*   : (l:lens where! in_lens_type l (regexp_concat (stype l1) (stype l2))\n#*                                  (regexp_concat (vtype l2) (vtype l1)))\n## = Native.Prelude.lens_swap l1 l2\n\n#* test get (lens_swap (copy [A-Z]) (copy [0-9])) \"A1\" = \"1A\"\n#* test put (lens_swap (copy [A-Z]) (copy [0-9])) \"2B\" \"A1\" = \"B2\"\n#* test create (lens_swap (copy [A-Z]) (copy [0-9])) \"2B\" = \"B2\"\n\n\\LENSSECTION{@lens_star@} The @lens_star@ operator iterates a lens zero \nor more times. The iterations of the concrete and abstract types of the \nlens must both be unambiguous.  The overloaded operator @*@ desugars into \n@lens_star@ when applied to a lens.  Recall that @regexp_iter R 0 -1@ is how\n@R*@ desugars.\n\n#* let lens_star_contract (l:lens) : bool\n#* = land (iterable_cex (stype l)) (iterable_cex (vtype l))\n\n#* let lens_star \n#*     (l:lens where! lens_star_contract l)\n#*   : (l':lens where! in_lens_type l'\n#*                (regexp_star (stype l))\n#*                (regexp_star (vtype l)))\n## = Native.Prelude.lens_star l\n\n#* test get (lens_star (copy [A-Z])) \"\" = \"\"\n#* test get (lens_star (copy [A-Z])) \"ABCD\" = \"ABCD\"\n#* test put (lens_star (copy [A-Z])) \"AB\" \"ABCD\" = \"AB\"\n#* test create (lens_star (copy [A-Z])) \"A\" = \"A\"\n\n\\LENSSECTION{@lens_plus@} The @lens_plus@ operator iterates a lens one\nor more times. The iterations of the concrete and abstract types of the \nlens must both be unambiguous (when non-empty). The overloaded operator @+@\nresolves to @lens_plus@ when applied to a lens. \n\n#* let lens_plus\n#*     (l:lens where! land (iterable_cex (stype l))\n#*                        (iterable_cex (vtype l)))\n#*   : (l':lens where! in_lens_type l' \n#*                (regexp_plus (stype l))\n#*                (regexp_plus (vtype l)))\n## = Native.Prelude.lens_plus l\n\n#* test get (lens_plus (copy [A-Z])) \"A\" = \"A\"\n#* test get (lens_plus (copy [A-Z])) \"ABCD\" = \"ABCD\"\n#* test put (lens_plus (copy [A-Z])) \"AB\" \"ABCD\" = \"AB\"\n#* test create (lens_plus (copy [A-Z])) \"A\" = \"A\"\n\n\\LENSSECTION{@lens_option@} The @lens_option@ operator runs a lens once or \nnot at all.  The concrete and abstract types of the lens must both be disjoint \nfrom the empty lens.  The overloaded operator @?@ resolves to @lens_option@\nwhen applied to a lens.\n\n#* let lens_option\n#*     (l:lens where! land (disjoint_cex (stype l) EPSILON)\n#*                        (disjoint_cex (vtype l) EPSILON))\n#*   : (l':lens where! in_lens_type l' \n#*                (regexp_union (stype l) EPSILON) \n#*                (regexp_union (vtype l) EPSILON))\n## = Native.Prelude.lens_option l\n\n#* test get (lens_option (copy [A-Z])) \"\" = \"\"\n#* test get (lens_option (copy [A-Z])) \"A\" = \"A\"\n#* test put (lens_option (copy [A-Z])) \"B\" \"\" = \"B\"\n#* test create (lens_option (copy [A-Z])) \"A\" = \"A\"\n\n\\LENSSECTION{@lens_iter@} The @lens_iter@ operator iterates a lens a finite\nnumber of times.  The concatenations of the concrete and abstract types of \nthe lens must both be unambiguous. The overloaded operator @{m,n}@ \nresolves into instances of @lens_iter@ when applied to a lens argument. \n\n#* let lens_iter \n#*    (l:lens where! land (splittable_cex (stype l) (stype l))\n#*                       (splittable_cex (vtype l) (vtype l)))\n#*    (min:int where! bgeq min 1) \n#*    (max:int where! \n#*       land (bgeq max min)\n#*            (implies (bgt max min)\n#*              (land (disjoint_cex (stype l) (regexp_iter (stype l) 2 2))\n#*              (lor (land (rel_is_id (vequiv l)) (is_basic l)) \n#*                   (disjoint_cex (vtype l) (regexp_iter (vtype l) 2 2))))))\n#*  : (l':lens where! in_lens_type l' \n#*               (regexp_iter (stype l) min max)\n#*               (regexp_iter (vtype l) min max))\n## = Native.Prelude.lens_iter l min max\n\n#* test get (lens_iter (copy [A-Z]) 1 4) \"ABCD\" = \"ABCD\"\n#* test put (lens_iter (copy [A-Z]) 1 4) \"AB\" \"ABCD\" = \"AB\"\n#* test create (lens_iter (copy [A-Z]) 1 4) \"A\" = \"A\"\n\n\\LENSSECTION{@invert@} The @invert@ operator swaps the $\\GET$ and $\\CREATE$ \ncomponents of a lens, which must be bijective.\n\n#* let invert \n#*     (l:lens where! land (bij l) (is_basic l)) \n#*   : (l':lens where! in_bij_lens_type l' (vtype l) (stype l))\n##   = Native.Prelude.invert l\n\n#* test get (invert (const [A] \"B\" \"A\")) \"B\" = \"A\"\n#* test invert (const [A-Z] \"B\" \"A\") = error\n\n\\LENSSECTION{@default@} The @default@ operator takes a lens @l@ and a string \n@d@ as arguments. It overrides @l@'s $\\CREATE$ function to use $\\PUT$ with \n@d@.\n\n#* let default (l:lens where! is_basic l)\n#*             (d:string where! matches_cex (stype l) d)\n#*           : (l':lens where! in_lens_type l' (stype l) (vtype l))\n## = Native.Prelude.default l d\n\n#* test create (default (const [A-Z] \"X\" \"A\") \"B\") \"X\" = \"B\"\n\n\\LENSSECTION{@merge@} The @merge@ operator takes a regular expression @R@ \nand produces a lens whose $\\GET$ function transforms a string belonging to the \nconcatenation of @R@ with itself by discarding the second substring belonging \nto @R@. The regular expression @R@ must be unambiguously concatenable with itself.\n\n#* let merge \n#*     (R:regexp where! splittable_cex R R) \n#*   : (l:lens where! in_lens_type l (regexp_concat R R) R)\n##   = Native.Prelude.merge R\n\n#* test get (merge [A-Z]) \"AA\" = \"A\"\n#* test get (merge [A-Z]) \"AB\" = \"A\"\n#* test put (merge [A-Z]) \"C\" \"AA\" = \"CC\"\n#* test put (merge [A-Z]) \"C\" \"AB\" = \"CB\"\n\n\\subsection{Resourceful Lenses}\n\n%The next few primitives construct lenses for handling ordered data \n%called dictionary lenses. For details, see \\citet{Boomerang07}.\n\n\\LENSSECTION{@key@,@nokey@,@force_key@,@force_nokey@} These functions\ndefines the key annotation of the characters under it. The @force_key@\nand @force_nokey@ overrides previous definitions while @key@ and @nokey@\nonly set the annotation for characters that does not have yet an\nannotation.\n\n#* let key (l:lens)\n#*       : (l':lens where! in_lens_type l' (stype l) (vtype l))\n## = Native.Prelude.lens_weight false 1 l\n\n#* let nokey (l:lens) \n#*         : (l':lens where! in_lens_type l' (stype l) (vtype l))\n## = Native.Prelude.lens_weight false 0 l\n\n#* let force_key (l:lens)\n#*             : (l':lens where! in_lens_type l' (stype l) (vtype l))\n## = Native.Prelude.lens_weight true 1 l\n\n#* let force_nokey (l:lens) \n#*               : (l':lens where! in_lens_type l' (stype l) (vtype l))\n## = Native.Prelude.lens_weight true 0 l\n\n\\LENSSECTION{@lens_match@} The @lens_match@ operator takes as arguments\na string @t@ and a lens @l@ and creates a ``chunk'' with tag @t@. The\ntype checker requires that there is not a tag inside @l@ with the same\nidentifier as the tag @t@. The operator @<tag:aregexp>@ desugars into\n@lens_match@ and the operator @<aregexp>@ desugars to @lens_match@ with\ntag @greedy 0 \"\"@.\n\n#* let lens_match\n#*     (t:tag)\n#*     (l:lens where! mtype_match_compatible_cex t (ktype l) (mtype l)) \n#*   : (l':lens where! in_lens_type l' (stype l) (vtype l))\n## = Native.Prelude.lens_match t l\n\n\\LENSSECTION{@align@} The @align@ operator converts a resourceful\nlens @l@ into a basic lens, making an alignment phase internal to it.\n\n#* let align\n#*     (l:lens) \n#*   : (l':lens where! land (in_lens_type l' (stype l) (vtype l))\n#*                         (is_basic l'))\n## = Native.Prelude.align l\n\n\\LENSSECTION{@fiat@} The @fiat@ operator takes a lens @l@ as an \nargument. It behaves like @l@, but overrides its $\\PUT$ component with a \nfunction that returns the original source exactly whenever the update to the \nview is a no-op.\n\n#* let fiat\n#*     (l:lens where! is_basic l) \n#*   : (l':lens where! in_lens_type l' (stype l) (vtype l))\n## = Native.Prelude.fiat l\n\n\\subsection{Canonizer Components}\n\n\\LENSSECTION{@uncanonized_type@} The @uncanonized_type@ function extracts the \n``representative'' type component (i.e., the type of the domain of its \n$\\CANONIZE$ function) of a canonizer. \n\n#* let uncanonized_type : canonizer -> regexp \n## = Native.Prelude.uncanonized_type\n\n#* let uncanonized_atype : canonizer -> aregexp \n## = Native.Prelude.uncanonized_atype\n\n\\LENSSECTION{@canonized_type@} The @canonized_type@ function extracts the \n``quotiented'' type component (i.e., the type of the codomain of its \n$\\CANONIZE$ function) of a  canonizer. \n\n#* let canonized_type : canonizer -> regexp \n## = Native.Prelude.canonized_type\n\n#* let canonized_atype : canonizer -> aregexp \n## = Native.Prelude.canonized_atype\n\n\\LENSSECTION{@in_canonizer_type@} The @in_canonizer_type@ function tests \nwhether a canonizer has the given uncanonized and canonized types.\n\n#* let in_canonizer_type (cn:canonizer) (U:regexp) (C:regexp)\n#*   = (land (equiv_cex (uncanonized_type cn) U)\n#*           (equiv_cex (canonized_type cn) C))\n\n\\LENSSECTION{@canonizer_is_basic@} The @canonizer_is_basic@ function\ntests whether a canonizer is a basic canonizer (i.e. does not contain\nany chunk).\n\n#* let canonizer_is_basic (cn:canonizer) : bool =\n#*   no_chunks (canonized_atype cn)\n% For the moment we only have symmetric canonizers, so there is no need to check uncanonized_atype\n\n\\subsection{Canonizers}\n\n\\LENSSECTION{@cnrel@} The @cnrel@ function extracts the equivalence \nrelation on a canonizer's (canonized) type.\n\n#* let cnrel : canonizer -> rel\n##   = (fun (cn:canonizer) -> \n##        rel_of_is_id (Native.Prelude.cnrel_identity cn))\n\n\\LENSSECTION{@canonize@} The @canonize@ function extracts the $\\CANONIZE$\ncomponent of a canonizer. The record-style projection notation \n@q.canonize@ desugars into @canonize@.\n\n#* let canonize \n#*     (cn:canonizer) \n#*     (c:string where! matches_cex (uncanonized_type cn) c) \n#*   : string\n## = Native.Prelude.canonize cn c\n\n\\LENSSECTION{@choose@} The @choose@ function extracts the $\\CHOOSE$\ncomponent of a canonizer. The record-style projection notation \n@q.choose@ desugars into @choose@.\n\n#* let choose\n#*     (cn:canonizer)\n#*     (b:string where! matches_cex (canonized_type cn) b)\n#*   : string\n## = Native.Prelude.choose cn b\n\n\\LENSSECTION{@canonizer_of_lens@} The @canonizer_of_lens@ operator\nbuilds a canonizer out of a lens with the lens's $\\GET$ function as the\n$\\CANONIZE$ component and  $\\CREATE$ as $\\CHOOSE$.\n\n#* let canonizer_of_lens (l:lens)\n#*   : (cn:canonizer where! in_canonizer_type cn (stype l) (vtype l))\n##   = Native.Prelude.canonizer_of_lens l\n\n\\LENSSECTION{@canonizer_concat@} The @canonizer_concat@ operator\nconcatenates canonizers. Only the concatenation of types on the left \nside needs to be unambiguous.\n\n#* let canonizer_concat \n#*   (cn1:canonizer)\n#*   (cn2:canonizer where! \n#*     land (splittable_cex (uncanonized_type cn1) (uncanonized_type cn2))\n#*          (implies \n#*             (not (land (rel_is_id (cnrel cn1)) (rel_is_id (cnrel cn2))))\n#*             (splittable_cex (canonized_type cn1) (canonized_type cn2))))\n#*   : (cn:canonizer where! in_canonizer_type cn \n#*           (regexp_concat (uncanonized_type cn1) (uncanonized_type cn2))\n#*           (regexp_concat (canonized_type cn1) (canonized_type cn2)))\n## = Native.Prelude.canonizer_concat cn1 cn2\n\n\\LENSSECTION{@canonizer_union@} The @canonizer_union@ operator\nforms the union of two canonizers. The types on the left need to be \ndisjoint. \n\n#* let canonizer_union \n#*     (cn1:canonizer) \n#*     (cn2:canonizer where! land (disjoint_cex (uncanonized_type cn1)\n#*                                             (uncanonized_type cn2))\n#*                               (lor (land (canonizer_is_basic cn1)\n#*                                          (canonizer_is_basic cn2))\n#*                                    (disjoint_cex (canonized_type cn1)\n#*                                                  (canonized_type cn2))))\n#*   : (cn:canonizer where! in_canonizer_type cn\n#*         (regexp_union (uncanonized_type cn1) (uncanonized_type cn2))\n#*         (regexp_union (canonized_type cn1) (canonized_type cn2)))\n##   = Native.Prelude.canonizer_union cn1 cn2\n\n\\LENSSECTION{@canonizer_iter@} The @canonizer_iter@ operator\niterates a canonizer. The iteration of the type on the left \nneeds to be unambiguous. The overloaded operators @*@, @+@, @?@, \n@{m,n}@ and @{n,}@ all desugar into instances of @canonizer_iter@ when \napplied to a canonizer. If the second argument is negative, then the \niteration is unbounded. For example,  @q*@ desugars \ninto @canonizer_iter q 0 (-1)@.\n\n#* let canonizer_iter\n#*   (cn:canonizer where!\n#*        land (iterable_cex (uncanonized_type cn))\n#*             (implies (not (rel_is_id (cnrel cn)))\n#*                      (iterable_cex (canonized_type cn))))\n#*   (min:int where! bgeq min 0) (max:int)\n#* : (cn':canonizer where! in_canonizer_type cn' \n#*          (regexp_iter (uncanonized_type cn) min max)\n#*          (regexp_iter (canonized_type cn) min max))\n## = Native.Prelude.canonizer_iter cn min max\n\n\\LENSSECTION{@columnize@} The @columnize@ primitive canonizer wraps \nlong lines of text. It takes as arguments an integer @n@, a regular\nexpression @R@, a character @s@ and a string @nl@. It produces a \ncanonizer whose $\\CANONIZE$ component takes strings belonging to \nthe iteration of @R@, extended so that @s@ and @nl@ may appear \nanywhere that @s@ may, and replaces @nl@ with @s@ globally. Its \n$\\CHOOSE$ component wraps a string belonging to the iteration of \n@R@ by replacing @s@ with @nl@ to obtain a string in which \n(if possible) the length of every line is less than or equal to @n@.\n\n#* let columnize \n#*   (k:int)\n#*   (R:regexp)\n#*   (sp:char)\n#*   (nl:string where!\n#*         disjoint_cex R (regexp_concat (regexp_star [^]) \n#*                                       (regexp_concat (regexp_of_string nl) \n#*                                       (regexp_star [^]))))\n#* : canonizer\n## = Native.Prelude.columnize k R sp nl\n\n\\noindent The following unit test illustrates the $\\CHOOSE$ component of\n@columnize@.\n\n#* test choose (columnize 5 (regexp_star [a-z ]) ' ' \"\\n\")\n#*        \"a b c d e f g\" =\n#* <<\n#*   a b c\n#*   d e f\n#*   g\n#* >>\n\n\\subsection{Quotient Lenses}\n\nThe next few primitives construct lenses that work up to programmer-specified \nequivalence relations. We call these structures quotient lenses. For details, \nsee \\citet{QuotientLenses08}.\n\n\\LENSSECTION{@left_quot@} The @left_quot@ operator quotients a lens @l@ by \na canonizer @q@ on the left by passing concrete strings through @q@.  \n\n#* let left_quot \n#*   (cn:canonizer)\n#*   (l:lens where! land (aequiv_cex (canonized_atype cn) (astype l))\n#*                      (rel_is_id (cnrel cn)))\n#* : (l':lens where! in_lens_type l' (uncanonized_type cn) (vtype l))\n## = Native.Prelude.left_quot cn l\n\n#* test get \n#*   (left_quot (columnize 5 (regexp_star [a-z ]) ' ' \"\\n\")\n#*              (copy (regexp_star [a-z ])))\n#* <<\n#*   a b c\n#*   d e f\n#*   g\n#* >>\n#* = \"a b c d e f g\"\n\n#* test create \n#*   (left_quot (columnize 5 (regexp_star [a-z ]) ' ' \"\\n\")\n#*              (copy (regexp_star [a-z ])))\n#* \"a b c d e\"\n#* = \n#* <<\n#*   a b c\n#*   d e\n#* >>\n\n\n\\LENSSECTION{@right_quot@} The @right_quot@ operator quotients a lens @l@ by \na canonizer @q@ on the right by passing abstract strings through @q@.  \n\n#* let right_quot\n#*   (l:lens)\n#*   (cn:canonizer where! land (aequiv (canonized_atype cn) (avtype l))\n#*                            (rel_is_id (cnrel cn)))\n#* : (l':lens where! in_lens_type l' (stype l) (uncanonized_type cn))\n## = Native.Prelude.right_quot l cn\n\n\\LENSSECTION{@dup1@} The @dup1@ operator takes as arguments a \nlens @l@, a function @f@, and a regular expression @R@, which \nshould denote the codomain of @f@. Its $\\GET$ function supplies \none copy of the concrete string to @l@'s $\\GET$ function and one \nto @f@, and concatenates the results. The $\\PUT$ and $\\CREATE$ functions \nsimply discard the part of the string computed by @f@ and use the \ncorresponding from @l@ on the rest of the string. The concatenation of \n@l@'s abstract type and the codomain of @f@ must be unambiguous.\n\n#* let dup1 \n#*     (l:lens where! is_basic l)\n#*     (R:regexp)\n#*     (f:string -> (x:string where! matches_cex R x))\n#*  :  (l':lens where! in_lens_type l' \n#*           (stype l) (regexp_concat (vtype l) R))\n## = Native.Prelude.dup1 l f R \n\n#* test get (dup1 (copy [A-Z]) [A-Z] (get (copy [A-Z]))) \"A\" = \"AA\"\n#* test put (dup1 (copy [A-Z]) [A-Z] (get (copy [A-Z]))) \"BC\" \"A\" = \"B\"\n\n\\LENSSECTION{@dup2@} The @dup2@ operator is like @dup1@ but uses\n@f@ to build the first part of the output.\n\n#* let dup2\n#*     (R:regexp)\n#*     (f:string -> (x:string where! matches_cex R x)) \n#*     (l:lens where! is_basic l)\n#*   : (l':lens where! in_lens_type l' \n#*         (stype l) (regexp_concat R (vtype l)))\n## = Native.Prelude.dup2 f R l \n\n#* test get (dup2 [A-Z] (get (copy [A-Z])) (copy [A-Z])) \"A\" = \"AA\"\n#* test put (dup2 [A-Z] (get (copy [A-Z])) (copy [A-Z])) \"BC\" \"A\" = \"C\"\n\n"
let _ = Hashtbl.add items "ical" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2009 J. Nathan Foster                                        *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /examples/ical.boom                                                        *)\n(* iCal lens                                                                  *)\n(* $Id: ical.boom 4607 2009-08-03 16:53:28Z ddavi $ *)\n\n(* TODO: add proper escaping *)\n\nmodule Ical = \n\nlet SPACE,ASTERISK,COLON,DASH,LPAREN,RPAREN,NL = \" \",\"*\",\":\",\"-\",\"(\",\")\",\"\\n\"\nlet BEGIN_CALENDAR,END_CALENDAR : (regexp * regexp) = \"BEGIN:VCALENDAR\",\"END:VCALENDAR\"\nlet BEGIN_EVENT,END_EVENT : (regexp * regexp) = \"BEGIN:VEVENT\",\"END:VEVENT\"\nlet PREAMBLE,POSTAMBLE : (regexp * regexp) = (BEGIN_CALENDAR . NL . ( ANY - containing BEGIN_EVENT)),(END_CALENDAR . NL)\nlet text : lens = Escaping.escape [^\\n] #{char*string}[('\\',\"\\\\\\\\\");('(',\"\\\\(\");(')',\"\\\\)\")]\nlet TEXT,ESCTEXT : regexp * regexp = stype text,vtype text\nlet TIME,LOC : regexp * regexp = (DIGIT{2} . \":\" . DIGIT{2}), (SPACE . LPAREN . ESCTEXT . RPAREN)\n\nlet line (tag:string) (l:lens) : lens = del (tag . \":\") . l . del \"\\n\"\nlet parens (l:lens) : lens = ins \"(\" . l . ins \")\"\nlet wrapl (l:lens) = left_quot (columnize 75 (stype l) ' ' (\"\\n  \")) l\nlet wrapr (l:lens) = right_quot l (columnize 75 (vtype l) ' ' (\"\\n  \"))\nlet now (s:string) : string = Sys.exec \"date +%H%M%S | tr -d '\\n'\"\nlet today (s:string) : string = Sys.exec \"date +%Y%m%d | tr -d '\\n'\"\nlet uid (s:string) : string = Sys.exec \"cat /dev/urandom|uuencode -m -|tail +2|tr -dc 'a-zA-Z0-9'|head -c25\"\nlet date (tag:string) (time:regexp -> regexp -> regexp -> lens) : lens = \n  line tag (clobber DIGIT{8} \"\" today . del \"T\" . time DIGIT{2} DIGIT{2} DIGIT{2} . del \"Z\")\nlet copy_time (H:regexp) (M:regexp) (S:regexp) : lens = copy H . ins \":\" . copy M . del S \nlet clobber_time (H:regexp) (M:regexp) (S:regexp) : lens = clobber (H . M . S) \"\" now\n\nlet event1 : lens = \n  del (BEGIN_EVENT . NL) . \n  fiat (Sort.sort_concat \n    #{lens}[\n      line \"CLASS\" (\"PRIVATE\" <-> ASTERISK | \"PUBLIC\" <-> SPACE)\n    ; date \"DTSTART\" copy_time . ins DASH \n    ; date \"DTEND\" copy_time . ins SPACE \n    ; date \"DTSTAMP\" clobber_time \n    ; date \"CREATED\" clobber_time \n    ; date \"LAST-MODIFIED\" clobber_time \n    ; line \"UID\" (clobber TEXT \"\" uid)\n    ; line \"TRANSP\" (const TEXT \"\" \"OPAQUE\") \n    ; line \"DESCRIPTION\" (del TEXT)\n    ; line \"STATUS\" (const TEXT \"\" \"TENTATIVE\") \n    ; line \"SEQUENCE\" (const NUMBER \"\" \"0\") \n    ; line \"SUMMARY\" (wrapl (text; key ESCTEXT)) . ins SPACE\n    ; line \"LOCATION\" (parens (wrapl (text; key ESCTEXT))) ]) . \n  del (END_EVENT) . copy NL\nlet event2 : lens =  \n  copy (SPACE | ASTERISK) . merge_with_sep TIME DASH . \n  copy SPACE . wrapr (key ESCTEXT . copy LOC) . copy NL\nlet ical1 : lens = del PREAMBLE . <greedy 0 \"\":event1 >* . del POSTAMBLE\nlet ical : lens = ical1; <greedy 0 \"\":event2 >*\n\nlet l  =  (copy (SPACE | ASTERISK) . \nmerge_with_sep TIME \"-\" . \ncopy (SPACE . ESCTEXT. LOC . NL))*\n\n(* test \"before ical\" = ?  *)\n(* test avtype ical1 = ? *)\n(* test astype (<g_:event2 >* ) = ? *)\n(* test aequiv (avtype ical1) (astype (<g_:event2 >* )) = ? *)\n(* test sequiv (<g_:event2 >* ) = ? *)\n\nlet ical2 : lens = \n  align ical1; \n  (copy (SPACE | ASTERISK) . \n  merge_with_sep TIME \"-\" . \n  copy (SPACE . ESCTEXT. LOC . NL))*\n\n\nlet public : lens = \n  del SPACE . \n  copy TIME . \n  copy (ESCTEXT . LOC) . \n  copy NL\n\nlet private : lens = \n  del ASTERISK . \n  copy TIME . \n  (ESCTEXT . LOC) <-> \"BUSY\" . \n  copy NL\n\nlet redact : lens = \n  (public | private)*\n\nlet erase : lens = \n  filter (stype private) (stype public); \n  public*\n\n\n\n(* html stuff *)\nlet pcdata : lens = \n  invert text; \n  Escaping.escape_with '&' [^\\n] Escaping.xml_escs\nlet PCDATA : regexp = vtype pcdata \nlet html_entry : lens = \n  MkXml.simple_elt NL2 \"time\" (merge_with_sep TIME \"-\") . \n  MkXml.simple_elt NL2 \"description\" (del \" \" . pcdata) .\n  MkXml.simple_elt NL2 \"location\" (del \" (\" . pcdata . del \")\") .\n  del \"\\n\"\nlet html_pub : lens = del \" \" . MkXml.elt NL1 \"entry\" html_entry\nlet html_pvt : lens = del \"*\" . MkXml.attr1_elt NL1 \"entry\" \"class\" (ins \"private\") html_entry\nlet html : lens = MkXml.outer_elt NL0 \"calendar\" (html_pub | html_pvt)*\n\nlet xml : lens = align ical1 ; html\n\ntest xml.get\n<<\nBEGIN:VCALENDAR\nBEGIN:VEVENT\nCLASS:PRIVATE\nDTSTART:20090215T081500Z\nDTEND:20090215T140000Z\nDTSTAMP:20090224T222716Z\nSUMMARY:Coffee with Sara\nLOCATION:La Columbe Coffee\nUID:856dv2lb8aiknrad10qq171jmg@google.com\nTRANSP:OPAQUE\nCREATED:20090224T222529Z\nDESCRIPTION:\nLAST-MODIFIED:20090227T233055Z\nSTATUS:CONFIRMED\nSEQUENCE:0\nEND:VEVENT\nBEGIN:VEVENT\nCLASS:PRIVATE\nDTSTART:20090215T200000Z\nDTEND:20090215T210000Z\nDTSTAMP:20090224T222716Z\nSUMMARY:Worko\nLOCATION:Gym\nUID:usqehvnsot5gplg7qkvig6ljvc@google.com\nTRANSP:OPAQUE\nCREATED:20090224T222610Z\nDESCRIPTION:\nLAST-MODIFIED:20090227T233055Z\nSTATUS:CONFIRMED\nSEQUENCE:0\nEND:VEVENT\nBEGIN:VEVENT\nCLASS:PRIVATE\nDTSTART:20090227T210000Z\nDTEND:20090227T210000Z\nDTSTAMP:20090227T231702Z\nSUMMARY:Meeting with Michael\nLOCATION:My office\nUID:jH0z0t7RKbx0BYGp5OkZ9zcLN@google.com\nTRANSP:OPAQUE\nCREATED:20090227T231702Z\nDESCRIPTION:\nLAST-MODIFIED:20090227T233055Z\nSTATUS:TENTATIVE\nSEQUENCE:0\nEND:VEVENT\nEND:VCALENDAR\n\n>> = \n<<\n<calendar>\n <entry class=\"private\">\n  <time>08:15</time>\n  <description>Coffee with Sara</description>\n  <location>La Columbe Coffee</location>\n </entry>\n <entry class=\"private\">\n  <time>20:00</time>\n  <description>Worko</description>\n  <location>Gym</location>\n </entry>\n <entry class=\"private\">\n  <time>21:00</time>\n  <description>Meeting with Michael</description>\n  <location>My office</location>\n </entry>\n</calendar>\n>>\n"
let _ = Hashtbl.add items "plist" "module Plist =\n\n(* nesting *)\nlet indent (spaces:string in Xml.WS) : (string in Xml.WS) = spaces . \"  \"\n\n(* simple values in plist/xml\n   \n   we let the inner lens, l, handle whitespace at the front; pvalue\n   will eliminate whitespace at the end\n*)\nlet kill_ws : (lens in Xml.WS <-> \"\") = qdel Xml.WS \"\"\nlet pvalue (spaces:string in Xml.WS) (tag:string) (l:lens where lens_splittable l kill_ws)\n    : (lens in Xml.ELT tag (stype l) <-> vtype l)\n    = Xml.simple_elt spaces tag (l . kill_ws)\n\n(* used to remove whitespace at the front of pvalues\n\n   we use pvalues/padded instead of Xml.elt so we can get a nicer\n   canonized form: we'd rather see \n\n     <integer>5</integer> \n\n   than \n\n     <integer>5\n     </integer>\n*)\nlet PADDED (R:regexp) : regexp = Xml.WS . R\nlet padded (l:lens) : (lens in PADDED (stype l) <-> vtype l)\n    = del Xml.WS . l\n\n(* DTD taken from http://www.apple.com/DTDs/PropertyList-1.0.dtd *)\n\n(* Primitive types\n\n   <!ELEMENT string (#PCDATA)>\n\n   <!ELEMENT data (#PCDATA)> <!-- Contents interpreted as Base-64 encoded -->\n \n   <!ELEMENT date (#PCDATA)> \n   <!-- Contents should conform to a subset of ISO 8601 (in particular,\n   YYYY '-' MM '-' DD 'T' HH ':' MM ':' SS 'Z'.  Smaller units may be\n   omitted with a loss of precision) -->\n*)\n\nlet pstring (spaces:string in Xml.WS) (l:lens where lens_splittable l kill_ws)\n    : (lens in Xml.ELT \"string\" (stype l) <-> vtype l)\n    = pvalue spaces \"string\" l\n\n(* http://tools.ietf.org/html/rfc1421 pages 12-3\n\n   The encoding process represents 24-bit groups of input bits as output\n   strings of 4 encoded characters. Proceeding from left to right across\n   a 24-bit input group extracted from the output of step 3, each 6-bit\n   group is used as an index into an array of 64 printable characters.\n   The character referenced by the index is placed in the output string.\n   These characters, identified in Table 1, are selected so as to be\n   universally representable, and the set excludes characters with\n   particular significance to SMTP (e.g., \".\", \"<k:CR>\", \"<k:LF>\").\n\n   Special processing is performed if fewer than 24 bits are available\n   in an input group at the end of a message.  A full encoding quantum\n   is always completed at the end of a message.  When fewer than 24\n   input bits are available in an input group, zero bits are added (on\n   the right) to form an integral number of 6-bit groups.  Output\n   character positions which are not required to represent actual input\n   data are set to the character \"=\".  Since all canonically encoded\n   output is an integral number of octets, only the following cases can\n   arise: (1) the final quantum of encoding input is an integral\n   multiple of 24 bits; here, the final unit of encoded output will be\n   an integral multiple of 4 characters with no \"=\" padding, (2) the\n   final quantum of encoding input is exactly 8 bits; here, the final\n   unit of encoded output will be two characters followed by two \"=\"\n   padding characters, or (3) the final quantum of encoding input is\n   exactly 16 bits; here, the final unit of encoded output will be three\n   characters followed by one \"=\" padding character.\n*)\n\nlet BASE64CHAR : regexp = [A-Za-z0-9+/]\nlet BASE64QUANTUM : regexp = (BASE64CHAR . Xml.WS){4}\nlet BASE64ENDING : regexp = \n  ((BASE64CHAR . Xml.WS){3} . (BASE64CHAR | \"=\")) | \n  ((BASE64CHAR . Xml.WS){2} . \"=\" . Xml.WS . \"=\")\nlet BASE64 : regexp = BASE64QUANTUM* . BASE64ENDING\n\nlet pdata (spaces:string in Xml.WS) (l:lens where subset (stype l) (PADDED BASE64))\n  : (lens in Xml.ELT \"data\" (stype l) <-> vtype l)\n  = pvalue spaces \"data\" l\n\n(* TODO ISO 8601 calls 19 valid way to refer to the 20th century, etc. *)\nlet NUM2 : regexp = DIGIT{2}\nlet ISO8601_DATE : regexp = ISO8601.Date.COMPLETE . \"T\".NUM2.\":\".NUM2.\":\".NUM2.\"Z\"\n\nlet pdate (spaces:string in Xml.WS) (l:lens where subset (stype l) (PADDED ISO8601_DATE))\n  : (lens in Xml.ELT \"date\" (stype l) <-> vtype l)\n  = pvalue spaces \"date\" l\n\n(* Numerical primitives\n\n   <!ELEMENT true EMPTY>  <!-- Boolean constant true -->\n\n   <!ELEMENT false EMPTY> <!-- Boolean constant false -->\n\n   <!ELEMENT real (#PCDATA)> \n   <!-- Contents should represent a floating point number matching (\"+\" | \"-\")? \n   d+ (\".\"d* )? (\"E\" (\"+\" | \"-\") d+)? where d is a digit 0-9.  -->\n\n   <!ELEMENT integer (#PCDATA)> \n   <!-- Contents should represent a (possibly signed) integer number in base 10 -->\n*)\n\nlet ptrue (spaces:string in Xml.WS)\n  : (lens in (Xml.WS . Xml.EMPTYELT \"true\") <-> \"\")\n  = Xml.simple_elt_no_kids spaces \"true\"\n\nlet pfalse (spaces:string in Xml.WS)\n  : (lens in (Xml.WS . Xml.EMPTYELT \"false\") <-> \"\")\n  = Xml.simple_elt_no_kids spaces \"false\"\n\n(* is there another way to do this, e.g., using ptrue and pfalse?\n\n   it seems like we keep having to lift conditionals all the way to the top...\n*)\nlet pbool (spaces:string in Xml.WS) (strue:string) (sfalse:string where not (strue = sfalse))\n  : (lens in (Xml.WS . (Xml.EMPTYELT \"true\" | Xml.EMPTYELT \"false\")) <-> (strue | sfalse))\n  = qdel Xml.WS spaces . (Xml.EMPTYELT \"true\" <-> strue || Xml.EMPTYELT \"false\" <-> sfalse)\n\ntest (pbool \"\" \"yes\" \"no\").get \"<true/>\" = \"yes\"\ntest (pbool \"\" \"yes\" \"no\").put \"no\" into \"<true/>\" = \"<false/>\"\n\nlet PLUSMINUS : regexp = '+' | '-'\n\nlet REAL : regexp = PLUSMINUS? . DIGIT+ . ( '.' . DIGIT* )? . (\"E\" . PLUSMINUS . DIGIT+)?\nlet preal (spaces:string in Xml.WS) (l:lens where subset (stype l) (PADDED REAL))\n  : (lens in Xml.ELT \"real\" (stype l) <-> vtype l)\n  = pvalue spaces \"real\" l\n\ntest (preal \"  \" REAL).get \"<real>+3.01E-10</real>\" = \"+3.01E-10\"\ntest (preal \"  \" REAL).create \"-1\" = \"  <real>-1</real>\"\n\nlet INTEGER : regexp = PLUSMINUS? . DIGIT+\nlet pinteger (spaces:string in Xml.WS) (l:lens where subset (stype l) (PADDED INTEGER))\n  : (lens in Xml.ELT \"integer\" (stype l) <-> vtype l)\n  = pvalue spaces \"integer\" l\n\ntest (pinteger \"  \" INTEGER).get \"<integer>120</integer>\" = \"120\"\ntest (pinteger \"  \" INTEGER).put \"5\" into \"<integer>0 </integer>\" = \"  <integer>5</integer>\"\ntest (pinteger \"  \" INTEGER).create \"120\" = \"  <integer>120</integer>\"\n\n(* Collections\n\n   <!ELEMENT array (%plistObject;)*>\n\n   <!ELEMENT dict (key, %plistObject;)*>\n\n   <!ELEMENT key (#PCDATA)>\n\n   \"When encoding the contents of a CFDictionary object, each member is\n   encoded by placing the dictionary key in a <key> tag and immediately\n   following it with the corresponding value\"\n\n   http://developer.apple.com/documentation/CoreFoundation/Conceptual/CFPropertyLists/Articles/XMLTags.html\n*)\n\nlet EMPTY_ARRAY : regexp = Xml.WS . Xml.EMPTYELT \"array\"\n\nlet empty_array (spaces:string in Xml.WS)\n    : (lens in EMPTY_ARRAY <-> \"\")\n    = Xml.simple_elt_no_kids spaces \"array\"\n\nlet NONEMPTY_ARRAY (R:regexp) : regexp = Xml.ELT \"array\" R+\n\nlet nonempty_array (spaces:string in Xml.WS) (tag:string) (l:lens where lens_iterable l)\n  : (lens in NONEMPTY_ARRAY (stype l) <-> (vtype l)+ )\n  = Xml.elt spaces \"array\" <dictionary tag:l>+\n\nlet ARRAY (R:regexp) : regexp = EMPTY_ARRAY | NONEMPTY_ARRAY R\n\nlet parray (spaces:string in Xml.WS) (tag:string) (l:lens where lens_iterable l)\n  : (lens in ARRAY (stype l) <-> (vtype l)* )\n  = empty_array spaces | nonempty_array spaces tag l\n\nlet larray = parray \"\" \"nums\" (pinteger \"\" (copy INTEGER . ins \";\"))\ntest larray.get \"<array>\\n <integer>1</integer></array>\" = \"1;\"\ntest larray.create \"\" = \"<array/>\"\ntest larray.put \"5;4;3;\" into \"<array/>\" =\n  \"<array><integer>5</integer><integer>4</integer><integer>3</integer></array>\"\n\nlet pdict (spaces:string in Xml.WS) (l:lens)\n  : (lens in Xml.ELT \"dict\" (stype l) <-> vtype l)\n  = Xml.elt spaces \"dict\" l\n\nlet EMPTY_DICT = Xml.WS . Xml.EMPTYELT \"dict\"\n\nlet empty_dict (spaces:string in Xml.WS)\n  : (lens in EMPTY_DICT <-> \"\")\n  = Xml.simple_elt_no_kids spaces \"dict\"\n\n(* first, homogenous dictionaries *)\nlet KEY (K:regexp) : regexp = Xml.ELT \"key\" K\n\nlet pkey (spaces:string in Xml.WS) (K:regexp)\n  : (lens in KEY K <-> K)\n  = pvalue spaces \"key\" (key K)\n\nlet KVELT (K:regexp) (V:regexp) : regexp =\n  KEY K . V\n\nlet KV (K:regexp) (V:regexp) : regexp =\n  K . V\n\nlet VALID_KV (spaces:string in Xml.WS) (K:regexp) (v:lens) : bool =\n  lens_splittable (pkey spaces K) v &&\n  lens_iterable (pkey spaces K . v)\n\nlet kvpair (spaces:string in Xml.WS) (K:regexp) (v:lens where lens_splittable (KEY K) v)\n  : (lens in KVELT K (stype v) <-> KV K (vtype v))\n  = pkey spaces K . v\n\nlet NONEMPTY_HDICT (K:regexp) (V:regexp) : regexp =\n  Xml.ELT \"dict\" (KVELT K V)+\n\nlet nonempty_hdict (spaces:string in Xml.WS) (tag:string) (KEYS:regexp) \n    (v:lens where VALID_KV (indent spaces) KEYS v)\n  : (lens in NONEMPTY_HDICT KEYS (stype v) <-> (KV KEYS (vtype v))+)\n  = let kv = kvpair (indent spaces) KEYS v in\n    pdict spaces <dictionary tag:kv>+\n\nlet HDICT (K:regexp) (V:regexp) : regexp = EMPTY_DICT | NONEMPTY_HDICT K V\n\nlet phdict (spaces:string in Xml.WS) (tag:string) (KEYS:regexp) \n    (v:lens where VALID_KV (indent spaces) KEYS v)\n  : (lens in HDICT KEYS (stype v) <-> (KV KEYS (vtype v))* )\n  = empty_dict spaces | nonempty_hdict spaces tag KEYS v\n\n(* precomputed indentation *)\nlet field (l:lens) = ins \"=\" . l . ins \";\"\nlet lhdict = \n  phdict \"\\n\" \"hdict\" (\"foo\"|\"bar\"|\"baz\") (field (pinteger \"\\n  \" INTEGER))\ntest lhdict.get \"<dict>\\n<key>foo</key><integer>5</integer>\\n</dict>\" = \"foo=5;\"\ntest lhdict.get \"<dict/>\" = \"\"\ntest lhdict.put \"bar=5;foo=4;\" into \"<dict/>\" =\n  <<\n    \n    <dict>\n      <key>bar</key>\n      <integer>5</integer>\n      <key>foo</key>\n      <integer>4</integer>\n    </dict>\n  >>\n\n(* automatically managed indentation -- would be much less ugly with anaphora \n\n   also, this would be more elegant if spaces were always the _last_\n   argument.  then we could pass around partially applied elements, etc.\n*)\nlet nonempty_hsdict (spaces:string in Xml.WS) (tag:string) (KEYS:regexp)\n    (mk_v:(spaces2:(string in Xml.WS) -> (v:lens where VALID_KV spaces2 KEYS v)))\n  : (lens in NONEMPTY_HDICT KEYS (stype (mk_v (indent spaces))) <-> (KV KEYS (vtype (mk_v (indent spaces))))+)\n  = let inner_spaces = indent spaces in\n    let kv = kvpair inner_spaces KEYS (mk_v inner_spaces) in\n    pdict spaces <dictionary tag:kv>+\n\nlet phsdict (spaces:string in Xml.WS) (tag:string) (KEYS:regexp)\n    (mk_v:(spaces2:(string in Xml.WS) -> \n\t  (v:lens where VALID_KV spaces2 KEYS v)))\n  : (lens in HDICT KEYS (stype (mk_v (indent spaces))) <-> (KV KEYS (vtype (mk_v (indent spaces))))* )\n  = empty_dict spaces | nonempty_hsdict spaces tag KEYS mk_v\n\nlet lhsdict = \n  phsdict \"\\n\" \"hsdict\" (\"foo\"|\"bar\"|\"baz\") \n    (fun (spaces:string in Xml.WS) -> pinteger spaces (field INTEGER))\ntest lhsdict.get \"<dict>\\n<key>foo</key><integer>5</integer>\\n</dict>\" = \"foo=5;\"\ntest lhsdict.get \"<dict/>\" = \"\"\ntest lhsdict.put \"bar=5;foo=4;\" into \"<dict/>\" =\n  <<\n    \n    <dict>\n      <key>bar</key>\n      <integer>5</integer>\n      <key>foo</key>\n      <integer>4</integer>\n    </dict>\n  >>\n\n(* fixed-length fixed-order heterogenous *)\n\nlet KVELTS (spec:(regexp*lens) List.t) : regexp List.t = \n  List.map{regexp*lens}{regexp}\n    (fun (p:regexp*lens) ->\n       let k,v = p in\n       KVELT k (stype v))\n    spec\n\nlet KVS (spec:(regexp*lens) List.t) : regexp List.t =\n  List.map{regexp*lens}{regexp}\n    (fun (p:regexp*lens) ->\n       let k,v = p in\n       KV k (vtype v))\n    spec       \n\nlet VALID_KVS (spec:(regexp*lens) List.t) =\n  concatable (KVELTS spec) &&\n  concatable (KVS spec)\n\n(* TODO this pattern keeps coming up...we should have\n   concat_lenses_ne, etc. for nonempty lists *)\nlet kvpairs (spaces:string in Xml.WS)\n    (spec:(regexp*lens) List.t where List.nonempty{regexp*lens} spec\n                                  && VALID_KVS spec)\n  : (lens in concat_regexps (KVELTS spec) <-> concat_regexps (KVS spec))\n  = let (Some(l)) = \n      List.fold_left{regexp*lens}{lens option}\n\t(fun (lo:lens option) (p:regexp*lens) ->\n\t   let k,v = p in\n\t   let l = kvpair spaces k v in\n\t   match lo with\n\t     | None -> Some{lens}(l)\n\t     | Some(l2) -> Some{lens}(l2 . l))\n\tNone{lens} spec in\n    l\n\nlet NONEMPTY_ODICT (spec:(regexp*lens) List.t) : regexp =\n  Xml.ELT \"dict\" (concat_regexps (KVELTS spec))\n\nlet nonempty_odict (spaces:string in Xml.WS) \n    (spec:(regexp*lens) List.t where List.nonempty{regexp*lens} spec\n                                  && VALID_KVS spec)\n  : (lens in NONEMPTY_ODICT spec <-> concat_regexps (KVS spec))\n  = let kv = kvpairs (indent spaces) spec in\n    pdict spaces kv\n\nlet ODICT (spec:(regexp*lens) List.t) : regexp \n  =  match List.empty{regexp*lens} spec with\n      | true -> EMPTY_DICT\n      | false -> NONEMPTY_ODICT spec\n\nlet podict (spaces:string in Xml.WS) \n    (spec:(regexp*lens) List.t where VALID_KVS spec)\n  : (lens in ODICT spec <-> concat_regexps (KVS spec))\n  = match List.empty{regexp*lens} spec with\n      | true -> empty_dict spaces\n      | false -> nonempty_odict spaces spec\n\nlet LINECHAR = [a-zA-Z,.]\nlet LINE = (LINECHAR . ((LINECHAR | \" \")* . LINECHAR)?)?\n\nlet lodict =\n  podict \"\\n\" \n    #{regexp*lens}[\"Author\",field (pstring \"\\n  \" LINE) . ins '\\n';\n\t\t   \"Lines\",\n\t\t   field (parray \"\\n  \" \"lines\"\n\t\t\t    (pstring \"\\n    \" (LINE . ins \" / \"))) .\n\t\t   ins '\\n';\n\t\t   \"Birthdate\",field (pinteger \"\\n  \" INTEGER)]\n\nlet sample = \n  <<\n   \n    <dict>\n      <key>Author</key>\n      <string>William Shakespeare</string>\n      <key>Lines</key>\n      <array>\n        <string>It is a tale told by an idiot,</string>\n        <string>Full of sound and fury, signifying nothing.</string>\n      </array>\n      <key>Birthdate</key>\n      <integer>1564</integer>\n    </dict>\n  >>\n\ntest lodict.get sample = \n  <<\n    Author=William Shakespeare;\n    Lines=It is a tale told by an idiot, / Full of sound and fury, signifying nothing. / ;\n    Birthdate=1564;\n  >>\n\ntest lodict.create \n  <<\n    Author=William Carlos Williams;\n    Lines=so much depends / upon /  / a red wheel / barrow /  / glazed with rain / water /  / beside the white / chickens. / ;\n    Birthdate=1883;\n  >> =\n  <<\n   \n   <dict>\n     <key>Author</key>\n     <string>William Carlos Williams</string>\n     <key>Lines</key>\n     <array>\n       <string>so much depends</string>\n       <string>upon</string>\n       <string></string>\n       <string>a red wheel</string>\n       <string>barrow</string>\n       <string></string>\n       <string>glazed with rain</string>\n       <string>water</string>\n       <string></string>\n       <string>beside the white</string>\n       <string>chickens.</string>\n     </array>\n     <key>Birthdate</key>\n     <integer>1883</integer>\n   </dict>\n  >>\n\ntest lodict.put\n  <<\n    Author=Michael Greenberg;\n    Lines=so much depends / upon /  / a red sail / boat /  / glazed with delaware / water /  / beside the white / chickens. / ;\n    Birthdate=1984;\n  >> into\n  <<\n\n   <dict>\n     <key>Author</key>\n     <string>Michael Greenberg</string>\n     <key>Lines</key>\n     <array>\n       <string>so much depends</string>\n       <string>upon</string>\n       <string></string>\n       <string>a red wheel</string>\n       <string>barrow</string>\n       <string></string>\n       <string>glazed with rain</string>\n       <string>water</string>\n       <string></string>\n       <string>beside the white</string>\n       <string>chickens.</string>\n     </array>\n     <key>Birthdate</key>\n     <integer>1984</integer>\n   </dict>\n  >>\n  =\n  <<\n   \n   <dict>\n     <key>Author</key>\n     <string>Michael Greenberg</string>\n     <key>Lines</key>\n     <array>\n       <string>so much depends</string>\n       <string>upon</string>\n       <string></string>\n       <string>a red sail</string>\n       <string>boat</string>\n       <string></string>\n       <string>glazed with delaware</string>\n       <string>water</string>\n       <string></string>\n       <string>beside the white</string>\n       <string>chickens.</string>\n     </array>\n     <key>Birthdate</key>\n     <integer>1984</integer>\n   </dict>\n  >>\n\n(* ---- *)\n\nlet OPT (o:bool) (E:regexp) : regexp =\n  match o with\n    | true -> E?\n    | false -> E\n\nlet opt (o:bool) (l:lens) : (lens in OPT o (stype l) <-> OPT o (vtype l)) =\n  match o with\n    | true -> l?\n    | false -> l\n\nlet KVELTSOPT (spec:(bool*regexp*lens) List.t) : regexp List.t = \n  List.map{bool*regexp*lens}{regexp}\n    (fun (p:bool*regexp*lens) ->\n       let o,k,v = p in\n       OPT o (KVELT k (stype v)))\n    spec\n\nlet KVSOPT (spec:(bool*regexp*lens) List.t) : regexp List.t =\n  List.map{bool*regexp*lens}{regexp}\n    (fun (p:bool*regexp*lens) ->\n       let o,k,v = p in\n       OPT o (KV k (vtype v)))\n    spec\n\nlet full_spec (spec:(bool*regexp*lens) List.t) : (regexp*lens) List.t =\n  List.map{bool*regexp*lens}{regexp*lens}\n    (fun (p:bool*regexp*lens) -> let (_,k,v) = p in (k,v))\n    spec\n\n(* TODO this pattern keeps coming up...we should have\n   concat_lenses_ne, etc. for nonempty lists *)\nlet kvpairsopt (spaces:string in Xml.WS)\n    (spec:(bool*regexp*lens) List.t where List.nonempty{bool*regexp*lens} spec\n                                  && VALID_KVS (full_spec spec))\n  : (lens in concat_regexps (KVELTSOPT spec) <-> concat_regexps (KVSOPT spec))\n  = let (Some(l)) = \n      List.fold_left{bool*regexp*lens}{lens option}\n\t(fun (lo:lens option) (p:bool*regexp*lens) ->\n\t   let o,k,v = p in\n\t   let l = opt o (kvpair spaces k v) in\n\t   match lo with\n\t     | None -> Some{lens}(l)\n\t     | Some(l2) -> Some{lens}(l2 . l))\n\tNone{lens} spec in\n    l\n\nlet NONEMPTY_ODICTOPT (spec:(bool*regexp*lens) List.t) : regexp =\n  Xml.ELT \"dict\" (concat_regexps (KVELTSOPT spec))\n\nlet nonempty_odictopt (spaces:string in Xml.WS) \n    (spec:(bool*regexp*lens) List.t where List.nonempty{bool*regexp*lens} spec\n                                  && VALID_KVS (full_spec spec))\n  : (lens in NONEMPTY_ODICTOPT spec <-> concat_regexps (KVSOPT spec))\n  = let kv = kvpairsopt (indent spaces) spec in\n    pdict spaces kv\n\nlet ODICTOPT (spec:(bool*regexp*lens) List.t) : regexp \n  =  match List.empty{bool*regexp*lens} spec with\n      | true -> EMPTY_DICT\n      | false -> NONEMPTY_ODICTOPT spec\n\nlet podictopt (spaces:string in Xml.WS) \n    (spec:(bool*regexp*lens) List.t where VALID_KVS (full_spec spec))\n  : (lens in ODICTOPT spec <-> concat_regexps (KVSOPT spec))\n  = match List.empty{bool*regexp*lens} spec with\n      | true -> empty_dict spaces\n      | false -> nonempty_odictopt spaces spec\n\nlet lodictopt =\n  podictopt \"\\n\" \n    #{bool*regexp*lens}[false,\"Author\",field (pstring \"\\n  \" LINE) . ins '\\n';\n\t\t        false,\"Lines\",field (parray \"\\n  \" \"lines\"\n\t\t\t                 (pstring \"\\n    \" (LINE . ins \" / \"))) . ins '\\n';\n\t\t        true, \"Birthdate\",field (pinteger \"\\n  \" INTEGER)]\n\nlet sample1 = \n  <<\n   \n   <dict>\n     <key>Author</key>\n     <string>William Shakespeare</string>\n     <key>Lines</key>\n     <array>\n       <string>It is a tale told by an idiot,</string>\n       <string>Full of sound and fury, signifying nothing.</string>\n     </array>\n     <key>Birthdate</key>\n     <integer>1564</integer>\n   </dict>\n  >>\n\ntest lodictopt.get sample1 = \n  <<\n    Author=William Shakespeare;\n    Lines=It is a tale told by an idiot, / Full of sound and fury, signifying nothing. / ;\n    Birthdate=1564;\n  >>\n\nlet sample2 = \n  <<\n   \n   <dict>\n     <key>Author</key>\n     <string>William Shakespeare</string>\n     <key>Lines</key>\n     <array>\n       <string>It is a tale told by an idiot,</string>\n       <string>Full of sound and fury, signifying nothing.</string>\n     </array>\n   </dict>\n  >>\n\nlet sample3 =\n  <<\n    Author=William Shakespeare;\n    Lines=It is a tale told by an idiot, / Full of sound and fury, signifying nothing. / ;\n\n  >>\n\ntest lodictopt.get sample2 = sample3\n\ntest lodictopt.put sample3 into sample1 = sample2\n\n\n(* ----- *)\n\n(* fast-sorted heterogenous *)\n\nlet VALID_SKVS (spec:(regexp*lens) List.t) =\n  sortable (KVELTS spec) &&\n  concatable (KVS spec)\n\n(* TODO this pattern keeps coming up...we should have\n   concat_lenses_ne, etc. for nonempty lists *)\nlet skvpairs (spaces:string in Xml.WS)\n    (spec:(regexp*lens) List.t where List.nonempty{regexp*lens} spec\n                                  && VALID_SKVS spec)\n  : (lens in (union_regexps (KVELTS spec))* <-> concat_regexps (KVS spec))\n  = let kvs = \n      List.map{regexp*lens}{lens}\n\t(fun (p:regexp*lens) ->\n\t   let k,v = p in\n\t   kvpair spaces k v)\n\tspec in\n    Sort.sort_concat kvs\n\nlet NONEMPTY_SDICT (spec:(regexp*lens) List.t) : regexp =\n  Xml.ELT \"dict\" (union_regexps (KVELTS spec))*\n\nlet nonempty_sdict (spaces:string in Xml.WS) \n    (spec:(regexp*lens) List.t where List.nonempty{regexp*lens} spec\n                                  && VALID_SKVS spec)\n  : (lens in NONEMPTY_SDICT spec <-> concat_regexps (KVS spec))\n  = pdict spaces (skvpairs (indent spaces) spec)\n\nlet SDICT (spec:(regexp*lens) List.t) : regexp \n  =  match List.empty{regexp*lens} spec with\n      | true -> EMPTY_DICT\n      | false -> NONEMPTY_SDICT spec\n\nlet psdict (spaces:string in Xml.WS) \n    (spec:(regexp*lens) List.t where VALID_KVS spec)\n  : (lens in SDICT spec <-> concat_regexps (KVS spec))\n  = match List.empty{regexp*lens} spec with\n      | true -> empty_dict spaces\n      | false -> nonempty_sdict spaces spec\n\nlet lsdict =\n  psdict \"\\n\" \n    #{regexp*lens}[\"Author\",field (pstring \"\\n  \" LINE) . ins '\\n';\n\t\t   \"Lines\",\n\t\t   field (parray \"\\n  \" \"lines\"\n\t\t\t    (pstring \"\\n    \" (LINE . ins \" / \"))) .\n\t\t   ins '\\n';\n\t\t   \"Birthdate\",field (pinteger \"\\n  \" INTEGER)]\n\ntest lsdict.get sample = \n  <<\n    Author=William Shakespeare;\n    Lines=It is a tale told by an idiot, / Full of sound and fury, signifying nothing. / ;\n    Birthdate=1564;\n  >>\n\ntest lsdict.get\n  <<\n   \n    <dict>\n      <key>Lines</key>\n      <array>\n        <string>It is a tale told by an idiot,</string>\n        <string>Full of sound and fury, signifying nothing.</string>\n      </array>\n      <key>Author</key>\n      <string>William Shakespeare</string>\n      <key>Birthdate</key>\n      <integer>1564</integer>\n    </dict>\n  >>\n  =\n  <<\n    Author=William Shakespeare;\n    Lines=It is a tale told by an idiot, / Full of sound and fury, signifying nothing. / ;\n    Birthdate=1564;\n  >>\n\n\ntest lsdict.create \n  <<\n    Author=William Carlos Williams;\n    Lines=so much depends / upon /  / a red wheel / barrow /  / glazed with rain / water /  / beside the white / chickens. / ;\n    Birthdate=1883;\n  >> =\n  <<\n   \n   <dict>\n     <key>Author</key>\n     <string>William Carlos Williams</string>\n     <key>Lines</key>\n     <array>\n       <string>so much depends</string>\n       <string>upon</string>\n       <string></string>\n       <string>a red wheel</string>\n       <string>barrow</string>\n       <string></string>\n       <string>glazed with rain</string>\n       <string>water</string>\n       <string></string>\n       <string>beside the white</string>\n       <string>chickens.</string>\n     </array>\n     <key>Birthdate</key>\n     <integer>1883</integer>\n   </dict>\n  >>\n\ntest lsdict.put\n  <<\n    Author=Michael Greenberg;\n    Lines=so much depends / upon /  / a red sail / boat /  / glazed with delaware / water /  / beside the white / chickens. / ;\n    Birthdate=1984;\n  >> into\n  <<\n   <dict>\n     <key>Author</key>\n     <string>Michael Greenberg</string>\n     <key>Birthdate</key>\n     <integer>1984</integer>\n     <key>Lines</key>\n     <array>\n       <string>so much depends</string>\n       <string>upon</string>\n       <string></string>\n       <string>a red wheel</string>\n       <string>barrow</string>\n       <string></string>\n       <string>glazed with rain</string>\n       <string>water</string>\n       <string></string>\n       <string>beside the white</string>\n       <string>chickens.</string>\n     </array>\n   </dict>\n  >>\n  =\n  <<\n   \n   <dict>\n     <key>Author</key>\n     <string>Michael Greenberg</string>\n     <key>Lines</key>\n     <array>\n       <string>so much depends</string>\n       <string>upon</string>\n       <string></string>\n       <string>a red sail</string>\n       <string>boat</string>\n       <string></string>\n       <string>glazed with delaware</string>\n       <string>water</string>\n       <string></string>\n       <string>beside the white</string>\n       <string>chickens.</string>\n     </array>\n     <key>Birthdate</key>\n     <integer>1984</integer>\n   </dict>\n  >>\n\n(* TODO\n\n   even better dictionaries\n\n   -- sorted finite mappings\n   -- optional elements\n   -- homogenous (or simply regular?) tails\n*)\n\n(* Top level element\n\n   <!ELEMENT plist %plistObject;>\n   <!ATTLIST plist version CDATA \"1.0\" >\n*)\n\n(* we allow any local DTD, but if you use a public DTD, it has to be\n   the right one.\n\n   TODO\n\n   this DTD is simple enough that we could specify the scope of the\n   internal subset, if we wanted\n*)\nlet DTD_ID : regexp =\n  Xml.DOCTYPE \"plist\"\n    ((\"SYSTEM\" . Xml.WSP . Xml.SYSTEMID) |\n     (\"PUBLIC\" . Xml.WSP . \n\t\"\\\"-//Apple Computer//DTD PLIST 1.0//EN\\\"\" . Xml.WSP .\n\t\"\\\"http://www.apple.com/DTDs/PropertyList-1.0.dtd\\\"\"))\n\nlet PLIST (BODY:regexp) : regexp = \n  Xml.ATTR_ELT \"plist\" (Xml.ATTR \"version\" \"1.0\") BODY\n    \nlet plist (l:lens)\n  : (lens in ((Xml.PROLOG DTD_ID)? . PLIST (stype l)) <-> vtype l)\n  = del (Xml.PROLOG DTD_ID)? .\n    Xml.attr1_elt_open \"\" \"plist\" \"version\" (del \"1.0\") . \n    l . \n    Xml.close_tag \"\\n\" \"plist\"\n\nlet llist = plist lhsdict\ntest llist.get \n  <<\n    <plist version=\"1.0\">\n      <dict>\n        <key>foo</key><integer>5</integer>\n      </dict>\n    </plist>\n  >> = \"foo=5;\"\ntest llist.get \"<plist version='1.0'><dict/></plist>\" = \"\"\ntest llist.put \"bar=5;foo=4;\" into \"<plist version='1.0'><dict/></plist>\" =\n  <<\n    <plist version='1.0'>\n    <dict>\n      <key>bar</key>\n      <integer>5</integer>\n      <key>foo</key>\n      <integer>4</integer>\n    </dict>\n    </plist>\n  >>\n\n(* from http://developer.apple.com/documentation/Cocoa/Conceptual/PropertyLists/UnderstandXMLPlist/UnderstandXMLPlist.html *)\nlet llist2 = plist lodict\ntest llist2.get\n  <<\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    \n    <!DOCTYPE plist SYSTEM \"file://localhost/System/Library/DTDs/PropertyList.dtd\">\n    \n    <plist version=\"1.0\">\n    \n    <dict>\n    \n        <key>Author</key>\n    \n        <string>William Shakespeare</string>\n    \n        <key>Lines</key>\n    \n        <array>\n    \n            <string>It is a tale told by an idiot,</string>\n    \n            <string>Full of sound and fury, signifying nothing.</string>\n    \n        </array>\n    \n        <key>Birthdate</key>\n    \n        <integer>1564</integer>\n    \n    </dict>\n    \n    </plist>\n  >> = \n  <<\n    Author=William Shakespeare;\n    Lines=It is a tale told by an idiot, / Full of sound and fury, signifying nothing. / ;\n    Birthdate=1564;\n  >>\n\n(* from http://www.apple.com/applescript/features/propertylists.html *)\nlet llist3 =\n  plist (podict \"\\n  \"\n\t   #{regexp*lens}[\"booleanKey\",field (pbool \"\\n    \" \"#t\" \"#f\");\n\t\t\t  \"dateKey\",field (pdate \"\\n    \" ISO8601_DATE);\n\t\t\t  \"listKey\",empty_array \"\\n    \" . ins \";\";\n\t\t\t  \"numberKey\",field (pinteger \"\\n    \" INTEGER);\n\t\t\t  \"recordKey\",empty_dict \"\\n    \" . ins \";\";\n\t\t\t  \"stringKey\",field (pstring \"\\n    \" LINE)])\n\t\t\t  \ntest llist3.get\n  <<\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <!DOCTYPE plist PUBLIC \"-//Apple Computer//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n    <plist version=\"1.0\">\n      <dict>\n        <key>booleanKey</key>\n        <true/>\n        <key>dateKey</key>\n        <date>2007-08-07T22:09:04Z</date>\n        <key>listKey</key>\n        <array/>\n        <key>numberKey</key>\n        <integer>5</integer>\n        <key>recordKey</key>\n        <dict/>\n        <key>stringKey</key>\n        <string>string value</string>\n      </dict>\n    </plist>\n  >>\n  =\n  \"booleanKey=#t;dateKey=2007-08-07T22:09:04Z;listKey;numberKey=5;recordKey;stringKey=string value;\"\n\nlet llist4 =\n  let tab = \"\\n    \" in\n  plist \n    (podict \"\\n\"\n       #{regexp*lens}[\"Year Of Birth\",field (pinteger tab INTEGER);\n\t\t      \"Pets Names\",\n\t\t      field (empty_array tab);\n\t\t      \"Picture\", field (pdata tab (padded BASE64)) . ins '\\n';\n\t\t      \"City of Birth\",field (pstring tab LINE);\n\t\t      \"Name\",field (pstring tab LINE);\n\t\t      \"Kids Names\",\n\t\t      field (parray tab \"kids\"\n\t\t\t       (pstring (tab . \"    \") LINE . ins \";\"))])\n\n(* from http://developer.apple.com/documentation/Darwin/Reference/ManPages/man5/plist.5.html *)\ntest llist4.get\n  <<\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <!DOCTYPE plist PUBLIC \"-//Apple Computer//DTD PLIST 1.0//EN\"\n            \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n    <plist version=\"1.0\">\n    <dict>\n        <key>Year Of Birth</key>\n        <integer>1965</integer>\n        <key>Pets Names</key>\n        <array/>\n        <key>Picture</key>\n        <data>\n            PEKBpYGlmYFCPA==\n        </data>\n        <key>City of Birth</key>\n        <string>Springfield</string>\n        <key>Name</key>\n        <string>John Doe</string>\n        <key>Kids Names</key>\n        <array>\n            <string>John</string>\n            <string>Kyra</string>\n        </array>\n    </dict>\n    </plist>\n  >> = \n  <<\n    Year Of Birth=1965;Pets Names=;Picture=PEKBpYGlmYFCPA==;\n    City of Birth=Springfield;Name=John Doe;Kids Names=John;Kyra;;\n  >>\n\n"
let _ = Hashtbl.add items "xml" "module Xml = \n\n  let WS = [ \\n]*\n  let WSP = [ \\n]+ \n\n(* --------------------------------------------------------------------------- *)\n(* XML functions *)\n\n(* [unesc_char ex] maps an XML symbol -- either a character or an\n   escaped characeter -- to its equivalent representation in ASCII.\n   o [ex] is the set of excluded characters, and must be a cset\n\n  By default, newlines and quotes are excluded (they are dealt with\n  elsewhere).\n*)\n\nlet xml_escs = #{char * string}['>',\"&gt;\";\n\t\t\t\t'<',\"&lt;\";\n\t\t\t\t'&',\"&amp;\";\n\t\t\t\t'\"',\"&quot;\"]\n\nlet EXCL (C:regexp where is_cset C) : regexp = [^\\n] - C\n\nlet SAFE : regexp = ANY - (containing (Escaping.unescaped xml_escs))\n\nlet ESCAPED (C:regexp where is_cset C) : regexp\n  = Escaping.char_or_escaped (EXCL C) (Escaping.restrict C xml_escs)\n\nlet unesc_char (C:regexp where is_cset C) \n  : (lens in ESCAPED C <-> EXCL C)\n  = Escaping.unescape_char (EXCL C) (Escaping.restrict C xml_escs)\n\n(* [unesc_string_ends ex ends_ex] maps an XML-escaped string\n   beginning and ending with characters not in [ex] or [ends_ex], to\n   its equivalent representation in ASCII.\n   o [ex] the set of excluded characters.       \n   o [ends_ex] the set of excluded characters at the end points.\n*)\nlet unesc_string_ends\n    (C:regexp where is_cset C)\n    (C_ENDS:regexp where is_cset C_ENDS) \n  : (lens in (ESCAPED (C|C_ENDS) . ((ESCAPED C)* . ESCAPED (C|C_ENDS))?)\n\t <-> (EXCL (C|C_ENDS) . ((EXCL C)* . EXCL (C|C_ENDS))?))\n  = let middle = unesc_char C in\n    let ends = unesc_char (C | C_ENDS) in\n    ends . (middle* . ends)?\n\n(* [unesc_string ex] maps an XML-escaped string starting and\n   beginning with a non-space character, to its equivalent\n   representation in ASCII.\n   o [ex] the set of excluded characters.  \n*)\nlet unesc_string (C:regexp where is_cset C) \n  : (lens in (ESCAPED (C|' ') . ((ESCAPED C)* . ESCAPED (C|' '))?)\n\t <-> (EXCL (C|' ') . ((EXCL C)* . EXCL (C|' '))?))\n  = unesc_string_ends C [ ]\n\nlet OPEN (tag:regexp) : regexp = \"<\" . tag . \">\"\nlet OPEN_NOKIDS (tag:regexp) : regexp = \"<\" . tag . \"/>\"\n\n(* [open sp t] recognizes and deletes a string consisting of\n   whitespace and the start of an XML open tag.\n   o [sp] is used to canonize the leading whitespace.\n   o [t] is the tag.\n*)\nlet raw_open (spaces:string in WS) (tag:string) : (lens in (WS . \"<\" . tag) <=> \"\") = \n  qdel WS spaces . \n  del (\"<\" . tag) \n\nlet simple_open_tag (tag:string) : (lens in OPEN tag <=> \"\") = \n  del (OPEN tag)\n\n(* [close] recognizes and deletes the string \">\" *)\nlet close : (lens in \">\" <-> \"\") = \n  del \">\"\n\n(* [slash_close] recognizes and deletes strings consisting of\n   whitespace followed by \"/>\", which is used to terminate XML\n   elements whose children are all attributes.\n*)\n(* Why is this bijective?  It's bijective \"up to\" canonization... *)\nlet slash_close : (lens in (WS . \"/>\") <=> \"\") = \n  qdel (WS . \"/>\") \"/>\"\n\n(* [open_tag sp t] recognizes and deletes a string consisting of\n   whitespace followed by an XML open tag.\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n*)\nlet open_tag (spaces:string in WS) (tag:string) \n  : (lens in (WS . OPEN tag) <=> \"\") \n  = raw_open spaces tag . \n    close\n\nlet CLOSE (tag:regexp) : regexp = \"</\" . tag . \">\"\n\n(* [simple_close_tag t] recognizes and deletes a string consisting\n   of an XML close tag.\n   o [t] element tag.   \n*)\nlet simple_close_tag (tag:string) : (lens in CLOSE tag <=> \"\") = \n  del (CLOSE tag)\n\n(* [close_tag sp t] recognizes and deletes a string consisting of\n   whitespace followed by an XML close tag. \n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n*)\nlet close_tag (spaces:string in WS) (tag:string) \n  : (lens in (WS . CLOSE tag) <=> \"\") \n  = qdel WS spaces . \n    simple_close_tag tag\n\n(* [simple_elt sp t l] proecesses a single-line XML element.\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n   o [l] lens for processing the children.\n*)\nlet simple_elt (spaces:string in WS) (tag:string) (body:lens) \n  : (lens in (WS . OPEN tag . stype body . CLOSE tag) <-> vtype body)\n  = open_tag spaces tag . \n    body . \n    simple_close_tag tag\n\nlet simple_elt_twotags (spaces:string in WS) (tag:string) \n  : (lens in (WS . OPEN tag . CLOSE tag) <-> \"\")\n  = open_tag spaces tag . \n    simple_close_tag tag\n\nlet simple_elt_openclose (spaces:string in WS) (tag:string)\n  : (lens in (WS . \"<\" . tag . WS . \"/>\") <-> \"\")\n  = raw_open spaces tag . slash_close\n\nlet EMPTYELT (tag:regexp) : regexp =\n  (\"<\" . tag . WS . \"/>\" | OPEN tag . CLOSE tag)\n\n(* [simple_elt_no_kids sp t] proecesses a single-line XML element \n   with no children.\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n*)\nlet simple_elt_no_kids (spaces:string in WS) (tag:string)\n  : (lens in (WS . EMPTYELT tag) <-> \"\")\n  = qdel WS spaces . del (EMPTYELT tag)\n\ntest (simple_elt_no_kids \"\" \"foo\").get \"<foo/>\" = \"\"\ntest (simple_elt_no_kids \"\" \"foo\").create \"\" = \"<foo/>\"\ntest (simple_elt_no_kids \"\" \"foo\").put \"\" into \"<foo></foo>\" = \"<foo></foo>\"\n\nlet ELT (tag:regexp) (BODY:regexp) : regexp\n  = WS . OPEN tag . BODY . WS . CLOSE tag\n\n(* [elt sp t l] processes a multi-line XML element.\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n   o [l] lens for processing children.\n*)\nlet elt (spaces:string in WS) (tag:string) (body:lens) \n  : (lens in ELT tag (stype body) <-> vtype body)\n  = open_tag spaces tag . \n    body . \n    close_tag spaces tag\n\n(* [top t l] processes a top-level multi-line XML element.\n   o [t] element tag.\n   o [l] lens for processing children.\n\n  there is no spacing before the open tag, and there is a newline\n  before the close tag\n*)\nlet top (tag:string) (body:lens) \n  : (lens in ELT tag (stype body) <-> vtype body)\n  = open_tag \"\" tag .\n    body .\n    close_tag NL0 tag\n\nlet raw_simple_elt (tag:string) (body:lens) \n  : (lens in (OPEN tag . stype body . CLOSE tag) <-> vtype body)\n  = simple_open_tag tag . \n    body . \n    simple_close_tag tag \n  \n(* this is a little to relaxed, as it calls \"this' and 'this\" well\n   formed\n\n   but (\"'\" . E . \"'\") | ('\"' . E . '\"') won't work as a lens (since\n   the vtypes are the same).  it won't work to use ||, either, since\n   E's equivalence class may not be the identity relation\n*)\nlet QUOTED (E:regexp) : regexp =\n  [''\"\"] . E . [''\"\"]\n\nlet quoted (l:lens) : (lens in QUOTED (stype l) <-> vtype l)\n  = del [''\"\"] . l . del [''\"\"]\n\nlet ATTR (name:regexp) (VALUE:regexp) : regexp \n    = WSP . name . \"=\" . QUOTED VALUE\n\n(* [attr n l] proceses a string consiting of whitespace and a\n   single XML attribute. Leading whitespace is canonized to a single\n   space.\n   o [n] attribute name.\n   o [l] lens for processing value.\n\n   N.B. we should allow single quotes, too\n*)\nlet attr (name:string) (value:lens) \n  : (lens in ATTR name (stype value) <-> vtype value)\n  = qdel WSP \" \" . \n    del name . \n    del \"=\" . \n    quoted value\n\n(*\nFrom W3C XML 1.1 Recommendation, 2nd Ed.\nhttp://www.w3.org/TR/2006/REC-xml11-20060816/#NT-prolog\n\nprolog       ::= XMLDecl  Misc* (doctypedecl  Misc* )?\n\nXMLDecl      ::= '<?xml' VersionInfo EncodingDecl? SDDecl? S? '?>'\nVersionInfo  ::= S 'version' Eq (\"'\" VersionNum \"'\" | '\"' VersionNum '\"')\nEq           ::= S? '=' S?\nVersionNum   ::= '1.1'\nEncodingDecl ::= S 'encoding' Eq ('\"' EncName '\"' | \"'\" EncName \"'\" )\nEncName      ::= [A-Za-z] ([A-Za-z0-9._] | '-')*\n\nMisc         ::= Comment | PI | S \n\nComment\t     ::= '<!--' ((Char - '-') | ('-' (Char - '-')))* '-->'\n\nPI           ::= '<?' PITarget (S (Char* - (Char* '?>' Char* )))? '?>'\nPITarget     ::= Name - (('X' | 'x') ('M' | 'm') ('L' | 'l'))\n\nS            ::= whitespace\n*)\n\nlet VERSION : regexp = \"1.\" . [01]\n\n(* this is really EncName, and not name...but this is a conservative\n   approximation *)\nlet NAME : regexp = [A-Za-z] . ([A-Za-z0-9._]|'-')*\n\nlet XMLDECL : regexp =\n  \"<?xml\" . (ATTR \"version\" VERSION)\n          . (ATTR \"encoding\" NAME)?\n          . (ATTR \"standalone\" (\"yes\"|\"no\"))?\n          . WS . \"?>\"\n\nlet COMMENT : regexp = \"<!--\" . (not_containing \"--\") . \"-->\"\nlet PI : regexp = \"<?\" . (NAME - ([Xx] . [Mm] . [Ll])) . WSP . \n\t                 (not_containing \"?>\") . \"?>\"\nlet MISC = COMMENT | PI | [ \\n\\t]\nlet MISC_NOWS = COMMENT | PI\nlet MISC_STAR = MISC* . MISC_NOWS\nlet follow_with_MISC (PRE:regexp) = (PRE | PRE . MISC_STAR)\n\nlet PUBIDCHAR : regexp  = [ \\n\\ta-zA-Z0-9'()+,./:=?;!*#@$_%] | '-'\nlet PUBID : regexp      = '\"' . PUBIDCHAR* . '\"' | \"'\" . (PUBIDCHAR - \"'\") . \"'\"\nlet SYSTEMID : regexp   = '\"' . [^\"\"]* . '\"' | \"'\" . [^'']* . \"'\"\nlet EXTERNALID : regexp = (\"SYSTEM\" . WSP . SYSTEMID) | (\"PUBLIC\" . WSP . PUBID . WSP . SYSTEMID)\n\n(* FIXME unsupported!  you can put a subset of a DTD in your\n   doctype...these can get long. *)\nlet INTERNAL : regexp = EPSILON\n\nlet DOCTYPE_full \n    (name : regexp where subset name NAME) \n    (id : regexp where subset id EXTERNALID)\n    (internal : regexp)\n    : regexp\n    = \"<!DOCTYPE\" . WSP . name . (WSP . id)? . WS . (internal . WS)? . '>'\n\nlet DOCTYPE\n    (name : regexp where subset name NAME) \n    (id : regexp where subset id EXTERNALID)\n    : regexp\n    = DOCTYPE_full name id INTERNAL\n\nlet ANYDOCTYPE : regexp =\n  DOCTYPE NAME EXTERNALID\n\nlet PROLOG (DT : regexp where subset DT ANYDOCTYPE) : regexp\n    = (follow_with_MISC XMLDECL) . \n      (follow_with_MISC ([ \\n\\t]* . DT))?\n\nlet prolog (DT : regexp where subset DT ANYDOCTYPE)\n  : (lens in PROLOG DT <-> \"\")\n  = const (PROLOG DT) \"\" \"<?xml version=\\\"1.0\\\" ?>\"\n\ntest (prolog ANYDOCTYPE).get \"<?xml version=\\\"1.0\\\" ?>\" = \"\"\ntest (prolog ANYDOCTYPE).create \"\" = \"<?xml version=\\\"1.0\\\" ?>\"\ntest (prolog ANYDOCTYPE).put \"\" into \"<?xml version=\\\"1.0\\\" standalone=\\\"yes\\\" ?>\"\n     = \"<?xml version=\\\"1.0\\\" standalone=\\\"yes\\\" ?>\"\n\nlet ATTR_OPEN (tag:string) (AS:regexp) : regexp =\n  OPEN (tag . AS)\n\nlet ATTR_ELT (tag:string) (AS:regexp) (BODY:regexp) : regexp =\n  WS . ATTR_OPEN tag AS . BODY . WS . CLOSE tag\n\n(* [attr1_elt sp t n v l] processes a multi-line XML element with\n   one attribute.\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n   o [n] attribute name.\n   o [v] lens for processing attribute value.\n   o [l] lens for processing element children.\n*)\nlet attr1_elt (spaces:string in WS) (tag:string) \n    (name:string) (value:lens) \n    (body:lens where splittable_cex (vtype value) (vtype body)) \n  : (lens in ATTR_ELT tag (ATTR name (stype value)) (stype body)\n\t <-> (vtype value . vtype body))\n  = raw_open spaces tag . \n    attr name value . \n    close . \n    body . \n    close_tag spaces tag \n\nlet attr1_elt_swap (spaces:string in WS) (tag:string) \n    (name:string) (value:lens) \n    (body:lens where splittable_cex (vtype body) (vtype value)) \n  : (lens in ATTR_ELT tag (ATTR name (stype value)) (stype body)\n\t <-> (vtype body . vtype value))\n  = raw_open spaces tag . \n    ( (attr name value) ~\n      ( close . body ) ) . \n    close_tag spaces tag \n    \n(* [attr1_simple_elt sp t n v l] processes a single-line XML element with\n   one attribute.\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n   o [n] attribute name.\n   o [v] lens for processing attribute value.\n   o [l] lens for processing element children.\n*)\nlet attr1_simple_elt (spaces:string in WS) (tag:string) \n    (name:string) (value:lens) \n    (body:lens where splittable_cex (vtype value) (vtype body))\n  : (lens in (WS . ATTR_OPEN tag (ATTR name (stype value)) . (stype body) . CLOSE tag)\n\t <-> (vtype value . vtype body))\n  = raw_open spaces tag . \n    attr name value . \n    close . \n    body . \n    simple_close_tag tag \n\nlet attr1_raw_simple_elt_open (tag:string)\n    (name:string) (value:lens)\n  : (lens in ATTR_OPEN tag (ATTR name (stype value))\n\t <-> vtype value)\n  = del (\"<\" . tag) . \n    attr name value . \n    close\n\nlet attr1_raw_simple_elt (tag:string)\n    (name:string) (value:lens)\n    (body:lens where splittable_cex (vtype value) (vtype body)) \n  : (lens in (ATTR_OPEN tag (ATTR name (stype value)) . (stype body) . CLOSE tag)\n\t <-> (vtype value . vtype body))\n  = attr1_raw_simple_elt_open tag name value . \n    body . \n    simple_close_tag tag \n\nlet ATTRS (spec:(string*regexp) List.t) : regexp List.t = \n  List.map{string*regexp}{regexp} \n    (fun (p:string*regexp) ->\n       let name,VALUE = p in\n\t ATTR name VALUE)\n    spec\n\nlet ALL_ATTRS (spec:(string*regexp) List.t) : regexp =\n  union_regexps (Sort.perm_regexps (ATTRS spec))\n\nlet ANY_ATTRS (spec:(string*regexp) List.t) : regexp =\n  (union_regexps (ATTRS spec))*  \n\nlet ALL_ATTR_ELT (tag:string) (spec:(string*regexp) List.t) (BODY:regexp) : regexp\n    = ATTR_ELT tag (ALL_ATTRS spec) BODY\n\nlet ANY_ATTR_ELT (tag:string) (spec:(string*regexp) List.t) (BODY:regexp) : regexp\n    = ATTR_ELT tag (ANY_ATTRS spec) BODY\n\n(* [attr2_elt sp t n1 v1 n2 v2 l] processes a multi-line XML\n   element with two attributes.\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n   o [ni] ith attribute name.\n   o [vi] lens for processing ith attribute value.\n   o [l] lens for processing element children.\n*)\nlet attr2_elt (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens where splittable_cex (vtype value1) (vtype value2)) \n    (body:lens where splittable_cex (vtype value1 . vtype value2) (vtype body)) \n  : (lens in ANY_ATTR_ELT tag #{string*regexp}[name1,stype value1;\n\t\t\t\t\t       name2,stype value2]\n  \t                  (stype body)\n         <-> (vtype value1 . vtype value2 . vtype body))\n  = raw_open spaces tag . \n    Sort.sort_concat #{lens}[attr name1 value1; attr name2 value2] . \n    close . \n    body . \n    close_tag spaces tag \n\nlet slow_attr2_elt (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens where splittable_cex (vtype value1) (vtype value2)) \n    (body:lens where splittable_cex (vtype value1 . vtype value2) (vtype body)) \n  : (lens in ALL_ATTR_ELT tag #{string*regexp}[name1,stype value1; \n\t\t\t\t\t       name2,stype value2]\n\t                  (stype body)\n         <-> (vtype value1 . vtype value2 . vtype body))\n  = raw_open spaces tag . \n    Sort.perm_sort_concat #{lens}[attr name1 value1; attr name2 value2] . \n    close . \n    body . \n    close_tag spaces tag \n\nlet attr2_raw_simple_elt_no_kids (tag:string)\n    (name1:string) (value1:lens)\n    (name2:string) (value2:lens where splittable_cex (vtype value1) (vtype value2)) \n  : (lens in OPEN_NOKIDS (tag . ANY_ATTRS #{string*regexp}[name1,stype value1; name2,stype value2] . WS)\n\t <-> (vtype value1 . vtype value2))\n  = del (\"<\" . tag) . \n    Sort.sort_concat #{lens}[attr name1 value1; attr name2 value2] . \n    slash_close \n\ntest (attr2_raw_simple_elt_no_kids \"foo\" \"a1\" \"5\" \"a2\" \"6\").get \"<foo a1='5' a2='6' />\" = \"56\"\ntest (attr2_raw_simple_elt_no_kids \"foo\" \"a1\" \"5\" \"a2\" \"6\").get \"<foo a1='5'   />\" = error\n\nlet ATTR_NOKIDS (tag:string) (AS:regexp) = WS . OPEN_NOKIDS (tag . AS . WS)\n\n\n(* [attrk_elt_no_kids sp t n1 v1 .. nk vk] processes a single-line XML element with\n   no children (other than its attributes.)\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n   o [ni] ith attribute name.\n   o [vi] lens for processing ith attribute value.\n*)\nlet attrs_elt_no_kids (spaces:string in WS) (tag:string) (attrs:lens) \n  : (lens in ATTR_NOKIDS tag (stype attrs) <-> vtype attrs)\n  = raw_open spaces tag . \n    attrs . \n    slash_close\n\nlet attr1_elt_no_kids (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n  : (lens in ATTR_NOKIDS tag (ATTR name1 (stype value1)) <-> vtype value1)\n  = attrs_elt_no_kids spaces tag (attr name1 value1)\n    \nlet attr2_elt_no_kids (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n  : (lens in ATTR_NOKIDS tag (ANY_ATTRS #{string*regexp}[name1,stype value1; \n\t\t\t\t\t\t\t name2,stype value2])\n         <-> (vtype value1 . vtype value2))\n  = attrs_elt_no_kids spaces tag \n      (Sort.sort_concat #{lens}[attr name1 value1; attr name2 value2])\n\ntest (attr2_elt_no_kids \"\" \"foo\" \"a1\" \"5\" \"a2\" \"6\").get \"<foo a1='5' a2='6' />\" = \"56\"\ntest (attr2_elt_no_kids \"\" \"foo\" \"a1\" \"5\" \"a2\" \"6\").get \"<foo a1='5'   />\" = error\n\nlet slow_attr2_elt_no_kids (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens)\n  : (lens in ATTR_NOKIDS tag (ALL_ATTRS #{string*regexp}[name1,stype value1; \n\t\t\t\t\t\t\t name2,stype value2])\n         <-> (vtype value1 . vtype value2))\n  = attrs_elt_no_kids spaces tag \n    (Sort.perm_sort_concat\n       #{lens}[(attr name1 value1);\n\t       (attr name2 value2)])\n\nlet attr3_elt_no_kids (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens)\n  : (lens in ATTR_NOKIDS tag (ANY_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\t name2,stype value2;\n\t\t\t\t\t\t\t name3,stype value3])\n         <-> (vtype value1 . vtype value2 . vtype value3))\n  = attrs_elt_no_kids spaces tag \n    (Sort.sort_concat #{lens}[(attr name1 value1);\n\t\t\t      (attr name2 value2);\n\t\t\t      (attr name3 value3)])\n\nlet slow_attr3_elt_no_kids (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens)\n  : (lens in ATTR_NOKIDS tag (ALL_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\tname2,stype value2;\n\t\t\t\t\t\t\tname3,stype value3])\n         <-> (vtype value1 . vtype value2 . vtype value3))\n  = attrs_elt_no_kids spaces tag \n    (Sort.perm_sort_concat\n       #{lens}[(attr name1 value1);\n\t       (attr name2 value2);\n\t       (attr name3 value3)])\n\nlet attr4_elt_no_kids (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens)\n    (name4:string) (value4:lens)\n  : (lens in ATTR_NOKIDS tag (ANY_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\t name2,stype value2;\n\t\t\t\t\t\t\t name3,stype value3;\n\t\t\t\t\t\t\t name4,stype value4])\n         <-> (vtype value1 . vtype value2 . vtype value3 . vtype value4))\n  = attrs_elt_no_kids spaces tag \n    (Sort.sort_concat #{lens}[(attr name1 value1);\n\t\t\t      (attr name2 value2);  \n\t\t\t      (attr name3 value3);\n\t\t\t      (attr name4 value4)])\n\nlet slow_attr4_elt_no_kids (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens)\n    (name4:string) (value4:lens)\n  : (lens in ATTR_NOKIDS tag (ALL_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\t name2,stype value2;\n\t\t\t\t\t\t\t name3,stype value3;\n\t\t\t\t\t\t\t name4,stype value4])\n         <-> (vtype value1 . vtype value2 . vtype value3 . vtype value4))\n  = attrs_elt_no_kids spaces tag \n    (Sort.perm_sort_concat\n       #{lens}[(attr name1 value1);\n\t       (attr name2 value2);\n\t       (attr name3 value3);\n\t       (attr name4 value4)])\n\nlet ATTR_EOPEN (tag:string) (AS:regexp) : regexp =\n  WS . ATTR_OPEN tag AS\n\n(* [attrk_open sp t n1 v1 .. nk vk] opens a single-line XML element with k attributes.\n   o [sp] canonical leading whitespace.\n   o [t] element tag.\n   o [ni] ith attribute name.\n   o [vi] lens for processing ith attribute value.\n*)\nlet attrs_open (spaces:string in WS) (tag:string) (attrs:lens) \n  : (lens in ATTR_EOPEN tag (stype attrs) <-> vtype attrs)\n  = raw_open spaces tag . \n    attrs . \n    close  \n\nlet attr1_elt_open (spaces:string in WS) (tag:string)\n    (name1:string) (value1:lens) \n  : (lens in ATTR_EOPEN tag (ATTR name1 (stype value1))\n\t <-> vtype value1)\n  = \n  attrs_open spaces tag \n    (attr name1 value1)\n\nlet attr2_elt_open (spaces:string in WS) (tag:string)\n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n  : (lens in ATTR_EOPEN tag (ANY_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\tname2,stype value2])\n         <-> (vtype value1 . vtype value2))\n  = attrs_open spaces tag \n      (Sort.sort_concat #{lens}[(attr name1 value1);\n\t  \t\t\t(attr name2 value2)])\n\nlet slow_attr2_elt_open (spaces:string in WS) (tag:string)\n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens)\n  : (lens in ATTR_EOPEN tag (ALL_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\tname2,stype value2])\n         <-> (vtype value1 . vtype value2))\n  = attrs_open spaces tag \n      (Sort.perm_sort_concat\n\t #{lens}[(attr name1 value1);\n\t\t (attr name2 value2)])\n\nlet attr3_elt_open (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens)\n  : (lens in ATTR_EOPEN tag (ANY_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\tname2,stype value2;\n\t\t\t\t\t\t\tname3,stype value3])\n         <-> (vtype value1 . vtype value2 . vtype value3))\n  = attrs_open spaces tag \n      (Sort.sort_concat\n\t #{lens}[(attr name1 value1);\n\t\t (attr name2 value2);\n\t\t (attr name3 value3)])\n\nlet slow_attr3_elt_open (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens)\n  : (lens in ATTR_EOPEN tag (ALL_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\tname2,stype value2;\n\t\t\t\t\t\t\tname3,stype value3])\n         <-> (vtype value1 . vtype value2 . vtype value3))\n  = attrs_open spaces tag \n      (Sort.perm_sort_concat\n\t #{lens}[(attr name1 value1);\n\t\t (attr name2 value2);\n\t\t (attr name3 value3)])\n\nlet attr4_elt_open (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens) \n    (name4:string) (value4:lens)\n  : (lens in ATTR_EOPEN tag (ANY_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t\tname2,stype value2;\n\t\t\t\t\t\t\tname3,stype value3;\n\t\t\t\t\t\t\tname4,stype value4])\n         <-> (vtype value1 . vtype value2 . vtype value3 . vtype value4))\n  = attrs_open spaces tag \n      (Sort.sort_concat\n\t #{lens}[(attr name1 value1);\n\t\t (attr name2 value2);\n\t\t (attr name3 value3);\n\t\t (attr name4 value4)])\n\nlet slow_attr4_elt_open (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens) \n    (name4:string) (value4:lens)\n  : (lens in ATTR_EOPEN tag (ALL_ATTRS #{string*regexp}[name1,stype value1;\n\t\t\t\t\t\t       name2,stype value2;\n\t\t\t\t\t\t       name3,stype value3;\n\t\t\t\t\t\t       name4,stype value4])\n         <-> (vtype value1 . vtype value2 . vtype value3 . vtype value4))\n  = attrs_open spaces tag \n      (Sort.perm_sort_concat\n       #{lens}[(attr name1 value1);\n               (attr name2 value2);\n               (attr name3 value3);\n               (attr name4 value4)])\n\n(* attrN_elt_swap2 *)\nlet attr2_elt_swap2 (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (body:lens where splittable_cex (vtype value1) (vtype body)\n                  && splittable_cex (vtype body) (vtype value2))\n  : (lens in ANY_ATTR_ELT tag #{string*regexp}[name1,stype value1;\n\t\t\t\t\t       name2,stype value2]\n\t                  (stype body)\n         <-> (vtype value1 . vtype body . vtype value2))\n  = (attr2_elt_open spaces tag \n       name1 value1 \n       name2 value2 .\n       body . \n       close_tag spaces tag); \n    ( copy (vtype value1) . ( copy (vtype value2) ~ copy (vtype body) ) )\n\nlet slow_attr2_elt_swap2 (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (body:lens where splittable_cex (vtype value1) (vtype body)\n                  && splittable_cex (vtype body) (vtype value2))\n  : (lens in ALL_ATTR_ELT tag #{string*regexp}[name1,stype value1;\n\t\t\t\t\t       name2,stype value2]\n                          (stype body)\n         <-> (vtype value1 . vtype body . vtype value2))\n  = (slow_attr2_elt_open spaces tag \n       name1 value1 \n       name2 value2 .\n       body . \n       close_tag spaces tag); \n    ( copy (vtype value1) . \n\t( copy (vtype value2) ~ copy (vtype body) ) )\n\nlet attr3_elt_swap2 (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens) \n    (body:lens where splittable_cex (vtype value1) (vtype body)\n                  && splittable_cex (vtype body) (vtype value2 . vtype value3))\n  : (lens in ANY_ATTR_ELT tag #{string*regexp}[name1,stype value1;\n\t\t\t\t\t       name2,stype value2;\n\t\t\t\t\t       name3,stype value3]\n                          (stype body)\n         <-> (vtype value1 . vtype body . vtype value2 . vtype value3))\n  = (attr3_elt_open spaces tag \n       name1 value1 \n       name2 value2 \n       name3 value3 . \n     body . \n     close_tag spaces tag); \n    ( copy (vtype value1) . \n      ( copy (vtype value2 . vtype value3) ~ copy (vtype body) ) )\n\nlet slow_attr3_elt_swap2 (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens) \n    (body:lens where splittable_cex (vtype value1) (vtype body)\n                  && splittable_cex (vtype body) (vtype value2 . vtype value3))\n  : (lens in ALL_ATTR_ELT tag #{string*regexp}[name1,stype value1;\n\t\t\t\t\t       name2,stype value2;\n\t\t\t\t\t       name3,stype value3]\n\t\t          (stype body)\n         <-> (vtype value1 . vtype body . vtype value2 . vtype value3))\n  = (slow_attr3_elt_open spaces tag \n       name1 value1 \n       name2 value2 \n       name3 value3 . \n     body . \n     close_tag spaces tag); \n    ( copy (vtype value1) . \n      ( copy (vtype value2 . vtype value3) ~ copy (vtype body) ) )\n\nlet attr4_elt_swap2 (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens) \n    (name4:string) (value4:lens) \n    (body:lens where splittable_cex (vtype value1) (vtype body)\n                  && splittable_cex (vtype body) (vtype value2 . vtype value3 . vtype value4))\n  : (lens in ANY_ATTR_ELT tag #{string*regexp}[name1,stype value1;\n\t\t\t\t\t       name2,stype value2;\n\t\t\t\t\t       name3,stype value3;\n\t\t\t\t\t       name4,stype value4]\n\t\t          (stype body)\n         <-> (vtype value1 . vtype body . vtype value2 . vtype value3 . vtype value4))\n  = (attr4_elt_open spaces tag \n       name1 value1 \n       name2 value2 \n       name3 value3\n       name4 value4 . \n     body . \n     close_tag spaces tag); \n    ( copy (vtype value1) . \n      ( copy (vtype value2 . vtype value3 . vtype value4) ~ copy (vtype body) ) )\n\nlet slow_attr4_elt_swap2 (spaces:string in WS) (tag:string) \n    (name1:string) (value1:lens) \n    (name2:string) (value2:lens) \n    (name3:string) (value3:lens) \n    (name4:string) (value4:lens) \n    (body:lens where splittable_cex (vtype value1) (vtype body)\n                  && splittable_cex (vtype body) (vtype value2 . vtype value3 . vtype value4))\n  : (lens in ALL_ATTR_ELT tag #{string*regexp}[name1,stype value1;\n\t\t\t\t\t       name2,stype value2;\n\t\t\t\t\t       name3,stype value3;\n\t\t\t\t\t       name4,stype value4]\n                          (stype body)\n         <-> (vtype value1 . vtype body . vtype value2 . vtype value3 . vtype value4))\n  = (slow_attr4_elt_open spaces tag \n       name1 value1 \n       name2 value2 \n       name3 value3\n       name4 value4 . \n     body . \n     close_tag spaces tag); \n    ( copy (vtype value1) . \n      ( copy (vtype value2 . vtype value3 . vtype value4) ~ copy (vtype body) ) )\n\n"
let _ = Hashtbl.add items "mkXml" "module MkXml = \nlet attr (name:string) (value:lens) : lens = \n  qins WSP \" \" . \n  ins name . \n  ins \"=\\\"\" . \n  value . \n  ins \"\\\"\"\nlet elt (ws:string) (tag:string) (body:lens) : lens =\n  qins WS ws .\n  ins (\"<\" . tag . \">\") .\n  body .\n  qins WS ws .\n  ins (\"</\" . tag . \">\")\nlet simple_elt (ws:string) (tag:string) (body:lens) : lens =\n  qins WS ws .\n  ins (\"<\" . tag . \">\") .\n  body .\n  ins (\"</\" . tag . \">\")\nlet attr1_elt (ws:string) (tag:string) (name:string) (value:lens) (body:lens) : lens =\n  qins WS ws .\n  ins (\"<\" . tag)  . qins \" \"* \" \" . \n  ins (name . \"=\\\"\") . \n  value .   \n  ins \"\\\">\" . \n  body . \n  qins WS ws . \n  ins (\"</\" . tag . \">\")\nlet simple_attr2 (ws:string) (tag:string) (name1:string) (value1:lens) (name2:string) (value2:lens) : lens = \n  let ls = #{lens}[(attr name1 value1);(attr name2 value2)] in\n  qins WS ws . \n  ins (\"<\" . tag) . \n  right_quot (concat_lenses ls) (canonizer_of_lens (Sort.perm_sort (vtypes ls))) . \n  ins \"/>\" \nlet outer_elt (ws:string) (tag:string) (body:lens) : lens =\n  ins (\"<\" . tag . \">\") .\n  body .\n  qins WS ws .\n  ins (\"</\" . tag . \">\") . \n  qins WS \"\"\n"
let _ = Hashtbl.add items "ISO8601" "module ISO8601 =\n\n  let PLUSMINUS = \"+\" | \"-\"\n\n  (* Per ISO 31-0 *)\n  let DECIMAL = \",\" | \".\" (* comma is preferred *)\n\n  (* 3.4.3 Characters used as designators *)\n\n  let P = \"P\" (* duration/period *)\n  let R = \"R\" (* recurring interval *)\n  let T = \"T\" (* local time/time/time duration *)\n  let W = \"W\" (* week *)\n  let Z = \"Z\" (* UTC *)\n\n  (************)\n  (* 4.1 Date *)\n  (************)\n\n  module Date =\n\n  let Y = [0-9]\n  let MM = ('0' . [1-9]) | \"10\" | \"11\" | \"12\"\n  let DD = ('0' . [1-9]) | ([12] . [0-9]) | \"30\" | \"31\"\n\n  let SEP = \"-\"\n\n  (***********************)\n  (* 4.1.2 Calendar date *)\n  (***********************)\n\n  (* 4.1.2.2 Complete representations *)\n  let DATE (sep:regexp) = Y{4} . sep . MM . sep . DD\n  let BASIC = DATE \"\"\n  let EXTENDED = DATE SEP\n  let COMPLETE = DATE SEP?\n\n  test \"19850412\"   : (string in COMPLETE)\n  test \"1985-04-12\" : (string in COMPLETE)\n  test \"19850412\"   : (string in BASIC)\n  test \"1985-04-12\" : (string in EXTENDED)\n\n  (* 4.1.2.3 Representations with reduced accuracy\n\n     ...two, four or six digits may be omitted, the omission starting\n     from the extreme right-hand side. The resulting representation\n     will then indicate a month, a year or a century, as set out\n     below. When only [DD] is omitted, a separator shall be inserted\n     between [YYYY] and [MM], but separators shall not be used in the\n     other representations with reduced accuracy.\n\n  *)\n  let REDUCED = Y{2} . (Y{2} . (SEP . MM)?)?\n\n  test \"1984-04\" : (string in REDUCED)\n  test \"1984\"    : (string in REDUCED)\n  test \"19\"      : (string in REDUCED)\n\n  (* 4.1.2.4 Expanded representations *)\n\n  let EXPAND (YS : regexp where subset YS Y+) (FMT : regexp) =\n    PLUSMINUS . YS . FMT\n\n  let EXPANDED_COMPLETE (YS : regexp where subset YS Y+) = EXPAND YS COMPLETE\n\n  let EXPANDED_REDUCED (YS : regexp where subset YS Y+) = EXPAND YS REDUCED\n\n  let EXPANDED (YS : regexp where subset YS Y+) =\n    EXPANDED_COMPLETE YS | EXPANDED_REDUCED YS\n\n  test \"+0019850412\"   : (string in EXPANDED Y{2})\n  test \"+001985-04-12\" : (string in EXPANDED Y{2})\n  test \"+0019850412\"   : (string in EXPANDED_COMPLETE Y{2})\n  test \"+001985-04-12\" : (string in EXPANDED_COMPLETE Y{2})\n  test \"+001985-04\"    : (string in EXPANDED Y{2})\n  test \"+001985\"       : (string in EXPANDED Y{2})\n  test \"+0019\"         : (string in EXPANDED Y{2})\n  test \"+001985-04\"    : (string in EXPANDED_REDUCED Y{2})\n  test \"+001985\"       : (string in EXPANDED_REDUCED Y{2})\n  test \"+0019\"         : (string in EXPANDED_REDUCED Y{2})\n\n  (**********************)\n  (* 4.1.2 Ordinal date *)\n  (**********************)\n\n  (* Table 1: Calendar months and ordinal days\n\n     Calendar month Calendar month Number of days in Ordinal dates of the days in Ordinal dates of the\n         number          name          the month           common years           days in leap years\n           01           January            31                  001-031                 001-031\n           02          February            28 (29 leap year)   032-059                 032-060\n           03            March             31                  060-090                 061-091\n           04            April             30                  091-120                 092-121\n           05             May              31                  121-151                 122-152\n           06            June              30                  152-181                 153-182\n           07             July             31                  182-212                 183-213\n           08           August             31                  213-243                 214-244\n           09         September            30                  244-273                 245-274\n           10           October            31                  274-304                 275-305\n           11          November            30                  305-334                 306-335\n           12          December            31                  335-365                 336-366\n  *)\n\n  (* ordinal days *)\n  let DDD = [0-2] . [0-9]{2} | '3' . ([0-5] . [0-9] | '6' . [0-6])\n\n  test \"001\" : (string in DDD)\n  test \"365\" : (string in DDD)\n  test \"366\" : (string in DDD)\n\n  let ODATE (sep:regexp) =\n    Y{4} . sep . DDD\n  let OBASIC = ODATE \"\"\n  let OEXTENDED = ODATE SEP\n  let OCOMPLETE = ODATE SEP?\n\n  test \"1985102\"  : (string in OCOMPLETE)\n  test \"1985-102\" : (string in OCOMPLETE)\n  test \"1985102\"  : (string in OBASIC)\n  test \"1985-102\" : (string in OEXTENDED)\n\n  (* There is no reduced represenation for ordinal dates --- they'd be\n     same as the year-only reduced representations of calendar dates. *)\n\n  (* 4.1.3.3 Expanded representations *)\n\n  let OEXPANDED (YS : regexp where subset YS Y+) = EXPAND YS OCOMPLETE\n\n  test \"+001985102\"  : (string in OEXPANDED Y{2})\n  test \"+001985-102\" : (string in OEXPANDED Y{2})\n\n  (*******************)\n  (* 4.1.4 Week date *)\n  (*******************)\n\n  (* calendar week numbers *)\n  (* years have 52 or 53 weeks *)\n  let Www = W . ([0-4] . [0-9] | '5' . [0-3])\n\n  (* Table 2: Calendar days\n  \n     Ordinal day number in  Calendar day name\t  \n           the week\n               1                Monday\n               2                Tuesday\n               3                Wednesday\n               4                Thursday\n               5                Friday\n               6                Saturday\n               7                Sunday\n  \n     What a bunch of anti-Semites -- Sunday is the first day of the\n     week!\n  *)\n\n  (* ordinal day numbers *)\n  let D = [1-7]\n\n  (* 4.1.4.2 Complete representations *)\n\n  let WDATE (sep:regexp) =\n    Y{4} . sep . Www . sep . D\n  let WBASIC = WDATE \"\"\n  let WEXTENDED = WDATE SEP\n  let WCOMPLETE = WDATE SEP?\n\n  test \"1985W155\"   : (string in WCOMPLETE)\n  test \"1985-W15-5\" : (string in WCOMPLETE)\n  test \"1985W155\"   : (string in WBASIC)\n  test \"1985-W15-5\" : (string in WEXTENDED)\n\n  (* 4.1.4.3 Representations with reduced accuracy *)\n\n  let WREDUCED = Y{4} . SEP? . Www\n  test \"1985W15\"  : (string in WREDUCED)\n  test \"1985-W15\" : (string in WREDUCED)\n\n  (* 4.1.4.4 Expanded representations *)\n\n  let WEXPANDED_COMPLETE (YS : regexp where subset YS Y+) =\n    EXPAND YS WCOMPLETE\n\n  let WEXPANDED_REDUCED (YS : regexp where subset YS Y+) =\n    EXPAND YS WREDUCED\n\n  let WEXPANDED (YS : regexp where subset YS Y+) =\n    WEXPANDED_COMPLETE YS | WEXPANDED_REDUCED YS\n\n  test \"+001985W155\"   : (string in WEXPANDED Y{2})\n  test \"+001985-W15-5\" : (string in WEXPANDED Y{2})\n  test \"+001985W155\"   : (string in WEXPANDED_COMPLETE Y{2})\n  test \"+001985-W15-5\" : (string in WEXPANDED_COMPLETE Y{2})\n  test \"+001985W15\"    : (string in WEXPANDED Y{2})\n  test \"+001985-W15\"   : (string in WEXPANDED Y{2})\n  test \"+001985W15\"    : (string in WEXPANDED_REDUCED Y{2})\n  test \"+001985-W15\"   : (string in WEXPANDED_REDUCED Y{2})\n\n  end\n\n  (* complete, reduced, ordinal, week-complete, and week-reduced date\n     formats are all disjoint *)\n  test disjoint_regexps #{regexp}[Date.COMPLETE; Date.REDUCED; \n\t\t\t\t  Date.OCOMPLETE; (* no reduced form! *)\n\t\t\t\t  Date.WCOMPLETE; Date.WREDUCED] = true\n\n  let DATE = Date.COMPLETE | Date.REDUCED \n           | Date.OCOMPLETE \n\t   | Date.WCOMPLETE | Date.WREDUCED\n  let COMPLETE_DATE = Date.COMPLETE | Date.OCOMPLETE | Date.WCOMPLETE\n\n  (*******************)\n  (* 4.2 Time of day *)\n  (*******************)\n\n  module Time =\n\n  let hh = ([01] . [0-9]) | '2' . [0-4]\n  let mm = ([0-5] . [0-9])\n  let ss = ([0-5] . [0-9]) | \"60\" \n  (* 60 is used only for leap seconds and instants within *)\n\n  let SEP = \":\"\n\n  (* 4.2.2.2 Complete representations *)\n\n  let TIME (sep:regexp) = hh . sep . mm . sep . ss\n  let BASIC = TIME \"\"\n  let EXTENDED = TIME SEP\n  let COMPLETE = TIME SEP?\n\n  test \"232050\"   : (string in COMPLETE)\n  test \"23:20:50\" : (string in COMPLETE)\n  test \"232050\"   : (string in BASIC)\n  test \"23:20:50\" : (string in EXTENDED)\n\n  (* 4.2.2.3 Representations with reduced accuracy *)\n\n  let REDUCED = hh . (SEP? . mm)?\n\n  test \"2320\"  : (string in REDUCED)\n  test \"23:20\" : (string in REDUCED)\n  test \"23\"    : (string in REDUCED)\n\n  (* 4.2.2.4 Representations with decimal fraction *)\n\n  let DECIMAL_FRACTION = DECIMAL . [1-9] . [0-9]*\n\n  let FTIME (sep:regexp) = \n    hh . sep . mm . sep . ss . DECIMAL_FRACTION\n  let FBASIC = FTIME \"\"\n  let FEXTENDED = FTIME SEP\n  let FCOMPLETE = FTIME SEP?\n\n  let FREDUCED =\n    hh . (DECIMAL_FRACTION | (SEP? . mm . DECIMAL_FRACTION))\n\n  test \"232050,5\"   : (string in FCOMPLETE)\n  test \"23:20:50,5\" : (string in FCOMPLETE)\n  test \"2320,8\"     : (string in FREDUCED)\n  test \"23:20,8\"    : (string in FREDUCED)\n  test \"23,3\"       : (string in FREDUCED)\n  test \"232050,5\"   : (string in FBASIC)\n  test \"23:20:50,5\" : (string in FEXTENDED)\n\n  (* 4.2.2.5 Representations with time designator *)\n\n  (* the time designator [T] indicates local time *)\n  let DCOMPLETE = T . COMPLETE\n  let DREDUCED = T . REDUCED\n  let DFCOMPLETE = T . FCOMPLETE\n\n  (* 4.2.3 Midnight *)\n\n  let MIDNIGHT = \n    let sep = SEP? in\n    let zz = \"00\" in\n    (zz|\"24\") . (sep . zz . (sep . zz)?)?\n\n  (* the 24 form should only be used at the end of a time interval *)\n  let MIDNIGHT_CANONICAL : (R:regexp where subset R MIDNIGHT) = \"00:00\" | \"24:00\"\n\n  (* 4.2.4 UTC of day *)\n\n  let ZCOMPLETE = COMPLETE . Z\n  let ZREDUCED = REDUCED . Z\n  let ZFCOMPLETE = FCOMPLETE . Z\n\n  test \"232030Z\"   : (string in ZCOMPLETE)\n  test \"2320Z\"     : (string in ZREDUCED)\n  test \"23Z\"       : (string in ZREDUCED)\n  test \"23:20:30Z\" : (string in ZCOMPLETE)\n  test \"23:20Z\"    : (string in ZREDUCED)\n\n  (* 4.2.5 Local time and Coordinated Universal Time (UTC) *)\n\n  (* 4.2.5.1 Difference between local time and UTC of day *)\n  \n  (* not \"self-standing expressions\", used only in the following section... *)\n  let TZDIFF = PLUSMINUS . hh . (SEP? . mm)?\n  \n  test \"+0100\"  : (string in TZDIFF)\n  test \"+01\"    : (string in TZDIFF)\n  test \"+01:00\" : (string in TZDIFF)\n\n  (* 4.2.5.2 Local time and the difference from UTC *)\n\n  let TZCOMPLETE = COMPLETE . TZDIFF\n  let TZREDUCED = REDUCED . TZDIFF\n  let TZFCOMPLETE = FCOMPLETE . TZDIFF\n\n  test \"152746+0100\"    : (string in TZCOMPLETE)\n  test \"152746-0500\"    : (string in TZCOMPLETE)\n  test \"152746+01\"      : (string in TZCOMPLETE)\n  test \"152746-05\"      : (string in TZCOMPLETE)\n  test \"15:27:46+01:00\" : (string in TZCOMPLETE)\n  test \"15:27:46-05:00\" : (string in TZCOMPLETE)\n  test \"15:27:46+01\"    : (string in TZCOMPLETE)\n  test \"15:27:46-05\"    : (string in TZCOMPLETE)\n\n  (* zone designators per 4.3.2 *)\n  let ZD = \"\" | Z | TZDIFF\n\n  end\n\n  test disjoint_regexps #{regexp}[Time.COMPLETE; Time.REDUCED; \n\t\t\t\t  Time.FCOMPLETE; Time.FREDUCED] = true\n\n  let TIME = (Time.COMPLETE | Time.REDUCED | Time.FCOMPLETE | Time.FREDUCED) . Time.ZD \n  let COMPLETE_TIME = (Time.COMPLETE | Time.FCOMPLETE) . Time.ZD\n\n  (****************************)\n  (* 4.3 Date and time of day *)\n  (****************************)\n\n  module DateTime =\n\n  (* full dates, complete time *)\n  let CALENDAR_COMPLETE = Date.COMPLETE . T . COMPLETE_TIME\n  let ORDINAL_COMPLETE  = Date.OCOMPLETE . T . COMPLETE_TIME\n  let WEEK_COMPLETE     = Date.WCOMPLETE . T . COMPLETE_TIME\n  let DATETIME_COMPLETE = COMPLETE_DATE . T . COMPLETE_TIME\n\n  test \"19850412T101530\"      : (string in DATETIME_COMPLETE)\n  test \"19850412T101530Z\"     : (string in DATETIME_COMPLETE)\n  test \"19850412T101530+0400\" : (string in DATETIME_COMPLETE)\n  test \"19850412T101530+04\"   : (string in DATETIME_COMPLETE)\n  test \"19850412T101530\"      : (string in CALENDAR_COMPLETE)\n  test \"19850412T101530Z\"     : (string in CALENDAR_COMPLETE)\n  test \"19850412T101530+0400\" : (string in CALENDAR_COMPLETE)\n  test \"19850412T101530+04\"   : (string in CALENDAR_COMPLETE)\n\n  test \"1985-04-12T10:15:30\"      : (string in DATETIME_COMPLETE)\n  test \"1985-04-12T10:15:30Z\"     : (string in DATETIME_COMPLETE)\n  test \"1985-04-12T10:15:30+0400\" : (string in DATETIME_COMPLETE)\n  test \"1985-04-12T10:15:30+04\"   : (string in DATETIME_COMPLETE)\n  test \"1985-04-12T10:15:30\"      : (string in CALENDAR_COMPLETE)\n  test \"1985-04-12T10:15:30Z\"     : (string in CALENDAR_COMPLETE)\n  test \"1985-04-12T10:15:30+0400\" : (string in CALENDAR_COMPLETE)\n  test \"1985-04-12T10:15:30+04\"   : (string in CALENDAR_COMPLETE)\n\n  (* full dates, possibly reduced time *)\n  let CALENDAR = Date.COMPLETE . T . TIME\n  let ORDINAL  = Date.OCOMPLETE . T . TIME\n  let WEEK     = Date.WCOMPLETE . T . TIME\n  let DATETIME = COMPLETE_DATE . T . TIME\n\n  test \"19850412T1015\"       : (string in DATETIME)\n  test \"1985-04-12T10:15\"    : (string in DATETIME)\n  test \"19850412T1015\"       : (string in CALENDAR)\n  test \"1985-04-12T10:15\"    : (string in CALENDAR)\n  test \"1985102T1015Z\"       : (string in DATETIME)\n  test \"1985-102T10:15Z\"     : (string in DATETIME)\n  test \"1985102T1015Z\"       : (string in ORDINAL)\n  test \"1985-102T10:15Z\"     : (string in ORDINAL)\n  test \"1985155T1015+0400\"   : (string in DATETIME)\n  test \"1985-W15-5T10:15+04\" : (string in DATETIME)\n  test \"1985W155T1015+0400\"  : (string in WEEK)\n  test \"1985-W15-5T10:15+04\" : (string in WEEK)\n\n  end\n\n  let DATETIME = DateTime.DATETIME\n"
let _ = Hashtbl.add items "itunes" "module Itunes =\n\nopen Plist\n\nlet SAFE = ANY - (containing (\"<\" | \">\" | \";;;\" | \"===\")) - (ANY . Xml.WSP)\n\nlet track (spaces:string in Xml.WS) = \n  let spaces' = \"\\n\" . indent spaces in\n  let field (l:lens) = ins \"===\" . l . ins \";;;\\n\" in\n  let required (l:lens) (name:string) = false,name,field l in\n  let optional (l:lens) (name:string) = true,name,field l in\n  let pint  = pinteger spaces' INTEGER in\n  let pstr  = pstring spaces' SAFE in\n  let pdate = pdate spaces' ISO8601_DATE in\n  let pbool = pbool spaces' \"1\" \"0\" in\n  podictopt spaces\n    #{bool*regexp*lens}[\n      required pint  \"Track ID\";\n      required pstr  \"Name\";\n      optional pstr  \"Artist\";\n      optional pstr  \"Album Artist\";\n      optional pstr  \"Composer\";\n      optional pstr  \"Album\";\n      optional pstr  \"Grouping\";\n      optional pstr  \"Genre\";\n      required pstr  \"Kind\";\n      optional pint  \"Size\";\n      optional pint  \"Total Time\";\n      optional pint  \"Disc Number\";\n      optional pint  \"Disc Count\";\n      optional pint  \"Track Number\";\n      optional pint  \"Track Count\";\n      optional pint  \"Year\";\n      optional pint  \"BPM\";\n      optional pdate \"Date Modified\";\n      required pdate \"Date Added\";\n      optional pint  \"Bit Rate\";\n      optional pint  \"Sample Rate\";\n      optional pbool \"Part Of Gapless Album\";\n      optional pstr  \"Comments\";\n      optional pint  \"Play Count\";\n      optional pint  \"Play Date\";\n      optional pdate \"Play Date UTC\";\n      optional pint  \"Skip Count\";\n      optional pdate \"Skip Date\";\n      optional pdate \"Release Date\";\n      optional pint  \"Rating\";\n      optional pbool \"Rating Computed\";        (* ?? *)\n      optional pint  \"Album Rating\";\n      optional pbool \"Album Rating Computed\";  (* ?? *)\n      optional pbool \"Compilation\";\n      optional pint  \"Artwork Count\";\n      optional pstr  \"Series\";\n      optional pint  \"Season\";\n      optional pstr  \"Episode\";\n      optional pint  \"Episode Order\";\n      optional pstr  \"Sort Album\";        (* may not be in the EXACT right order... *)\n      optional pstr  \"Sort Album Artist\";\n      optional pstr  \"Sort Composer\";\n      optional pstr  \"Sort Artist\";\n      optional pstr  \"Sort Name\";\n      optional pstr  \"Sort Series\";\n      required pstr  \"Persistent ID\";\n      optional pbool \"Clean\";\n      optional pbool \"Disabled\";\n      required pstr  \"Track Type\";\n      optional pbool \"Protected\";\n      optional pbool \"Purchased\";\n      optional pbool \"Has Video\";\n      optional pbool \"HD\";\n      optional pint  \"Video Width\";\n      optional pint  \"Video Height\";\n      optional pbool \"Movie\";\n      optional pbool \"TV Show\";\n      optional pbool \"Podcast\";\n      optional pbool \"Unplayed\";\n      optional pint  \"File Type\";\n      required pstr  \"Location\"; (* this has per-OS structure... *)\n      optional pint  \"File Folder Count\";\n      optional pint  \"Library Folder Count\"\n    ]\n\nlet tracks (spaces:string in Xml.WS) = \n  phdict spaces \"tracks\" INTEGER (track (indent spaces))\n\nlet input =\n  <<\n  <dict>\n    <key>Track ID</key><integer>37</integer>\n    <key>Name</key><string>Thinking Of You</string>\n    <key>Artist</key><string>Lenny Kravitz</string>\n    <key>Composer</key><string>Lenny Kravitz/Lysa Trenier</string>\n    <key>Album</key><string>5</string>\n    <key>Genre</key><string>Pop/Funk</string>\n    <key>Kind</key><string>MPEG audio file</string>\n    <key>Size</key><integer>6141310</integer>\n    <key>Total Time</key><integer>383764</integer>\n    <key>Track Number</key><integer>32</integer>\n    <key>Year</key><integer>1998</integer>\n    <key>Date Modified</key><date>2005-06-08T20:04:06Z</date>\n    <key>Date Added</key><date>2004-05-06T04:29:57Z</date>\n    <key>Bit Rate</key><integer>128</integer>\n    <key>Sample Rate</key><integer>44100</integer>\n    <key>Comments</key><string>By ScazzI</string>\n    <key>Play Count</key><integer>6</integer>\n    <key>Play Date</key><integer>-1088231274</integer>\n    <key>Play Date UTC</key><date>2005-08-13T05:00:22Z</date>\n    <key>Persistent ID</key><string>FAKE</string>\n    <key>Track Type</key><string>File</string>\n    <key>Location</key><string>file://localhost/C:/\n    Documents%20and%20Settings/Test%20Name/My%20Documents/\n    My%20Music/Masheed/Lenny%20Kravitz%20-%20Thinking%20Of%20You.mp3/\n    </string>\n    <key>File Folder Count</key><integer>-1</integer>\n    <key>Library Folder Count</key><integer>-1</integer>\n  </dict>\n  >>\n\nlet output =\n  <<\n  Track ID===37;;;\n  Name===Thinking Of You;;;\n  Artist===Lenny Kravitz;;;\n  Composer===Lenny Kravitz/Lysa Trenier;;;\n  Album===5;;;\n  Genre===Pop/Funk;;;\n  Kind===MPEG audio file;;;\n  Size===6141310;;;\n  Total Time===383764;;;\n  Track Number===32;;;\n  Year===1998;;;\n  Date Modified===2005-06-08T20:04:06Z;;;\n  Date Added===2004-05-06T04:29:57Z;;;\n  Bit Rate===128;;;\n  Sample Rate===44100;;;\n  Comments===By ScazzI;;;\n  Play Count===6;;;\n  Play Date===-1088231274;;;\n  Play Date UTC===2005-08-13T05:00:22Z;;;\n  Persistent ID===FAKE;;;\n  Track Type===File;;;\n  Location===file://localhost/C:/\n    Documents%20and%20Settings/Test%20Name/My%20Documents/\n    My%20Music/Masheed/Lenny%20Kravitz%20-%20Thinking%20Of%20You.mp3/;;;\n  File Folder Count===-1;;;\n  Library Folder Count===-1;;;\n  \n  >>\n\ntest (track (indent \"\")).get input = output\n\nlet items (spaces:string in Xml.WS) =\n  parray spaces \"playlist_items\" \n    (podict (indent spaces)\n       #{regexp*lens}[\"Track ID\",ins \"===\" . pinteger \"\" INTEGER . ins \";;;\\n\"])\n\nlet playlist (spaces:string in Xml.WS) =\n  let spaces' = \"\\n\" . indent spaces in\n  let field (l:lens) = ins \"===\" . l . ins \";;;\\n\" in\n  let required (l:lens) (name:regexp) = false,name,field l in\n  let optional (l:lens) (name:regexp) = true,name,field l in\n  let pint  = pinteger spaces' INTEGER in\n  let pstr  = pstring spaces' SAFE in\n  let pdate = pdate spaces' ISO8601_DATE in\n  let pbool = pbool spaces' \"1\" \"0\" in\n  let pdata = pdata spaces' (padded BASE64) in\n  podictopt spaces\n    #{bool*regexp*lens}[\n      required pstr  \"Name\";\n      optional pbool \"Master\";\n      required pint  \"Playlist ID\";\n      required pstr  \"Playlist Persistent ID\";\n      optional pstr  \"Parent Persistent ID\";\n      optional pint  \"Distinguished Kind\";\n      optional pbool (\"Music\"|\n                      \"Movies\"|\n                      \"TV Shows\"|\n                      \"Podcasts\"|\n                      \"Audiobooks\"|\n                      \"Purchased Music\"|\n                      \"Party Shuffle\");      \n      optional pbool \"Visible\";\n      optional pbool \"All Items\";\n      optional pbool \"Folder\";\n      optional pdata \"Smart Info\";\n      optional pdata \"Smart Criteria\";\n      optional (items (indent spaces)) \"Playlist Items\"]\n\nlet input =\n  <<\n   <dict>\n     <key>Name</key><string>iTunes DJ</string>\n     <key>Playlist ID</key><integer>10630</integer>\n     <key>Playlist Persistent ID</key><string>2B9E87A28E9A7788</string>\n     <key>Distinguished Kind</key><integer>22</integer>\n     <key>Party Shuffle</key><true/>\n     <key>All Items</key><true/>\n     <key>Playlist Items</key>\n     <array>\n       <dict>\n         <key>Track ID</key><integer>1871</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>3203</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>3301</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>2075</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>1189</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>1425</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>1321</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>2713</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>1717</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>2603</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>1661</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>3001</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>3177</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>1943</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>2939</integer>\n       </dict>\n       <dict>\n         <key>Track ID</key><integer>2053</integer>\n       </dict>\n     </array>\n   </dict>\n  >>\n\nlet output =\n  <<\n   Name===iTunes DJ;;;\n   Playlist ID===10630;;;\n   Playlist Persistent ID===2B9E87A28E9A7788;;;\n   Distinguished Kind===22;;;\n   Party Shuffle===1;;;\n   All Items===1;;;\n   Playlist Items===Track ID===1871;;;\n   Track ID===3203;;;\n   Track ID===3301;;;\n   Track ID===2075;;;\n   Track ID===1189;;;\n   Track ID===1425;;;\n   Track ID===1321;;;\n   Track ID===2713;;;\n   Track ID===1717;;;\n   Track ID===2603;;;\n   Track ID===1661;;;\n   Track ID===3001;;;\n   Track ID===3177;;;\n   Track ID===1943;;;\n   Track ID===2939;;;\n   Track ID===2053;;;\n   ;;;\n\n  >>\n\ntest (playlist \"\\n\").get input = output\n\nlet playlists (spaces:string in Xml.WS) = \n  parray spaces \"playlists\" (playlist (indent spaces))\n\nlet iTML =\n  let spaces = indent (indent \"\\n\") in\n  let pint  = pinteger spaces INTEGER in\n  let pstr  = pstring spaces SAFE in\n  let pdate = pdate spaces ISO8601_DATE in\n  let pbool = pbool spaces \"1\" \"0\" in\n  let field (l:lens) (name:string) = name, ins \"===\" . l . ins \";;;\\n\" in\n  (plist (podict (indent \"\\n\")\n            #{regexp*lens}[\n              field pint  \"Major Version\";\n              field pint  \"Minor Version\";\n              field pstr  \"Application Version\";\n              field pint  \"Features\";\n              field pbool \"Show Content Ratings\";\n              field pstr  \"Music Folder\";\n              field pstr  \"Library Persistent ID\";\n              \"Tracks\", tracks (indent spaces);\n              \"Playlists\",playlists (indent spaces)])) . qdel Xml.WS \"\"\n\n(*\nlet lib = Sys.read \"iTML.xml\"\n\ntest matches_cex (stype iTML) lib = ?\n*)\n"
let _ = Hashtbl.add items "escaping" "module Escaping = \n\n(* FIRST TRY:\n\nlet unrender_quotedstr =\n    \"\\\"\" <-> \"\" \n  . copy ANY\n  . \"\\\"\" <-> \"\" \n\nlet unescape_quotedstr_char =\n    \"\\\\\\\"\" <-> \"\\\"\"\n  || \"\\\\\\\\\" <-> \"\\\\\"\n  || copy (ANYCHAR - [\\\\\"])\n\nlet unescape_quotedstr = unescape_quotedstr_char*\n\ntest get unescape_quotedstr\n    <<\n        <hello\\\"world>\n    >> \n  = \n    <<\n        <hello\"world>\n    >> \n\nlet tester = unrender_quotedstr ; unescape_quotedstr\n(* DOESN'T WORK!! *)\n*)\n\nlet unrender_quotedstr (R : regexp where (splittable_cex '\"' R) && (splittable_cex R '\"')) =\n    ('\"' <-> \"\") . \n    copy R . \n    ('\"' <-> \"\")\n\nlet unescape_quotedstr_char =\n     (\"\\\\\\\"\" <-> '\"')\n  || (\"\\\\\\\\\" <-> '\\')\n  || copy (ANYCHAR - '\\')\n\nlet unescape_quotedstr \n  : (lens in (('\\' . ('\"' | '\\')) | [^\\\\])* <-> ANY) \n  = unescape_quotedstr_char*\n\ntest get unescape_quotedstr\n    <<\n        <hello\\\"\\\"world>\n    >>\n  = \n    <<\n        <hello\"\"world>\n    >> \n\nlet test1 = unrender_quotedstr (stype unescape_quotedstr) ; unescape_quotedstr\n\n(* Does this transformation work in general? *)\n\n(* Making the example harder: Make the ASCII into a CSV... *)\n\nlet escape_xml_char = \n     ('<' <-> \"&lt;\")\n  || ('>' <-> \"&gt;\")\n  || ('&' <-> \"&amp;\")\n  || copy (ANYCHAR - [<>&])\n\nlet escape_xml \n  : (lens in ANY <-> (('&' . (\"lt\"|\"gt\"|\"amp\") . ';') | [^&<>])* )\n  = escape_xml_char*\n\nlet render_tag (R : regexp where splittable_cex \"<tag>\" R &&\n\t\t                 splittable_cex R \"</tag>\") \n  : (lens in R <-> (\"<tag>\" . R . \"</tag>\"))\n  = (\"\" <-> \"<tag>\") .\n    copy R .\n    (\"\" <-> \"</tag>\")\n\nlet test2 = escape_xml; render_tag (vtype escape_xml) \n\ntest get test2\n    <<\n        <hello\"\"world>\n    >> \n  = \n    <<\n        <tag>&lt;hello\"\"world&gt;</tag>\n    >> \n\n\n    \nlet l = test1 ; test2\n\ntest get l\n    <<\n        \" <hello\\\"\\\"world> \"\n    >> \n  = <<\n        <tag> &lt;hello\"\"world&gt; </tag>\n    >>\n\n(*************************************************)\n(* That works.  So let's make it more generic... *)\n\n(* regex -> str -> str -> lens\n   no possibility of failure, can give complete return type\n*)\nlet render (R : regexp)\n           (before : string where splittable_cex before R) \n\t   (after : string where splittable_cex after R)\n  : (lens in R <-> (before . R . after))\n  = (\"\" <-> before) .\n    copy R .\n    (\"\" <-> after)\n\nlet render_xml (R : regexp where splittable_cex \"<tag>\" R &&\n                                 splittable_cex R \"</tag>\") \n  : (lens in R <-> (\"<tag>\" . R . \"</tag>\"))\n  = render R \"<tag>\" \"</tag>\"\n\n(* safe, since render is safe; can we pass the buck without \n   repeating the contract? \n\n   in essence, can we instrument render_tag but not install blame on its \n   arguments?\n*)\nlet tagged (R : regexp) (tag : string) : regexp = \n  '<' . tag . '>' . R . (\"</\" . tag) . '>'\n\nlet render_tag (R : regexp) (tag : string) \n  : (lens in R <-> tagged R tag)\n  = render R (\"<\" . tag . \">\") (\"</\" . tag . \">\")\n\ntest (render_tag ANY \"foo\").vtype = (\"<foo>\" . ANY . \"</foo>\")\n\n(* as above *)\nlet quoted (R : regexp) = '\"' . R . '\"'\n\nlet render_str (R : regexp) : (lens in R <-> quoted R) = render R '\"' '\"'\n\n(* is bijectivity guaranteed?  yes, but we need buck-passing *)\nlet unrender_str (R : regexp) : (lens in quoted R <-> R) = invert (render_str R)\n\n(**************************************************************)\n(* escaping of strings, generically, with lists of escapes *)\n\n(* an escaping is a list of (char * string)\n\n   the character is what is escaped\n\n   the string is the suffix of the escape code (where some character\n   precedes all escape codes)\n*)\n\n(* string escaping; we take \\ to be the escape, so \" is escaped by \\\"\n   and \\ is escaped by \\\\ .  (\" to fix tuareg quote parsing) *)\n \nlet str_escs : (char * string) List.t =\n  #{char * string}[ ('\"',\"\\\\\\\"\") ; ('\\\\', \"\\\\\\\\\") ]\n\nlet xml_escs : (char * string) List.t =\n  #{char * string}[ ('>',\"&gt;\"); ('<',\"&lt;\"); ('&',\"&amp;\") ] \n\nlet escaped_chars (escs : (char * string) List.t)\n  = List.map{char * string}{char} fst{char}{string} escs\n\nlet escape_codes (escs : (char * string) List.t)\n  = List.map{char * string}{string} snd{char}{string} escs\n\nlet prefix (pfx : string) (escs : (char * string) List.t) : (char * string) List.t =\n  List.map{char * string}{char * string}\n    (fun (esc : char * string) ->\n       let from,to = esc in\n       (from,pfx . to))\n    escs\n\nlet restrict (ex:regexp) (escs : (char * string) List.t) : (char * string) List.t =\n  let escs = \n    List.fold_left{char * string}{(char * string) List.t}\n      (fun (escs : (char * string) List.t) (esc : (char * string)) ->\n\t match matches ex (fst{char}{string} esc) with\n\t   | true  -> escs\n\t   | false -> List.Cons{char * string}(esc,escs))\n      #{char * string}[] escs in\n  List.reverse{char * string} escs\n\ntest restrict [&.] xml_escs =   #{char * string}[('>',\"&gt;\");\n\t\t\t\t\t\t ('<',\"&lt;\")]\n\n(* this function already existed inside escape, but we had to \n   pull it out *)\nlet unescaped (escs : (char * string) List.t) : regexp =\n  union_regexps (escaped_chars escs)\n\ntest unescaped xml_escs = [<>&]\n\n(* this function didn't exist before, but we need it to \n   talk about the vtype of the lens produced by escape *)\nlet escaped (escs : (char * string) List.t) : regexp =\n  union_regexps (escape_codes escs)\n\ntest escaped xml_escs = ('&' . (\"gt\"|\"lt\"|\"amp\") . ';')\n\n(* it's an interesting exercise to start with \"naive\" ass-covering and lead up to\n   this relatively concise and understandable contract\n\n   1) escaped chars are arbitrary strings, contract is \"hell on wheels\"\n   2) change to single characters\n   3) observe that the iterability constraint on the domain is satisfied by construction\n   4) rewrite the codomain, making it nice and concise\n*)\n\n(* given a set of chars to be escaped and escape codes, valid escaped \"bits\" are:\n   (a) an escape code, or\n   (b) a character that didn't need to be escaped\n*)\nlet char_or_escaped (R:regexp) (escs : (char * string) List.t) : regexp =\n  escaped escs | (R - (unescaped escs))\n\nlet mutually_distinct (strs : string List.t) : bool =\n  let r,_ = \n    List.fold_left{string}{bool * (string List.t)}\n      (fun (acc : bool * (string List.t)) (s : string) ->\n\t let md_sofar,l_sofar = acc in\n\t   (md_sofar && not (List.member{string} s l_sofar),List.Cons{string} (s,l_sofar)))\n      (true,List.Nil{string})\n      strs in\n  r\n\nlet no_repeated_escape_codes (escs : (char * string) List.t) : bool =\n  mutually_distinct (escape_codes escs)\n\nlet escape_char \n  (R:regexp where is_cset R) \n  (escs : (char * string) List.t where\n            no_repeated_escape_codes escs &&\n            lens_iterable (char_or_escaped R escs))\n  : (lens in R <=> char_or_escaped R escs)\n  =\n  List.fold_left{string * string}{lens}\n    (fun (l : lens) (p : string * string) -> \n       let (from,to) = p in\n       (from <-> to) || l)\n    (copy (R - (unescaped escs)))\n    escs\n\nlet unescape_char\n  (R:regexp where is_cset R) \n  (escs : (char * string) List.t where\n            no_repeated_escape_codes escs &&\n            lens_iterable (char_or_escaped R escs))\n  : (lens in char_or_escaped R escs <=> R)\n  = invert (escape_char R escs)\n\nlet escape \n  (R:regexp where is_cset R) \n  (escs : (char * string) List.t where\n            no_repeated_escape_codes escs &&\n            lens_iterable (char_or_escaped R escs))\n  : (lens in R* <=> (char_or_escaped R escs)* )\n  = (escape_char R escs)*\n\nlet unescape \n  (R:regexp where is_cset R) \n  (escs : (char * string) List.t where\n            no_repeated_escape_codes escs &&\n            lens_iterable (char_or_escaped R escs))\n  : (lens in (char_or_escaped R escs)* <=> R* )\n  = (unescape_char R escs)*\n\n\n(* do we want lens, or can/should we somehow say \"specialize\"? *)\nlet escape_xml \n  : (lens in ANY <=> (('&' . (\"gt\"|\"lt\"|\"amp\") . ';') | [^<>&])* )\n  = escape ANYCHAR xml_escs\n\n(* ditto *)\nlet escape_str \n  : (lens in ANY <=> (('\\\\' . ('\"'|'\\\\')) | [^\"\"\\\\])* )\n  = escape ANYCHAR str_escs\n\n(* ditto *)\nlet unescape_str \n  : (lens in ((('\\' . ('\"'|'\\')) | [^\"\"\\\\])* ) <-> ANY)\n  = invert escape_str\n\nlet l1 = \n  unrender_str (stype unescape_str) ; unescape_str ; \n  escape_xml ; render_xml (vtype escape_xml)\n\ntest get l1\n    <<\n        \" <hello\\\"\\\"world> \"\n    >> \n  = <<\n        <tag> &lt;hello\"\"world&gt; </tag>\n    >>\n\n(**************************************************************)\n(* alternative version of escaping, with a single distinguished\n   character beginning all escape sequences *)\n\nlet str_esc_code = '\\\\'\nlet str_escs2 : (char * string) List.t =\n  #{char * string}[ ('\"','\"') ; ('\\\\', '\\\\') ]\n\nlet xml_esc_code = '&'\nlet xml_escs2 : (char * string) List.t =\n  #{char * string}[ ('>',\"gt;\"); ('<',\"lt;\"); ('&',\"amp;\") ] \n\nlet char_or_escaped_with\n    (esc : char) \n    (R:regexp where is_cset R) \n    (escs : (char * string) List.t) : regexp =\n  let escs = prefix esc escs in\n  (escaped escs) | (R - (unescaped escs))\n\nlet escape_with\n  (esc : char)\n  (R : regexp where is_cset R) \n  (pairs : (char * string) List.t\n    where List.exists{string * string} \n            (fun (p : string * string) -> (fst{string}{string} p) = esc)\n            pairs &&\n          no_repeated_escape_codes pairs &&\n          lens_iterable (char_or_escaped_with esc R pairs))\n  : (lens in R* <=> (char_or_escaped_with esc R pairs)* )\n  =\n  let escape_char =\n    List.fold_left{char * string}{lens}\n      (fun (l : lens) (p : char * string) -> \n\t let (from,to) = p in\n        (from <-> (esc . to)) || l)\n      (copy (R - unescaped pairs))\n      pairs in\n  escape_char*\n\nlet escape_with2\n  (esc : char)\n  (R : regexp where is_cset R)\n  (escs : (char * string) List.t\n    where List.exists{string * string} \n            (fun (p : string * string) -> (fst{string}{string} p) = esc)\n          escs &&\n          no_repeated_escape_codes escs &&\n          lens_iterable (char_or_escaped_with esc R escs))\n  : (lens in R* <=> (char_or_escaped_with esc R escs)* )\n  = escape R (prefix esc escs)\n\n(* do we want lens, or can/should we somehow say \"specialize\"? *)\nlet escape_xml \n  : (lens in ANY <=> (('&' . (\"gt\"|\"lt\"|\"amp\") . ';') | [^<>&])* )\n  = escape_with xml_esc_code ANYCHAR xml_escs2\n\n(* ditto *)\nlet escape_str \n  : (lens in ANY <=> (('\\\\' . ('\"'|'\\\\')) | [^\"\"\\\\])* )\n  = escape_with str_esc_code ANYCHAR str_escs2\n\n(* ditto *)\nlet unescape_str \n  : (lens in ((('\\' . ('\"'|'\\')) | [^\"\"\\\\])* ) <-> ANY)\n  = invert escape_str\n\nlet l2 = \n  unrender_str (stype unescape_str) ; unescape_str ; \n  escape_xml ; render_xml (vtype escape_xml)\n\ntest get l2\n    <<\n        \" <hello\\\"\\\"world> \"\n    >> \n  = <<\n        <tag> &lt;hello\"\"world&gt; </tag>\n    >>\n\n(**************************************************************)\n(* example: CSV <-> XML *)\nlet intersperse ('a) (ls : 'a List.t) (sep : 'a) : 'a List.t =\n  List.reverse{'a}\n      (List.fold_left{'a}{'a List.t}\n        (fun (acc:'a List.t) (vi:'a) -> \n           List.Cons{'a}\n             (match acc with \n               | List.Nil     -> (vi,acc)\n               | List.Cons(_) -> (vi,List.Cons{'a}(sep,acc))))\n        #{'a}[] ls)\n\nlet lens_concatable (ls : lens List.t) (sep : lens) : bool = \n  let ls' : lens List.t = intersperse{lens} ls sep in\n  (concatable (stypes ls')) && (concatable (vtypes ls'))\n \n(* to cover our asses, we need the concatable refinement\n   do we want the specific return type?\n*)\nlet intersperse_lenses \n      (lenses : lens List.t) \n      (sep : lens where lens_concatable lenses sep) \n  : (lens in (concat_regexps (stypes (intersperse{lens} lenses sep)))\n         <-> (concat_regexps (vtypes (intersperse{lens} lenses sep))))\n  = concat_lenses (intersperse{lens} lenses sep)\n\nlet field_to_xml (field : string) \n  : (lens in (quoted (('\\' . ('\"'|'\\')) | [^\"\"\\\\])* )\n         <-> (tagged (('&' . (\"lt\"|\"gt\"|\"amp\") . ';') | [^&<>])* ) field)\n  = unrender_str (stype unescape_str) ; unescape_str ;\n    escape_xml ; render_tag (vtype escape_xml) field\n\n(* as above -- do we want the strict return type?  do we want to pass the buck? *)\nlet csv_to_xml (fields : string List.t where lens_concatable fields (del \",\")) = \n  intersperse_lenses (List.map{string}{lens} field_to_xml fields) (del \",\")\n\nlet l3 = csv_to_xml #{string}[\"first\";\"last\"]\n\ntest get l3\n    <<\n        \"Michael \\\"The Autominator\\\"\",\"Greenberg, Jr. &c\"\n    >>\n  = <<\n        <first>Michael \"The Autominator\"</first><last>Greenberg, Jr. &amp;c</last>\n    >>\n"
let _ = Hashtbl.add items "string" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2009                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /lenses/string.boom                                                        *)\n(* string related functions                                                   *)\n(* $Id: exception.boom 4632 2009-08-20 16:16:52Z cretin $ *)\n(******************************************************************************)\n\nmodule String =\n\n#{@}\n\n\\subsection{Strings}\n\n\\LENSSECTION{@sub@} The @sub@ function behaves like the OCaml\nString.sub function.  It returns a string of length @len@, containing\nthe substring of @s@ that starts at position @start@ and has length\n@len@.\n\n#* let sub (start:int where bgeq start 0)\n#*         (len:int)\n#*         (s:string where (bleq (plus len start) (length s)))\n#*   : string\n## = Native.Prelude.string_sub s start len\n\n\\LENSSECTION{@index_from@} The @index_from@ and @rindex_from@\nfunctions behave like the OCaml @String.index_from@ and\n@String.rindex_from@ functions. It returns the character number of the\nfirst occurrence of character @c@ in string @s@ after position @i@. If\nthe character was not found, they return @None@.\n\n#* let index_from (s:string)\n#*                (i:int where land (bgeq i 0) (bgeq (length s) i))\n#*                (c:char)\n#*   : int option\n## = Native.Prelude.string_index_from s i c\n\n#* let index (s:string) (c:char) = index_from s 0 c\n\n#* let rindex_from (s:string)\n#*                 (i:int where land (bgeq (plus i 1) 0) (bgeq (length s) (plus i 1)))\n#*                 (c:char)\n#*   : int option\n## = Native.Prelude.string_rindex_from s i c\n\n#* let rindex (s:string) (c:char) = rindex_from s (length s - 1) c\n\n\\LENSSECTION{@star_split@} The @star_split@ function splits the string\n@s@ according to the iteration of the regular expression @r@. It\nreturns the list of the substrings.\n\n#* let star_split : (r:regexp ->\n#*                  (s:string where land (iterable_cex r)\n#*                                       (matches_cex (regexp_iter r 0 (minus 0 1)) s)) ->\n#*                  string List.t)\n## = Native.Prelude.star_split\n\n\\LENSSECTION{@bad_index@} The @bad_index@ function returns the index\nof the character in @s@ making it not match the regular expression\n@r@.\n\n#* let bad_index : regexp -> string -> int\n## = Native.Prelude.bad_prefix_position\n\n\\LENSSECTION{@explode@} The @explode@ function explodes a string into\ncharacters, returning a list of strings.\n\n#* let explode (s:string) : (l:string List.t where List.length{string} l = length s)\n#* = star_split ANYCHAR s\n\n#* test explode \"\" = #{string}[]\n#* test explode \"lorem\" = #{string}[\"l\";\"o\";\"r\";\"e\";\"m\"]\n\n\\LENSSECTION{@implode@} The @implode@ function implodes a list of\nchar into a string.\n\n#* let implode (l:string List.t) : string\n#* = List.fold_left{string}{string} (fun (s:string) (s':string) -> s . s') \"\" l\n\n#* test implode #{string}[] = \"\"\n#* test implode #{string}[\"a\";\"b\";\"c\"] = \"abc\"\n#* test implode #{string}[\"abc\";\"def\";\"ghi\"] = \"abcdefghi\"\n#* test implode (explode \"testing\") = \"testing\"\n\n\\LENSSECTION{@file_ext@} The @file_ext@ returns the extension of a\nfilename. More precisely, it returns the substring after the last @.@\nin the string. If there is no @.@ in the string, it returns @None@.\n\n#* let file_ext (file:string) : string option =\n#*   let l = minus (length file) 1 in\n#*   match rindex_from file l '.' with\n#*     | Some n -> Some{string} (sub (plus n 1) (minus l n) file)\n#*     | None -> None{string}\n\n\\LENSSECTION{@length@} The @length@ function computes the length of a\nstring.\n\n#* let length : string -> int\n## = Native.Prelude.length\n\n#* let drop (n:int) (s:string where n leq (length s)) =\n#*   sub n (length s - n) s\n\n#* let rdrop (n:int) (s:string where n leq (length s)) =\n#*   sub 0 (length s - n) s\n\n#* let take (n:int) (s:string where n leq (length s)) =\n#*   sub 0 n s\n\n#* let rtake (n:int) (s:string where n leq (length s)) =\n#*   sub (length s - n) n s\n\n#* let end_with (s:string) (e:string) =\n#*   let ns = length s in\n#*   let ne = length e in\n#*   match ns geq ne with\n#*   | true -> (rtake ne s = e)\n#*   | false -> false\n#*   :bool\n\n#* let compare : string -> string -> int\n## = Native.Prelude.string_compare\n\n#* test List.sort{string} compare #{string}[\"c\";\"d\";\"a\";\"b\";\"e\"]\n#*                              = #{string}[\"a\";\"b\";\"c\";\"d\";\"e\"]\n"
let _ = Hashtbl.add items "apply_contract" "module Apply_contract =\n\n  let refine ('a) (p:'a -> bool) (v:'a) : (vc:'a where p vc) = \n    (* let the compiler insert the check! *)    \n    v \n    \n  let pos (n:int) = bgt n 0\n  \n  test refine{int} pos 1 = 1\n  test refine{int} pos 0 = error\n\n  let naive_refine ('a) (p:'a -> bool) (v:'a) : 'a =\n    let refined : (vc:'a where p vc) = v in (* cast into r *)\n    refined\n\n  test naive_refine{int} pos 1 = 1\n  test naive_refine{int} pos 0 = error\n\n  let pos (x:int) : bool = x gt 0\n  let f (x:int where pos x) : int = plus x 1\n  let pos (x:int) : bool = equals{int} x 0\n  test f 0 = error\n  \n"
let _ = Hashtbl.add items "bibtex" "#{*}\n(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2007 J. Nathan Foster and Benjamin C. Pierce                 *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /examples/bibtex.boom                                                      *)\n(* BiBTeX <-> RIS lens                                                        *)\n(* $Id$ *)\n(******************************************************************************)\n\nmodule Bibtex = \n\n(* ABBREVIATIONS *)\nlet mk_cn : lens -> canonizer = canonizer_of_lens \n\n(* GLOBALS *)\nlet CHAR : regexp = [a-zA-Z. ]\nlet ALPHA : regexp = [a-zA-Z.]\nlet NL : string = \"\\n\"\nlet EPSILON : string = \"\"\nlet tag (s:string) : string = s . \"  - \"\nlet special : regexp = [@{}\"\"]\nlet not_special : regexp = ANYCHAR - special\n\nlet ANY_TAG : regexp = [A-Z] . [A-Z0-9] . \"  - \"\n\nlet no_tags (r:regexp) : regexp = \n  r - (containing ANY_TAG)\n\nlet ty_tag : string = tag \"TY\"\nlet au_tag : string = tag \"AU\"\n\n(* AUTHORS *)\nlet author : lens = \n  let ANY_AND : regexp = containing (WS . \"and\" . WSP) in\n  let string_no_ws : lens = copy (ALPHA+) in\n  let string_ws : lens = copy ((ALPHA . CHAR* . ALPHA) - ANY_AND) in\n  ins au_tag .\n  ( (string_no_ws . copy \", \" . string_ws)\n  || ((string_ws . del \" \") ~ (string_no_ws . ins \", \")) )\n\n(* process a list of authors *)\nlet wsp_and : regexp = WSP . \"and\" . WSP\nlet authors : lens = author . ( default (wsp_and <-> \"\\n\") \" and \" . author)*\n\n(* unit tests *)\ntest author.get \"Pierce, Benjamin C.\" = \"AU  - Pierce, Benjamin C.\"\ntest author.get \"Foster, J. Nathan\" = \"AU  - Foster, J. Nathan\"\ntest author.get \"J. Nathan Foster\" = \"AU  - Foster, J. Nathan\"\ntest author.put \"AU  - Foster, J. Nathan\" into \"Foster, John\" = \"Foster, J. Nathan\"\ntest author.put \"AU  - Foster, J. Nathan\" into \"J. Nathan Foster\" = \"J. Nathan Foster\"\ntest authors.get\n  \"Aaron Bohannon and J. Nathan Foster and Benjamin C. Pierce\" =\n  \"AU  - Bohannon, Aaron\n  |AU  - Foster, J. Nathan\n  |AU  - Pierce, Benjamin C.\"\n\ntest authors.get\n  \"Bohannon, Aaron and Foster, J. Nathan and Pierce, Benjamin C.\" = \n  \"AU  - Bohannon, Aaron\n  |AU  - Foster, J. Nathan\n  |AU  - Pierce, Benjamin C.\"\n\ntest authors.get \n  \"Bohannon, Aaron and Foster, J. Nathan and Benjamin C. Pierce\" = \n  \"AU  - Bohannon, Aaron\n  |AU  - Foster, J. Nathan\n  |AU  - Pierce, Benjamin C.\"\n\ntest authors.create \n  \"AU  - Bohannon, Aaron\n  |AU  - Foster, J. Nathan\n  |AU  - Pierce, Benjamin C.\" = \n  \"Bohannon, Aaron and Foster, J. Nathan and Pierce, Benjamin C.\"\n\ntest authors.get\n    <<\n        J. Nathan Foster \n               and Benjamin C. Pierce \n               and Alan Schmitt\n    >> = \n    <<\n        AU  - Foster, J. Nathan\n        AU  - Pierce, Benjamin C.\n        AU  - Schmitt, Alan\n    >>\n\n(* HELPER FUNCTIONS *)\nlet upper : regexp = UALPHACHAR\nlet lower : regexp = not_special - upper\nlet lower_no_ws = lower - WSCHAR\n\nlet to_lower : (lens in not_special <-> lower) = \n  ( default ([aA] <-> \"a\") \"a\"\n  | default ([bB] <-> \"b\") \"b\" \n  | default ([cC] <-> \"c\") \"c\" \n  | default ([dD] <-> \"d\") \"d\" \n  | default ([eE] <-> \"e\") \"e\" \n  | default ([fF] <-> \"f\") \"f\" \n  | default ([gG] <-> \"g\") \"g\" \n  | default ([hH] <-> \"h\") \"h\" \n  | default ([iI] <-> \"i\") \"i\" \n  | default ([jJ] <-> \"j\") \"j\"    \n  | default ([kK] <-> \"k\") \"k\" \n  | default ([lL] <-> \"l\") \"l\" \n  | default ([mM] <-> \"m\") \"m\" \n  | default ([nN] <-> \"n\") \"n\" \n  | default ([oO] <-> \"o\") \"o\" \n  | default ([pP] <-> \"p\") \"p\" \n  | default ([qQ] <-> \"q\") \"q\" \n  | default ([rR] <-> \"r\") \"r\" \n  | default ([sS] <-> \"s\") \"s\" \n  | default ([tT] <-> \"t\") \"t\" \n  | default ([uU] <-> \"u\") \"u\" \n  | default ([vV] <-> \"v\") \"v\" \n  | default ([wW] <-> \"w\") \"w\" \n  | default ([xX] <-> \"x\") \"x\" \n  | default ([yY] <-> \"y\") \"y\" \n  | default ([zZ] <-> \"z\") \"z\" \n  | copy [^a-zA-Z@{}\"\"] ) \n\nlet braces : (lens in (\"{\" . not_special+ . \"}\") <-> ((\"{\" . [A-Z] . \"}\") | lower)+ ) = \n  del \"{\" . \n    (ins \"{\" . copy upper . ins \"}\" | \n     copy lower)+ . \n  del \"}\"\n\ntest braces.get \"{HeLlO}\" = \"{H}e{L}l{O}\"\ntest braces.create \"{F}oo\" = \"{Foo}\"\ntest braces.create \"ho{W}{D}{Y}\" = \"{hoWDY}\"\n\n(* how do we write precise types for canonizers? *)\nlet empty_cn : canonizer = mk_cn (copy \"\")\n\nlet first_cn : canonizer = mk_cn ((ins \"{\" . copy upper . ins \"}\" || braces) || copy lower )\n\ntest canonize first_cn \"H\" = \"{H}\"\ntest canonize first_cn \"f\" = \"f\"\ntest canonize first_cn \"{HeLlO}\" = \"{H}e{L}l{O}\"\n\n(* NOTE: must be lazy star / dot *)\nlet rest_cn  : canonizer = (mk_cn (to_lower || braces))*\nlet title_can : canonizer = empty_cn | (first_cn . rest_cn)\n\ntest choose title_can \"{L}{O}{O}{J}: {W}eaving {L}{O}{O}{M} into {J}ava\" = \n                      \"L{O}{O}{J}: {W}eaving {L}{O}{O}{M} into {J}ava\"\n\nlet canonize_title \n  : (lens in (not_special | (\"{\" . not_special+ . \"}\"))* <-> \n             (((\" \"? . (not_special - WSCHAR)) | \" \" . upper)* . \" \"?)) \n  = let l : lens = \n      ((copy lower_no_ws \n       | del \"{\" . copy upper . del \"}\"\n       | (WSP <-> \" \") . copy lower_no_ws\n       | (WSP <-> \" \") . del \"{\" . copy upper . del \"}\")* )\n\t. (copy \"\" | (WSP <-> \" \")) in \n    left_quot title_can l\n\ntest canonize_title.get \"LOOJ: {W}eaving {LOOM} into {Java}\" = \n\"Looj: Weaving LOOM into Java\"\n\ntest canonize_title.get \"Looj: {W}eaving {LOOM} into {Java}\" = \n\"Looj: Weaving LOOM into Java\"\n\ntest canonize_title.put \"LOOJ: Weaving LOOM into Java\" into \"{LOOJ}: {Weaving LOOM into Java}\" = \n\"L{O}{O}{J}: {W}eaving {L}{O}{O}{M} into {J}ava\"\n\ntest canonize_title.get \n  \"A {L}ogic {Y}our {T}ypechecker {C}an {C}ount {O}n: {U}nordered {T}ree {T}ypes in {P}ractice\" =\n  \"A Logic Your Typechecker Can Count On: Unordered Tree Types in Practice\"\n\n(* VALUES *)\nlet esc (s:string) = regexp_of_string (\"\\\\\" . s)\nlet bare_value = [A-Za-z0-9]+\nlet braced_value = no_tags ([^@{}\\\\] | esc \"{\" | esc \"}\")*\nlet quoted_value = no_tags ([^@\"\"\\\\] | esc \"\\\"\")*\n\n(* FIELDS *)\nlet start_field (lb:string) : regexp = WS . \"=\" . WS . lb\nlet end_field (rb:string) : regexp = rb . [ ]* . \",\" . [ ]* . \"\\n\"\n\nlet mk_template \n  (lb:string) \n  (l:lens where lens_splittable (del (start_field lb)) l)\n  (rb:string where lens_splittable (del (start_field lb) . l) (del (end_field rb))) \n  : (lens  in ((start_field lb) . (stype l) . (end_field rb)) <-> (vtype l))\n  = del (start_field lb) . l . del (end_field rb)\n\n(* I lifted this out to avoid re-calculating the NFAs for the\n   preamble. I don't know if this saves us much because we still have\n   to copy the (huge) Array.ts each time this function is invoked, but\n   it can't hurt *)\nlet quoted_preamble = mk_template \"\\\"\" (copy quoted_value) \"\\\"\"\nlet braced_preamble = mk_template \"{\" (copy braced_value) \"}\"\nlet bare_preamble = mk_template \"\" (copy bare_value) \"\"\nlet any_preamble = quoted_preamble || braced_preamble || bare_preamble \n\nlet std_field_bibtex (o:regexp) = WS . o . (stype any_preamble)\nlet std_field_ris (r:string) (c:string) = r . (vtype any_preamble) . c\n\n(* str concatenations in vtype of return are fine; we only need the check on o *)\nlet do_std_field (r:string) (O:regexp where lens_splittable (del O) any_preamble) (c:string) \n  : (lens in std_field_bibtex O <-> std_field_ris r c)\n  = (WS <-> r) . del O . any_preamble . ins c\n      \nlet mk_do_field \n  (r:string) \n  (lo:regexp -> lens) \n  (O:regexp) \n  (lb:string) \n  (l:lens) \n  (rb:string where lens_splittable (lo O) (mk_template lb l rb))\n  (c:string) \n  : (lens in\n    (WS . (stype (lo O . mk_template lb l rb))) <-> \n    (r . (vtype (lo O . mk_template lb l rb)) . c))\n  = \n  (WS <-> r) . lo O . mk_template lb l rb . ins c\n\nlet field_bibtex (loo:lens) (l1:lens) (l2:lens) (l3:lens) : regexp =\n  let tmpl1 = mk_template \"{\" l1 \"}\" in\n  let tmpl2 = mk_template \"\\\"\" l2 \"\\\"\" in\n  let tmpl3 = mk_template \"\" l3 \"\" in\n  let templates = tmpl1 || tmpl2 || tmpl3 in\n  WS . (stype loo) . (stype templates)\n\nlet field_ris (r:string) (loo:lens) (l1:lens) (l2:lens) (l3:lens) (c:string) : regexp =\n  let tmpl1 = mk_template \"{\" l1 \"}\" in\n  let tmpl2 = mk_template \"\\\"\" l2 \"\\\"\" in\n  let tmpl3 = mk_template \"\" l3 \"\" in\n  let templates = tmpl1 || tmpl2 || tmpl3 in\n  r . (vtype loo) . (vtype templates) . c\n\nlet uniform_field_bibtex (loo:lens) (l:lens) : regexp = field_bibtex loo l l l\nlet uniform_field_ris (r:string) (loo:lens) (l:lens) (c:string) : regexp =\n  field_ris r loo l l l c\n\nlet do_field \n  (r:string) \n  (lo:regexp -> lens) \n  (O:regexp) \n  (l1:lens where lens_splittable (lo O) (mk_template \"{\" l1 \"}\"))\n  (l2:lens where lens_splittable (lo O) (mk_template \"\\\"\" l2 \"\\\"\"))\n  (l3:lens where lens_splittable (lo O) (mk_template \"\" l3 \"\"))\n  (c:string) \n  : (lens in field_bibtex (lo O) l1 l2 l3 <-> field_ris r (lo O) l1 l2 l3 c) =\n     mk_do_field r lo O \"{\" l1 \"}\" c\n  || mk_do_field r lo O \"\\\"\" l2 \"\\\"\" c\n  || mk_do_field r lo O \"\" l3 \"\" c\n\n(* special processors for fields *)\nlet digits : regexp = DIGIT+\n\nlet page_value \n  : (lens in (digits . \"-\"+ . digits) <-> (\"SP  - \" . digits . \"\\nEP  - \" . digits))\n  = ins (tag \"SP\") . copy digits . ins \"\\n\" .\n    del [\\-]+ . \n    ins (tag \"EP\") . copy digits \n\nlet month_data : lens = \n    (\"January\" | \"jan\") <-> \"01\"\n  | (\"February\" | \"feb\") <-> \"02\"\n  | (\"March\" | \"mar\") <-> \"03\"\n  | (\"April\" | \"apr\") <-> \"04\"\n  | (\"May\" | \"may\") <-> \"05\"\n  | (\"June\" | \"jun\") <-> \"06\"\n  | (\"July\" | \"jul\") <-> \"07\"\n  | (\"August\" | \"aug\") <-> \"08\"\n  | (\"September\" | \"sep\") <-> \"09\"\n  | (\"October\" | \"oct\") <-> \"10\"\n  | (\"November\" | \"nov\") <-> \"11\"\n  | (\"December\" | \"dec\") <-> \"12\"\n\nlet month_str : regexp = stype month_data\nlet month_num : regexp = vtype month_data\n\nlet dates_bibtex : regexp = \n  std_field_bibtex \"year\" . (uniform_field_bibtex (del \"month\") month_data)?\nlet dates_ris : regexp = \n  std_field_ris (tag \"PY\") \"/\" . (uniform_field_ris \"\" (del \"month\") month_data \"\")? . \"//\\n\"\n\nlet do_dates : (lens in dates_bibtex <-> dates_ris) = \n  let do_year : lens = do_std_field (tag \"PY\") \"year\" \"/\" in\n  let do_month : lens = do_field \"\" del \"month\" month_data month_data month_data \"\" in \n    (do_year . do_month?)\n    . ins \"//\" \n    . ins \"\\n\"\n\nlet title_bibtex : regexp = \n  field_bibtex (del \"title\") canonize_title canonize_title (copy bare_value)\n\nlet title_ris : regexp =\n  field_ris (tag \"T1\") (del \"title\") \n            canonize_title canonize_title (copy bare_value)\n            \"\\n\"\n    \nlet author_bibtex : regexp = \n  field_bibtex (del \"author\") authors authors (copy EMPTY)  \nlet author_ris : regexp = \n  field_ris \"\" (del \"author\") authors authors (copy EMPTY) NL\n\nlet do_author : (lens in author_bibtex <-> author_ris) = \n  do_field EPSILON del \"author\" authors authors (copy EMPTY) NL\n\nlet do_title : (lens in title_bibtex <-> title_ris) = \n  do_field (tag \"T1\") del \"title\" \n           canonize_title canonize_title (copy bare_value) \"\\n\"\n\nlet pages_bibtex : regexp =\n  field_bibtex (del \"pages\") page_value page_value (copy EMPTY)\n\nlet pages_ris : regexp =\n  field_ris \"\" (del \"pages\") page_value page_value (copy EMPTY) \"\\n\"\n\nlet do_pages : (lens in pages_bibtex <-> pages_ris) = \n  do_field \"\" del \"pages\" page_value page_value (copy EMPTY) \"\\n\"\n\n\nlet non_field = ([a-zA-Z]+ - \n                  (\"author\" | \"title\" | \"booktitle\" | \"journal\" | \"volume\" | \n                   \"number\" | \"note\" | \"pages\" | \"year\" | \"month\" | \"address\" |\n                   \"url\" | \"pdf\" | \"issn\" | \"publisher\" | \"abstract\" |\n                   \"series\"))\n\nlet noteize (R:regexp) : (lens in R <-> (R . \": \")) = \n  copy R . ins \": \"\n\nlet field_to_note_bibtex : regexp = \n  field_bibtex (noteize non_field)\n    (copy braced_value) (copy quoted_value) (copy bare_value)\n\nlet field_to_note_ris : regexp =\n  field_ris (tag \"M1\") (noteize non_field)\n            (copy braced_value) (copy quoted_value) (copy bare_value)\n            \"\\n\"\n\nlet do_field_to_note : (lens in field_to_note_bibtex <-> field_to_note_ris) = \n    do_field (tag \"M1\") noteize non_field \n             (copy braced_value) (copy quoted_value) (copy bare_value)\n             \"\\n\"\n  \nlet field_ris_tnl (R:string) : regexp = std_field_ris (tag R) \"\\n\"\n\nlet std_fields_bibtex : regexp = \n  ( author_bibtex \n  | title_bibtex \n  | dates_bibtex \n  | pages_bibtex\n  | std_field_bibtex \"booktitle\" | std_field_bibtex \"journal\"\n  | std_field_bibtex \"volume\"    | std_field_bibtex \"number\"\n  | std_field_bibtex \"note\"      | std_field_bibtex \"address\"\n  | std_field_bibtex \"url\"       | std_field_bibtex \"pdf\"\n  | std_field_bibtex \"issn\"      | std_field_bibtex \"publisher\"\n  | std_field_bibtex \"abstract\"  | std_field_bibtex \"series\") \n\nlet std_fields_ris : regexp = \n  ( author_ris\n  . title_ris       \n  . (field_ris_tnl \"T2\")?  \n  . (field_ris_tnl \"JO\")?  \n  . (field_ris_tnl \"VL\")?  \n  . (field_ris_tnl \"IS\")?\n  . (field_ris_tnl \"N1\")?  \n  . pages_ris?\n  . dates_ris?\n  . (field_ris_tnl \"AD\")?  \n  . (field_ris_tnl \"UR\")?  \n  . (field_ris_tnl \"L1\")?  \n  . (field_ris_tnl \"SN\")?   \n  . (field_ris_tnl \"PB\")?  \n  . (field_ris_tnl \"N2\")?  \n  . (field_ris_tnl \"T3\")? )\n\nlet fields_bibtex : regexp = (std_fields_bibtex | field_to_note_bibtex)*\nlet fields_ris : regexp = std_fields_ris . field_to_note_ris*\n\nlet fields : (lens in fields_bibtex <-> fields_ris) = \n  Sort.partition_sort_concat \n  #{lens}[\n      do_author\n    ; do_title\n    ; (do_std_field (tag \"T2\") \"booktitle\" NL)?\n    ; (do_std_field (tag \"JO\") \"journal\" NL)?\n    ; (do_std_field (tag \"VL\") \"volume\" NL)?\n    ; (do_std_field (tag \"IS\") \"number\" NL)?\n    ; (do_std_field (tag \"N1\") \"note\" NL)?\n    ; do_pages?\n    ; do_dates?\n    ; (do_std_field (tag \"AD\") \"address\" NL)?\n    ; (do_std_field (tag \"UR\") \"url\" NL)?\n    ; (do_std_field (tag \"L1\") \"pdf\" NL)?\n    ; (do_std_field (tag \"SN\") \"issn\" NL)?\n    ; (do_std_field (tag \"PB\") \"publisher\" NL)?\n    ; (do_std_field (tag \"N2\") \"abstract\" NL)?\n    ; (do_std_field (tag \"T3\") \"series\" NL)? ]\n  do_field_to_note \n\nlet key_re : regexp = (not_special - [, \\n])+\n\nlet key_bibtex : regexp = key_re . \",\" . [ ]* . \"\\n\"\nlet key_ris : regexp = tag \"ID\" . key_re\n\nlet do_key : (lens in key_bibtex <-> key_ris)\n  = ins (tag \"ID\") . key [^@{}\"\",\\n ]+ . ((\",\" . [ ]* . \"\\n\") <-> \"\")\n\ntest do_key.get \"dtts,\\n\" = \"ID  - dtts\"\n\nlet type_bibtex (b:string) : regexp = \"@\" . b . WS . \"{\"\nlet type_ris (r:string) : regexp = \"TY  - \" . r\n\n(* trivially splittable -- everything is constant strings*)\nlet do_type (b:string) (r:string) : (lens in type_bibtex b <-> type_ris r) = \n  (\"@\" . b . WS . \"{\") <-> (\"TY  - \" . r)\n\nlet chunk_bibtex =\n  (type_bibtex \"article\"       | type_bibtex \"inproceedings\" |\n   type_bibtex \"misc\"          | type_bibtex \"incollection\" |\n   type_bibtex \"mastersthesis\" | type_bibtex \"manual\" |\n   type_bibtex \"phdthesis\") .  (* includes the open { *)\n   key_bibtex . fields_bibtex . WS . \"}\"\n\nlet chunk_ris =\n  (type_ris \"JOUR\" | type_ris \"CONF\" | type_ris \"UNPB\" |\n   type_ris \"CHAP\" | type_ris \"THES\" | type_ris \"COMP\") . NL .\n   key_ris . NL . fields_ris . \"ER  -\\n\\n\"\n\nlet chunk : (lens in chunk_bibtex <-> chunk_ris) = \n  ( do_type \"article\" \"JOUR\" \n  | do_type \"inproceedings\" \"CONF\"\n  | do_type \"misc\" \"UNPB\"\n  | do_type \"incollection\" \"CHAP\"\n  | (do_type \"mastersthesis\" \"THES\" || do_type \"phdthesis\" \"THES\")\n  | do_type \"manual\" \"COMP\" )\n  . ins NL . \n  do_key . ins NL . \n  fields . \n  ((WS . \"}\") <-> \"ER  -\\n\\n\")\n\nlet non_entry : regexp = \n  ANY - (containing\n          (\"@\" . (\"article\"       | \"inproceedings\" | \"misc\" | \"incollection\" |\n                 \"mastersthesis\" | \"manual\"        | \"phdthesis\")))\n\nlet del_non_entry : lens = \n  del non_entry\n\nlet full_chunk = del_non_entry . <greedy 0 \"k\":chunk>    \n\nlet ris : (lens in ((non_entry . chunk_bibtex)* . non_entry) <-> chunk_ris* ) = \n  (full_chunk . full_chunk* )? . del_non_entry\n\ntest ris.get \n<<\n\n  @inproceedings{dtts,\n     author = {J. Nathan Foster \n               and Benjamin C. Pierce \n               and Alan Schmitt},\n     title =  {A {L}ogic {Y}our {T}ypechecker {C}an {C}ount {O}n: {U}nordered {T}ree {T}ypes in {P}ractice},\n     booktitle = planx07,\n     year =   2007,\n     month = jan,\n     pages = {80--90},\n     conf=    {http://www.cis.upenn.edu/~jnfoster/papers/dtts.pdf},\n     slides = {http://www.cis.upenn.edu/~jnfoster/papers/dtts-slides.pdf},\n     jnf =    \"yes\",\n   }\n>> = \n<<\nTY  - CONF\nID  - dtts\nAU  - Foster, J. Nathan\nAU  - Pierce, Benjamin C.\nAU  - Schmitt, Alan\nT1  - A Logic Your Typechecker Can Count On: Unordered Tree Types in Practice\nT2  - planx07\nSP  - 80\nEP  - 90\nPY  - 2007/01//\nM1  - conf: http://www.cis.upenn.edu/~jnfoster/papers/dtts.pdf\nM1  - slides: http://www.cis.upenn.edu/~jnfoster/papers/dtts-slides.pdf\nM1  - jnf: yes\nER  -\n\n\n>>\n\ntest ris.get \n\"@article{Lenses-TOPLAS05,\n| author = {J. Nathan Foster and Michael B. Greenwald and Jonathan T. Moore and Benjamin C. Pierce and Alan Schmitt},\n| title = {Combinators for Bidirectional Tree Transformations: \n|          {A} Linguistic Approach to the View Update Problem},\n| journal = {Transactions on Programming Languages and Systems (TOPLAS)},\n| year = {2007},\n| month = may,\n| pages = {233--246},\n| address = {New York, NY, USA},\n|} \n|\n|@inproceedings{SchemaSync-DBPL05,\n|  author    = {Foster, J. Nathan and Greenwald, Michael B. and Kirkegaard, Christian and Pierce, Benjamin C. and Schmitt, Alan},\n|  title     = {Exploiting Schemas in Data Synchronization},\n|  booktitle = {Database Programming Languages (DBPL), Trondheim, Norway},\n|  year      = {2005},\n|  month     = {August}, \n|  pages     = {42--57},\n|}\n|\" = \n<<\nTY  - JOUR\nID  - Lenses-TOPLAS05\nAU  - Foster, J. Nathan\nAU  - Greenwald, Michael B.\nAU  - Moore, Jonathan T.\nAU  - Pierce, Benjamin C.\nAU  - Schmitt, Alan\nT1  - Combinators for bidirectional tree transformations: A linguistic approach to the view update problem\nJO  - Transactions on Programming Languages and Systems (TOPLAS)\nSP  - 233\nEP  - 246\nPY  - 2007/05//\nAD  - New York, NY, USA\nER  -\n\nTY  - CONF\nID  - SchemaSync-DBPL05\nAU  - Foster, J. Nathan\nAU  - Greenwald, Michael B.\nAU  - Kirkegaard, Christian\nAU  - Pierce, Benjamin C.\nAU  - Schmitt, Alan\nT1  - Exploiting schemas in data synchronization\nT2  - Database Programming Languages (DBPL), Trondheim, Norway\nSP  - 42\nEP  - 57\nPY  - 2005/08//\nER  -\n\n\n>>\n \ntest ris.get\n<<\n@article{schema-sync-jcss,\n  author = {J. Nathan Foster \n            and Michael B. Greenwald \n            and Christian Kirkegaard \n            and Benjamin C. Pierce \n            and Alan Schmitt},\n  title =  {Exploiting {S}chemas in {D}ata {S}ynchronization},\n  journal = {Journal of Computer and System Sciences},\n  publisher= {Elsevier},\n  volume = 73,\n  number = 4,\n  year = 2007,\n  month = {June},\n  note = {Short version in DBPL '05.},\n  full = { http://dx.doi.org/10.1016/j.jcss.2006.10.024 },\n  jnf = \"yes\",\n  plclub = \"yes\",\n}\n\n>> = \n<<\nTY  - JOUR\nID  - schema-sync-jcss\nAU  - Foster, J. Nathan\nAU  - Greenwald, Michael B.\nAU  - Kirkegaard, Christian\nAU  - Pierce, Benjamin C.\nAU  - Schmitt, Alan\nT1  - Exploiting Schemas in Data Synchronization\nJO  - Journal of Computer and System Sciences\nVL  - 73\nIS  - 4\nN1  - Short version in DBPL '05.\nPY  - 2007/06//\nPB  - Elsevier\nM1  - full:  http://dx.doi.org/10.1016/j.jcss.2006.10.024 \nM1  - jnf: yes\nM1  - plclub: yes\nER  -\n\n\n>>\n\ntest ris.put <<\nTY  - JOUR\nID  - schema-sync-jcss\nAU  - Foster, J. Nathan\nAU  - Greenwald, Michael B.\nAU  - Kirkegaard, Christian\nAU  - Pierce, Benjamin C.\nAU  - Schmitt, Alan\nT1  - Exploiting Schemas in Data Synchronization\nJO  - Journal of Computer and System Sciences\nVL  - 73\nIS  - 4\nN1  - Short version in DBPL '05.\nPY  - 2007/06//\nPB  - Elsevier\nM1  - full:  http://dx.doi.org/10.1016/j.jcss.2006.10.024 \nM1  - jnf: yes\nM1  - plclub: yes\nER  -\n\nTY  - CONF\nID  - SchemaSync-DBPL05\nAU  - Foster, J. Nathan\nAU  - Greenwald, Michael B.\nAU  - Kirkegaard, Christian\nAU  - Pierce, Benjamin C.\nAU  - Schmitt, Alan\nT1  - Exploiting schemas in data synchronization\nT2  - Database Programming Languages (DBPL), Trondheim, Norway\nM1  - plclub: yes\nER  -\n\n\n>> into <<\n@article{Lenses-TOPLAS05,\n author = {J. Nathan Foster and Michael B. Greenwald and Jonathan T. Moore and Benjamin C. Pierce and Alan Schmitt},\n title = {Combinators for Bidirectional Tree Transformations: \n          {A} Linguistic Approach to the View Update Problem},\n journal = {Transactions on Programming Languages and Systems (TOPLAS)},\n year = {2007},\n month = may,\n pages = {233--246},\n address = {New York, NY, USA},\n} \n\n@inproceedings{SchemaSync-DBPL05,\n  author    = {Foster, J. Nathan and Greenwald, Michael B. and Kirkegaard, Christian and Pierce, Benjamin C. and Schmitt, Alan},\n  title     = {Exploiting Schemas in Data Synchronization},\n  booktitle = {Database Programming Languages (DBPL), Trondheim, Norway},\n  year      = {2005},\n  month     = {August}, \n  pages     = {42--57},\n}\n>> = <<\n@article{schema-sync-jcss,\n author = {J. Nathan Foster and Michael B. Greenwald and Christian Kirkegaard and Benjamin C. Pierce and Alan Schmitt},\n title = {Exploiting {S}chemas in {D}ata {S}ynchronization},\n journal = {Journal of Computer and System Sciences},\nvolume=\"73\",\nnumber=\"4\",\nnote=\"Short version in DBPL '05.\",\n year = {2007},\n month = jun,\npublisher=\"Elsevier\",\nfull={ http://dx.doi.org/10.1016/j.jcss.2006.10.024 },\njnf={yes},\nplclub={yes},\n} \n\n@inproceedings{SchemaSync-DBPL05,\n  author    = {Foster, J. Nathan and Greenwald, Michael B. and Kirkegaard, Christian and Pierce, Benjamin C. and Schmitt, Alan},\n  title     = {Exploiting schemas in data synchronization},\n  booktitle = {Database Programming Languages (DBPL), Trondheim, Norway},\nplclub={yes},\n}\n>>\n\n\n\nlet main () =\n  let usage (code:int) =\n    let prog = Prefs.get_prog_name () in\n    let _ = Sys.put_str (\n      \"Usage: \" . prog . \" {get|put} args\\n\" .\n\t\"  \".prog.\" get <source>\\n\" .\n\t\"  \".prog.\" put <view> <old source>\\n\" )\n    in\n    code\n  in\n  let cget (source:string) =\n    match String.file_ext source with\n      | Some \"bib\" -> (let _ = Sys.put_str (get ris (Sys.read source)) in 0)\n      | _ -> usage 1\n  in\n  let cput (view:string) (source:string) =\n    match String.file_ext view, String.file_ext source with\n      | Some \"ris\", Some \"bib\" -> (let _ = Sys.put_str (put ris (Sys.read view) (Sys.read source)) in 0)\n      | _ -> usage 1\n  in\n  match Prefs.read_string_list (Prefs.extern_rest ()) with\n    | \"get\"::source::[] -> cget source\n    | \"put\"::view::source::[] -> cput view source\n    | _ -> usage 1\n\n"
let _ = Hashtbl.add items "students" "module Students = \n  let Name : regexp = [a-zA-Z]+ . ([ ] . [a-zA-Z]+)*\n  let Email :regexp = [a-zA-Z._]+ . [@] . [a-zA-Z._]+\n  let Id : regexp  = [0-9]{8}\n  let Nl : regexp = \"\\r\\n\" | [\\r\\n]\n\n  let person : lens = \n    Xml.attr1_elt_swap NL1 \"student\" \"sid\" (copy Id)\n      begin\n        Xml.simple_elt NL2 \"name\" (copy Name) .\n        qins SP \" \" .\n        Xml.simple_elt NL2 \"email\" (ins \"(\" . copy Email . ins \")\") .\n        qins SP \" \"\n      end\n\n  let persons : lens =\n      copy \"\"\n    | person . ( qins Nl \"\\n\" . person )*\n\n  let file : lens =\n    Xml.elt NL0 \"students\" persons\n\n  let file_xml : string = \n<<\n <students>\n  <student sid=\"19701234\">\n   <name>John Doe</name>\n   <email>john_doe@notmail.org</email>\n  </student>\n  <student sid=\"19785678\">\n   <name>Jane Dow</name>\n   <email>dow@bmail.org</email>\n  </student>\n </students>\n>>\n\n  let file_ascii : string = \n<<\n  John Doe (john_doe@notmail.org) 19701234\n  Jane Dow (dow@bmail.org) 19785678\n>>\n\ntest file.get file_xml = file_ascii \n\ntest file.create file_ascii = (NL0 . file_xml)\n"
let _ = Hashtbl.add items "greedy" "module Greedy =\n\nlet sep_list (a:lens) (b:lens) = (a . (b . a)* )\n\nlet g (name:string) = Tag (Greedy, Threshold 0, Key, name)\n\nlet main =\n  let word = (copy [a-z] . del [A-Z]* )+ in\n  let line = sep_list <g \"w\":word> \" \" in\n  let file = sep_list <g \"l\":line> \"\\n\" in\n  file\n\ntest get main \"aRobASe\" = \"aobe\"\ntest get main <<\n  worDonE woRDTwo\n  linETwo loETne lOteE\n  omTEo mENToe o nto\n  aoOEEU thoeu nOEUA\n>> = <<\n  woron wowo\n  linwo lone lte\n  omo moe o nto\n  ao thoeu n\n>>\n\ntest create main \"aoeu\" = \"aoeu\"\ntest create main <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>> = <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>>\n\ntest put main \"a b c\" \"aA bB cC\" = \"aA bB cC\"\ntest put main \"a b c\" \"bB cC aA\" = \"aA bB cC\"\ntest put main \"a b c\" \"cC aA bB\" = \"aA bB cC\"\n\ntest put main \"a b c d f\" \"aA cC dD eE fF\" = \"aA bE cC dD fF\"\n\ntest put main \"a b c\" \"aX aY aZ\" = \"aX bY cZ\"\ntest put main \"a a a\" \"bB aA cC\" = \"aA aB aC\"\n\ntest put main \"b c\" \"aA bB cC\" = \"bB cC\"\ntest put main \"a c\" \"aA bB cC\" = \"aA cC\"\ntest put main \"a b\" \"aA bB cC\" = \"aA bB\"\n\ntest put main \"a\" \"aA aAA\" = \"aA\"\ntest put main \"a a\" \"aA\" = \"aA a\"\n\ntest put main \"b a\" \"aA bB\" = \"bB aA\"\n\ntest put main \"b c a y\" \"aA bB cC dD\" = \"bB cC aA yD\"\ntest put main \"x y z\" \"aA bB cC\" = \"xA yB zC\"\n\ntest put main \"xxx yy z\" \"aA bBbBB cCcCCcCCC\" = \"xCxCCxCCC yByBB zA\"\n\ntest put main <<\n  a a a a a\n  z\n  b c a y\n>> <<\n  aA bB cC dD\n  aAAA aAA aA\n  xXXX\n>> = <<\n  aAAA aAA aA a a\n  zXXX\n  bB cC aA yD\n>>\n\ntest put main <<\n  ooo ooo o\n  nn nnn\n  aaa a aa\n  uu u\n  ddd dd d\n>> <<\n  oooOOoO oOOooO oO\n  aaAAa aAaa aAA aAAa\n  eeEeEE eE\n  uUUuuU uuUU\n>> = <<\n  oOOooO oooOO oO\n  nEn nnEnEE\n  aaAAa aAA aAAa\n  uuUU uUU\n  ddd dd d\n>>\n\ntest put main \"ooo o\" \"oOoOoOO oOOoO oO\" = \"oOoOoOO oO\"\n\ntest put main \"o a o a o a o a\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO aA oOO aAA oOOO aAAA oOOOO aAAAA\"\n\ntest put main \"o a o a o a\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO aA oOO aAA oOOO aAAA\"\n\ntest put main \"o o o o o\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO oOO oOOO oOOOO oOOOOO\"\n\ntest put main \"o o o o\"\n              \"aA oO aAA oOO aAAA oOOO aAAAA oOOOO aAAAAA oOOOOO\"\n            = \"oO oOO oOOO oOOOO\"\n\ntest put main \"aa a\" \"aUUUUUaaUUU aaUU\" = \"aaUU aUUUUU\"\n\nlet main =\n  let word = ([a-m] . del [A-Z]* | [n-z] . del [A-Z]* )+ in\n  sep_list (\"+\" . <g \"w\":word> | \"-\" . <g \"w\":word>) \" \"\n\ntest get main \"+aA -bB\" = \"+a -b\"\ntest put main \"+a -b +c -d\" \"+aA -bB +cC -dD\" = \"+aA -bB +cC -dD\"\ntest put main \"-a +b -c +d\" \"+aA -bB +cC -dD\" = \"-aA +bB -cC +dD\"\ntest put main \"+c -d +a -b\" \"+aA -bB +cC -dD\" = \"+cC -dD +aA -bB\"\ntest put main \"-c -d +a +b\" \"+aA -bB +cC -dD\" = \"-cC -dD +aA +bB\"\n\ntest put main \"+a +c -d\" \"+aA -bB +cC\" = \"+aA +cC -dB\"\ntest put main \"-a +m +d -e\" \"+aA -bB +cC -dD\" = \"-aA +mB +dD -eC\"\ntest put main \"-a +n +d -e\" \"+aA -bB +cC -dD\" = \"-aA +n +dD -eC\"\n\n(* compose *)\n\nlet main =\n  let word1 = ([a-z] . [A-Z]* . del [0-9]* )+ in\n  let line1 = sep_list <g \"w\":word1> \" \" in\n  let file1 = sep_list <g \"l\":line1> \"\\n\" in\n  let word2 = ([a-z] . del [A-Z]* )+ in\n  let line2 = sep_list <g \"w\":word2> \" \" in\n  let file2 = sep_list <g \"l\":line2> \"\\n\" in\n  file1 ; file2\n\ntest get main \"aA0 bB1 cC2\" = \"a b c\"\ntest create main \"a b c\" = \"a b c\"\ntest put main \"a b c\" \"aA0 bB1 cC2\" = \"aA0 bB1 cC2\"\ntest put main \"a c d\" \"aA0 bB1 cC2\" = \"aA0 cC2 dB1\"\n\nlet main =\n  let word = ([a-z] . [A-Z]* . del [0-9]* )+ ; ([a-z] . del [A-Z]* )+ in\n  let line = sep_list <g \"w\":word> \" \" in\n  let file = sep_list <g \"l\":line> \"\\n\" in\n  file\n\ntest get main \"aA0 bB1 cC2\" = \"a b c\"\ntest create main \"a b c\" = \"a b c\"\ntest put main \"a b c\" \"aA0 bB1 cC2\" = \"aA0 bB1 cC2\"\ntest put main \"a c d\" \"aA0 bB1 cC2\" = \"aA0 cC2 dB1\"\n\nlet a = copy \"a\" . copy \"b\"*\nlet a2 = copy (\"a\" . \"b\"* )\nlet b = copy \"a\" . del \"b\"*\n\nlet main =\n  let sep_iter (a:lens) (b:lens) (n:int) = a . lens_iter (b . a) n n in\n  let cn = [a-z] . [A-Z]* in\n  let wn = <g \"c\":cn>+ in\n  let wnc = <g \"w\":wn> in\n  let c = [a-z] . del [A-Z]* in\n  let w = <g \"c\":c>+ in\n  let wc = <g \"w\":w> in\n  ( sep_iter   wnc \" \" 3 . '1' <-> '2'\n  ; sep_iter   wnc \" \" 3 . '2' <-> '3')\n  ; ( sep_iter wnc \" \" 3 . '3' <-> '4'\n    ; sep_iter wc \" \" 3 . '4' <-> '5')\n\ntest get main \"aAbB cCdD eE fF1\" = \"ab cd e f5\"\ntest create main \"a b c e5\" = \"a b c e1\"\ntest put main \"b de ge h5\" \"aAbB cC dDeE fFgG1\" = \"bB dDeE gGeF hC1\"\n\n(* invert *)\n\nlet main =\n  let l = invert (copy [a-z] . del \"B\") . del [ 0-9]\n  in <g \"g\":l>*\n\ntest get main \"a1b2\" = \"aBbB\"\ntest create main \"aBbB\" = \"a b \"\ntest put main \"aBbBcBeB\" \"a1c3d4e5\" = \"a1b4c3e5\"\n\nlet l = copy [a-z] . del \"B\"\n\ntest (invert <l>) = error (* chunks in invert *)\n\n"
let _ = Hashtbl.add items "ffactor" "(**********************************************************************)\n(* The Harmony Project                                                *)\n(* harmony@lists.seas.upenn.edu                                       *)\n(**********************************************************************)\n(* Copyright (C) 2009 J. Nathan Foster and Benjamin C. Pierce         *)\n(*                                                                    *)\n(* This library is free software; you can redistribute it and/or      *)\n(* modify it under the terms of the GNU Lesser General Public         *)\n(* License as published by the Free Software Foundation; either       *)\n(* version 2.1 of the License, or (at your option) any later version. *)\n(*                                                                    *)\n(* This library is distributed in the hope that it will be useful,    *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of     *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU  *)\n(* Lesser General Public License for more details.                    *)\n(**********************************************************************)\n(* /examples/ffactor.boom                                             *)\n(* management tool for multiple versions of the same file             *)\n(* $Id:: ffactor.boom 4901 2010-05-13 21:14:49Z cretin              $ *)\n(**********************************************************************)\nmodule Ffactor =\n\n(* ---------------------------------------------------------------- *)\n(*                               TODO                               *)\n(*\n\n- do the check prefs in main\n- use 'zmodload zsh/stat' and 'zstat +mtime file'\n  if activated with '-x' stringlist\n- Arg module\n  - add a usage function\n  - rewrite it using Prefs.get_args\n    create_... : ... -> Arg.t -> Arg.t\n- write a --documentation\n\n *)\n\n(* ---------------------------------------------------------------- *)\n(*                           definitions                            *)\n\nlet if 'a (b:bool) (t:'a) (f:'a) =\n  match b with\n  | true -> t\n  | false -> f\n  :'a\nlet id 'a (x:'a) = x\nlet format_list (prefix:string) (separator:string) (suffix:string)\n    'a (f:'a -> string) (l:'a List.t) =\n  prefix . fst{string}{bool} (\n    List.fold_left{'a}{string * bool} (\n      fun (sb:string * bool) (x:'a) ->\n        match sb with\n        | s, b -> (s . if{string} b separator \"\" . f x, true)\n            :string * bool\n    ) (\"\", false) l\n  ) . suffix\nlet show_list 'a (l:'a List.t) =\n  (format_list \"[\" \";\" \"]\"){'a} show{'a} l\nlet if_none 'a (x:'a) (yo:'a option) =\n  match yo with\n  | None -> x\n  | Some y -> y\n  :'a\n\n(* lens utilities *)\nlet ambiguous_lens_concat_contract (a:lens) (b:lens) =\n  is_basic a && is_basic b && splittable_cex (stype a) (stype b)\nlet ambiguous_lens_concat\n    (a:lens)\n    (b:lens where ambiguous_lens_concat_contract a b) =\n  Native.Prelude.lens_concat a b\nlet ambiguous_lens_partition_one_contract (a:lens) (b:lens) =\n  lens_star_contract b && lens_swap_contract b* a\n  && ambiguous_lens_concat_contract (lens_swap b* a) b*\nlet ambiguous_lens_partition_one\n    (a:lens)\n    (b:lens where ambiguous_lens_partition_one_contract a b) =\n  ambiguous_lens_concat (lens_swap b* a) b*\nlet is_lens (l:lens) = rel_is_id (sequiv l) && rel_is_id (vequiv l)\n\n(* exceptions *)\ntype errno = ENOENT of string\nlet show_errno (e:errno) =\n  match e with\n  | ENOENT f -> f . \": No such file or directory.\"\ntype exception =\n    Failure of string\n  | Invalid_argument of string\n  | Exit of int\n  | ErrNo of errno\nlet bind = Exception.generic_bind{exception}\nlet okfailwith 'a = (),\n  Exception.generic_try{exception}{'a},\n  Exception.generic_raise{exception}{'a},\n  (fun (message:string) ->\n     Exception.generic_raise{exception}{'a} (Failure message)),\n  Exception.generic_ok{exception}{'a}\nlet main_end (convert:exception -> int) (x:(exception, int) Exception.t) =\n  Exception.generic_convert{exception}{int} x convert\n\n(* other *)\nlet write (file:string) (data:string) =\n  let _ = Sys.write file data in 0\nlet put_str_ln (x:string) = Sys.put_str (x . newline)\nlet list_to_option 'a (xs:'a List.t) =\n  let _, raise, _, ok = okfailwith{'a option} in\n  match xs with\n  | [] -> ok None{'a}\n  | x::[] -> ok (Some{'a} x)\n  | _ -> raise (Invalid_argument \"list_to_option\")\nlet safe_read (file:string) =\n  let _, raise, _, ok = okfailwith{string} in\n  match Sys.file_exists file with\n  | true -> ok (Sys.read file)\n  | false -> raise (ErrNo $ ENOENT file)\n\n(* instantiation *)\nlet id's = id{string}\nlet if_none's = if_none{string}\nlet show'r = show{regexp}\nlet show's = show{string}\nlet list_to_option's = list_to_option{string}\nlet bind'bi = bind{bool}{int}\nlet bind'si = bind{string}{int}\nlet bind'sLi = bind{string List.t}{int}\nlet bind'sOi = bind{string option}{int}\nlet bind'sOs = bind{string option}{string}\nlet bind'ss = bind{string}{string}\nlet bind'ui = bind{unit}{int}\nlet okfailwith'b = okfailwith{bool}\nlet okfailwith'i = okfailwith{int}\nlet okfailwith's = okfailwith{string}\nlet okfailwith'sL = okfailwith{string List.t}\nlet okfailwith'sO = okfailwith{string option}\nlet okfailwith'u = okfailwith{unit}\n\n(* ---------------------------------------------------------------- *)\n(*                            Arg module                            *)\n\nmodule Arg =\n  type t =\n      Bool of bool_prefs\n    | StringList of string_list_prefs\n  let make_alias (t:t) (alias:string) =\n    match t with\n    | Bool p -> Prefs.alias_bool p alias\n    | StringList p -> Prefs.alias_string_list p alias\n  let create_bool (name:string) (doc:string) =\n    let p = Prefs.create_bool (\"-\" . name) false doc in\n    let read () =\n      let _, ok = okfailwith'b in\n      ok $ Prefs.read_bool p\n    in\n    Bool p, read\n  let create_bool_alias (name:string) (alias:string) (doc:string) =\n    let p, read = create_bool name doc in\n    let _ = make_alias p alias in\n    read\n  let create_string_option (name:string) (doc:string) =\n    let p = Prefs.create_string_list (\"-\" . name) doc in\n    let read () =\n      let value = Prefs.read_string_list p in\n      let _, try, raise, failwith, _ = okfailwith'sO in\n      try (list_to_option's value) $ fun (exn:exception) ->\n      match exn with\n      | Invalid_argument _ ->\n          failwith (\"You can't define more than one \" . name . \".\")\n      | x -> raise x\n    in\n    StringList p, read\n  let create_string_option_alias\n      (name:string) (alias:string) (doc:string) =\n    let p, read = create_string_option name doc in\n    let _ = make_alias p alias in\n    read\n  let create_string (name:string) (default:string) (doc:string) =\n    let p, read =\n      create_string_option\n        name (doc . \" (default: \" . show's default . \")\")\n    in\n    let read () =\n      bind'sOs (read ()) $ fun (value:string option) ->\n      let _, ok = okfailwith's in\n      ok $ if_none's default value\n    in\n    p, read\n  let create_string_alias\n      (name:string) (alias:string) (default:string) (doc:string) =\n    let p, read = create_string name default doc in\n    let _ = make_alias p alias in\n    read\n  let create_string_mandatory (name:string) (doc:string) =\n    let p, read = create_string_option name $ \"mandatory: \" . doc in\n    let read () =\n      bind'sOs (read ()) $ fun (value:string option) ->\n      let _, failwith, ok = okfailwith's in\n      match value with\n      | Some v -> ok v\n      | None -> (failwith $ show's name . \" is mandatory.\")\n    in\n    p, read\n  let create_string_mandatory_alias\n      (name:string) (alias:string) (doc:string) =\n    let p, read = create_string_mandatory name doc in\n    let _ = make_alias p alias in\n    read\n  let create_string_list (name:string) (doc:string) =\n    let p = Prefs.create_string_list (\"-\" . name) doc in\n    let read () =\n      let _, ok = okfailwith'sL in\n      ok $ Prefs.read_string_list p\n    in\n    StringList p, read\n  let create_string_list_alias (name:string) (alias:string) (doc:string) =\n    let p, read = create_string_list name doc in\n    let _ = make_alias p alias in\n    read\n  let create_rest () =\n    let p = Prefs.extern_rest () in\n    let read () =\n      let _, ok = okfailwith'sL in\n      ok $ Prefs.read_string_list p\n    in\n    StringList p, read\n  let get_prog_name = Prefs.get_prog_name\n  let print_usage = Prefs.print_usage\nend\n\n(* ---------------------------------------------------------------- *)\n(*                         File_pref module                         *)\n\nmodule File_pref =\n  type value = Value of regexp\n  type separator = Separator of string\n  type comment = Comment of  string * string\n  type command = Command of string * string\n  type hide = Hide of string * string\n  type view = View of string * string\n  type t = T of value * separator * comment * command * hide * view\n  let default_value = Value ([a-zA-Z] . [,$~{} ./a-zA-Z0-9_\\-@]* )\n  let default_separator = Separator \";\"\n  let default_comment = Comment (\"#\", \"\\n\")\n  let default_command = Command (\"@\", \"\")\n  let default_hide = Hide (\"(\", \")\")\n  let default_view = View (\"view:\", \"\")\n  let default_t = T (\n    default_value,\n    default_separator,\n    default_comment,\n    default_command,\n    default_hide,\n    default_view)\n  let set_value (value:regexp) (t:t) =\n    match t with T (_, separator, comment, command, hide, view)\n      -> T (Value value, separator, comment, command, hide, view)\n  let set_separator (separator:string) (t:t) =\n    match t with T (value, _, comment, command, hide, view)\n      -> T (value, Separator separator, comment, command, hide, view)\n  let set_comment (comment:string * string) (t:t) =\n    match t with T (value, separator, _, command, hide, view)\n      -> T (value, separator, Comment comment, command, hide, view)\n  let get_value (t:t) =\n    match t with T (Value value, _, _, _, _, _) -> value\n  let get_separator (t:t) =\n    match t with T (_, Separator separator, _, _, _, _) -> separator\n  let get_comment (t:t) =\n    match t with T (_, _, Comment comment, _, _, _) -> comment\n  let get_command (t:t) =\n    match t with T (_, _, _, Command command, _, _) -> command\n  let get_hide (t:t) =\n    match t with T (_, _, _, _, Hide hide, _) -> hide\n  let get_view (t:t) =\n    match t with T (_, _, _, _, _, View view) -> view\n  let shell_like = default_t\n  let c_like = set_comment (\"//\", \"\\n\") default_t\n  let cpp_like = set_comment (\"/*\", \"*/\") default_t\n  let ocaml_like = set_comment (\"(*\", \"*)\") default_t\n  let debug_like = T (\n    Value [a-z],\n    Separator \"\",\n    Comment (\"(\", \")\"),\n    Command (\"\", \"\"),\n    Hide (\"!\", \"\"),\n    View (\"\", \"\"))\n  let comment_signs (t:t) =\n    let prefix, suffix = get_comment t in\n    prefix | suffix\n  let c_prefix (t:t) =\n    let comment, _ = get_comment t in\n    let command, _ = get_command t in\n    comment . command\n  let c_suffix (t:t) =\n    let _, comment = get_comment t in\n    let _, command = get_command t in\n    command . comment\n  let no_comments (t:t) = not_containing $ comment_signs t\n  let commands (t:t) = c_prefix t . no_comments t . c_suffix t\n  let data (t:t) = not_containing $ commands t\n  let make_view (t:t) (values:string List.t) =\n    let prefix, suffix = get_view t in\n    let separator = get_separator t in\n    (format_list prefix separator suffix){string} id's values\n  let c_string (t:t) (value:string) = c_prefix t . value . c_suffix t\n  let cv_string (t:t) (values:string List.t) =\n    c_string t $ make_view t values\n  let c_regexp (t:t) (r:regexp) = c_prefix t . r . c_suffix t\n  let c_lens (t:t) (l:lens) = c_prefix t . l . c_suffix t\n  let ch_other (t:t) (r:regexp) =\n    let prefix, suffix = get_hide t in\n    c_lens t $ ins prefix . diff (get_value t) r . ins suffix\n  let c_all (t:t) = c_prefix t . get_value t . c_suffix t\n  let c_stop (t:t) = c_string t \"\"\n  let check (t:t) (value_list:string List.t) =\n    let subset (a:regexp) (b:regexp) = is_empty $ diff a b in\n    let sl (a:regexp) (b:regexp) = a . (b . a)* in\n    let v = get_value t in\n    let sep = get_separator t in\n    let tp, ts = get_comment t in\n    let dp, ds = get_command t in\n    let hp, hs = get_hide t in\n    let vp, vs = get_view t in\n    let checks =\n      #{bool * string}[\n        iterable (sep . v),\n         \"the values and the separator are ambiguous\";\n        subset (vp . sl v sep . vs) (no_comments t),\n         \"the view prefix contains comments\";\n        subset v? (no_comments t),\n        \"the values may contain comments\";\n        subset (hp . v . hs) (no_comments t),\n        \"the hide pre/su-ffixes contain comments\";\n        not (matches v \"\"),\n        \"your values should not contain the empty string\";\n        List.for_all{string} (matches v) value_list,\n        \"the values do not match \" . show'r v]\n    in\n    let bind =\n      Exception.generic_bind{unit}{string option}{string option}\n    in\n    let ok = Exception.generic_ok{unit}{string option} in\n    let convert (x:(unit, string option) Exception.t) =\n      Exception.generic_convert{unit}{string option} x $ fun () ->\n      None{string}\n    in\n    convert $\n    List.fold_left{bool * string}{(unit, string option) Exception.t}\n      (fun (x:(unit, string option) Exception.t) (bs:bool * string) ->\n         bind x $ fun (u:string option) ->\n         match bs with\n         | true, _ -> ok None{string}\n         | false, s -> ok (Some{string} s))\n      (ok None{string}) checks\n  let good (t:t) (vs:string List.t) = check t vs = None{string}\nend\nlet bind'pi = bind{File_pref.t}{int}\nlet bind'pp = bind{File_pref.t}{File_pref.t}\nlet okfailwith'p = okfailwith{File_pref.t}\n\n(* ---------------------------------------------------------------- *)\n(*                            main lens                             *)\n\nlet main_lens (prefs:File_pref.t)\n    (value_list:string List.t where File_pref.good prefs value_list)\n    :(l:lens where is_lens l) =  (* it's very well behaved *)\n  let data = File_pref.data prefs in\n  let cv_string = File_pref.cv_string prefs in\n  let c_regexp = File_pref.c_regexp prefs in\n  let ch_other = File_pref.ch_other prefs in\n  let c_stop = File_pref.c_stop prefs in\n  let values =\n    List.fold_left{string}{regexp}\n      (fun (acc:regexp) (value:string) -> acc | value)\n      [] value_list\n  in\n  let _:(unit where bij ((c_stop | c_regexp values) . data)) = () in\n  let section =\n    let hidden = Tag (Positional, Threshold 100, Key, \"hidden\") in\n      (c_stop | c_regexp values) . data\n    |  <hidden:ch_other values . del data>\n  in\n  let value_check = ins $ cv_string value_list in\n  data . value_check . align section*\n\n(* ---------------------------------------------------------------- *)\n(*                          main function                           *)\n\n(* command line arguments *)\nlet read_help = Arg.create_bool_alias \"help\" \"h\" \"print this help\"\nlet read_init = Arg.create_bool_alias \"init\" \"i\" \"create the source file\"\nlet read_extension = Arg.create_string_alias\n  \"extension\" \"e\" \"factor\" \"extension of source\"\nlet read_output = Arg.create_string_option_alias\n  \"output\" \"o\" \"output file (default to the other file)\"\nlet read_default = Arg.create_string_mandatory_alias\n  \"default\" \"d\" \"shell, c, cpp or ocaml\"\nlet read_file = Arg.create_string_mandatory_alias\n  \"file\" \"f\" \"the source/view file\"\nlet _, read_rest = Arg.create_rest ()\n\n(* usage message *)\nlet usage:string =\n  \"Usage: \" . Arg.get_prog_name ()\n  . \" --default <file_type> --file <file> [values [...]]\"\n\n(* main code *)\nlet main () =\n  let check_string_with (r:regexp) (s:string) (m:string) =\n    let _, failwith, ok = okfailwith's in\n    match matches r s with\n    | true -> ok s\n    | false -> failwith m\n  in\n  let file_error (filename:string) (head:string) (advices:string List.t) =\n    let tail =\n      match advices with\n      | [] -> \"\"\n      | _ ->\n          List.fold_left{string}{string}\n            (fun (acc:string) (line:string) ->\n               acc . \"\\n* \" . line)\n            \"\\n\\nYou might want to check these:\"\n            advices\n    in\n    \"File \" . show's filename . \" \" . head . \".\" . tail\n  in\n  main_end\n    (fun (exn:exception) ->\n       let err (s:string) =\n         let _ = put_str_ln $ Arg.get_prog_name () . \": \" . s in 1\n       in\n       match exn with\n       | Exit i -> i\n       | Failure s -> (err $ \"Failure: \" . s)\n       | ErrNo e -> (err $ show_errno e)\n       | _ -> (err $ \"Uncaught exception \" . show{exception} exn)) $\n  bind'bi (read_help ()) $ fun (help:bool) ->\n  bind'ui\n    (let _, raise, _, ok = okfailwith'u in\n     match help with\n     | true -> (\n         let _ = Arg.print_usage usage in\n         raise (Exit 0))\n     | false -> ok ()) $\n    fun () ->\n  bind'si (read_default ()) $ fun (default:string) ->\n  bind'pi\n    (let _, failwith, ok = okfailwith'p in\n     match default with\n     | \"shell\" -> ok File_pref.shell_like\n     | \"c\" -> ok File_pref.c_like\n     | \"cpp\" -> ok File_pref.cpp_like\n     | \"ocaml\" -> ok File_pref.ocaml_like\n     | other -> (failwith $\n         show's other . \" is not a valid file preference.\")) $\n    fun (prefs:File_pref.t) ->\n  bind'si (read_file ()) $ fun (filename:string) ->\n  bind'bi (read_init ()) $ fun (init:bool) ->\n  bind'si\n    (bind'ss (read_extension ()) $ fun (extension:string) ->\n     let _, ok = okfailwith's in\n     ok $ \".\" . extension) $\n    fun (extension:string) ->\n  bind'sOi (read_output ()) $ fun (output:string option) ->\n  bind'sLi (read_rest ()) $ fun (values:string List.t) ->\n  let values = List.sort{string} String.compare values in\n  let _, raise, failwith, ok = okfailwith'i in\n  match init with\n  | true -> (  (* create the source file *)\n      (* TODO: check if no .conflin boom is already there *)\n      bind'ui  (* check if no value is are defined *)\n        (let _, failwith, ok = okfailwith'u in\n         match values with\n         | [] -> ok ()\n         | _ -> failwith \"You can't give values with init.\") $\n        fun () ->\n      let c_stop = File_pref.c_stop in\n      let data = File_pref.data prefs in\n      bind'si  (* read and check file *)\n        (bind'ss (safe_read filename) $ fun (file:string) ->\n         check_string_with data file\n           (file_error filename \"contains commands-like comments\"\n              #{string}[])) $\n        fun (file:string) ->\n      let output = if_none's (filename . extension) output in\n      ok $ write output $ c_stop prefs . file)\n  | false -> (  (* get or put *)\n      let mlpv = main_lens prefs values in\n      match String.end_with filename extension with\n      | true -> (  (* get *)\n          let sfile = filename in\n          let vfile = String.rdrop (length extension) filename in\n          bind'si\n            (bind'ss (safe_read sfile) $ fun (source:string) ->\n             check_string_with (stype mlpv) source $\n               file_error sfile \"is not a valid source\" #{string}[\n                 \"The file_type is the right one\";\n                 \"The file does not contain mispelled commands\"]) $\n            fun (source:string) ->\n          let output = if_none's vfile output in\n          ok $ write output $ get mlpv source)\n      | false -> (  (* put *)\n          let vfile = filename in\n          let sfile = filename . extension in\n          bind'si\n            (bind'ss (safe_read vfile) $ fun (view:string) ->\n             check_string_with (vtype mlpv) view $\n               file_error vfile \"is not a valid view\" #{string}[\n                 \"The expanding value \"\n                 . show's (File_pref.make_view prefs values)\n                 . \" is the one after the view prefix\";\n                 \"The file_type is the right one\";\n                 \"You didn't misspelled a command\"]) $\n            fun (view:string) ->\n          let source =\n            let _, try, raise, failwith, _ = okfailwith's in\n            try (safe_read sfile) $ fun (exn:exception) ->\n            match exn with\n            | ErrNo (ENOENT _) -> failwith\n                \"Can't find a source file.  Did you forget --init?\"\n            | x -> raise x\n          in\n          bind'si\n            (bind'ss source $ fun (source:string) ->\n             check_string_with (stype mlpv) source $\n               file_error sfile \"is not a valid source\" #{string}[\n                 \"The file_type is the right one\";\n                 \"The extension \" . show's (String.drop 1 extension)\n                 . \" is the right one\"]) $\n            fun (source:string) ->\n          let output = if_none's sfile output in\n          ok $ write output $ put mlpv view source))\n\n(* ---------------------------------------------------------------- *)\n(*                            unit tests                            *)\n\n(* --- Debug --- *)\n\nlet mld = main_lens File_pref.debug_like\n\nlet mldv = mld #{string}[]\ntest get mldv (  \"()d0(a)a0()d1(b)b1()d2\")\n            = (\"()()d0(!a)()d1(!b)()d2\"  )\ntest put mldv (\"()\" .\"(!a)(!b)\"  ) (* ()    (!a)(!b) *)\n              (  \"()d0(a)a1(b)a2\") (* ()()d0(!a)(!b) *)\n            = (      \"(a)a1(b)a2\")\n\nlet mldv = mld #{string}[\"a\"]\ntest get mldv (   \"()d0(a)a0()d1(b)b1()d2\")\n            = (\"(a)()d0(a)a0()d1(!b)()d2\" )\n\nlet mldv = mld #{string}[\"a\";\"b\"]\ntest get mldv (    \"()d0(a)a0()d1(c)c1()d2(b)b2()d3\")\n            = (\"(ab)()d0(a)a0()d1(!c)()d2(b)b2()d3\" )\ntest put mldv (\"(ab)()D0(a)A1()D2\") (* (a)()D0(a)A1()D2 *)\n              (    \"()d0\"  .\"()d2\") (* (a)()d0     ()d2 *)\n            = (    \"()D0(a)A1()D2\")\ntest put mldv (\"(ab)()D0(!d)()D2\" ) (* (a)()D0(!d)()D2 *)\n              (    \"()d0(c)c1()d2\") (* (a)()d0(!c)()d2 *)\n            = error\n(* test put mldv (\"(ab)()D0\"  .\"()D2\") (\\* (a)()D0    ()D2 *\\) *)\n(*               (    \"()d0(c)c1()d2\") (\\* (a)()d0(!c)()d2 *\\) *)\n(*             = error *)\n\n(*\n * Local Variables:\n * mode: tuareg\n * End:\n *)\n"
let _ = Hashtbl.add items "units" "module Units =\n\n  let l1 : lens = copy [0-9]\n  let l2 : lens = copy [^0-9]\n  test (<l1> . <l2>) = error\n  test (<diffy \"x\":l1> . <diffy \"x\":l2>) = error\n  test (<diffy \"x\":l1> . <greedy 0 \"x\":l1>) = error\n  test (<Tag(Positional, Threshold 0, NoKey, \"x\"):l1> . <Tag(Positional, Threshold 1, NoKey, \"x\"):l1>) = error\n  test (<Tag(Positional, Threshold 0, NoKey, \"x\"):l1> . <Tag(Positional, Threshold 0, Key, \"x\"):l1>) = error\n\n  test \"a\"? . (\"aa\" <-> \"b\" | \"a\" <-> \"c\") = error\n\n  let single_cn : canonizer =\n    canonizer_of_lens ((WS . \"<a x=\") <-> \"<b x=\") .\n    canonizer_of_lens (dup1 DIGIT (\"><c y=\" . DIGIT) (fun (s:string) -> \"><c y=\" . s)) .\n    canonizer_of_lens \">\"\n\n  let double_cn : canonizer =\n    canonizer_of_lens (WS <-> \"\") .\n    canonizer_of_lens (\"<b x=\" . DIGIT . \">\") .\n    canonizer_of_lens (WS <-> \"\") .\n    canonizer_of_lens (\"<c y=\" . DIGIT . \">\")\n\n  let double_lns : lens =\n    (\"<b x=\" <-> \"\") .\n    DIGIT .\n    ins \",\" .\n    (\"><c y=\" <-> \"\") .\n    DIGIT .\n    (\">\" <-> \"\")\n\n  test left_quot (single_cn | double_cn) double_lns = error\n\n  let final_lns = left_quot (double_cn | single_cn) double_lns\n\n  test final_lns.get \"  \\n<a x=7>\" = \"7,7\"\n  test final_lns.get \"\\n  <b x=7>    <c y=7>\" = \"7,7\"\n  test final_lns.create \"7,7\" = \"<b x=7><c y=7>\"\n  test final_lns.create \"3,7\" = \"<b x=3><c y=7>\"\n\n  let qc (v:string) (E:regexp) (D:regexp) (u:string) =\n    left_quot (canonizer_of_lens (const E v v))\n      (right_quot (v <-> u)\n         (canonizer_of_lens (const D u u)))\n\n  test (qc \"x\" [a-z] [0-9] \"1\").create \"9\" = \"x\"\n\n(* permute *)\nlet l : lens = \n  lens_permute\n    #{int}[1;0;2] \n    #{lens}[copy [A-Z];key [0-9]; copy [a-z]]\n\ntest stype l = ([A-Z] . [0-9] . [a-z])\ntest vtype l = ([0-9] . [A-Z] . [a-z])\ntest l.get \"A5z\" = \"5Az\"\ntest l.create \"0Az\" = \"A0z\"\n\nlet l : lens = copy [a] ~ copy [b]\ntest l.get \"ab\" = \"ba\"\ntest l.create \"ba\" = \"ab\"\n\nlet l : lens = (copy [a])* ~ (copy [b])*\ntest l.create \"bbaaaaa\" = \"aaaaabb\"\n\n(* sort *)\nlet q : canonizer = sort #{regexp}[[0-9];[A-Z];[a-z]]\n\ntest canonize q \"f7N\" = \"7Nf\"\n\nlet sort3 (r1:regexp) (r2:regexp) (r3:regexp) = sort #{regexp}[r1;r2;r3] \nlet l3 = \n(*  let r1,r2,r3 = \"a\",\"b\",\"c\" in *)\n  let r1,r2,r3 = \"a\",\"b\",\"c\" in\n  left_quot (sort3 r1 r2 r3) (copy (r1 . r2 . r3))\n\ntest l3.get \"abc\" = \"abc\"\ntest l3.get \"abc\" = \"abc\"\ntest l3.get \"acb\" = \"abc\"\ntest l3.get \"acb\" = \"abc\"\ntest l3.get \"abc\" = \"abc\"\ntest l3.get \"acb\" = \"abc\"\ntest l3.get \"bac\" = \"abc\"\ntest l3.get \"bac\" = \"abc\"\ntest l3.get \"bca\" = \"abc\"\ntest l3.get \"bca\" = \"abc\"\ntest l3.get \"bac\" = \"abc\"\ntest l3.get \"bca\" = \"abc\"\ntest l3.get \"cab\" = \"abc\"\ntest l3.get \"cab\" = \"abc\"\ntest l3.get \"cba\" = \"abc\"\ntest l3.get \"cba\" = \"abc\"\ntest l3.get \"cab\" = \"abc\"\ntest l3.get \"cba\" = \"abc\"\ntest l3.get \"abc\" = \"abc\"\ntest l3.get \"acb\" = \"abc\"\ntest l3.get \"bac\" = \"abc\"\ntest l3.get \"bca\" = \"abc\"\ntest l3.get \"cab\" = \"abc\"\ntest l3.get \"cba\" = \"abc\"\n\n(* fiat *)\nlet lfiat =\n  fiat (Sort.sort_concat #{lens}[(\"a\" . del [0-9]);\n                                 (\"b\" . del [0-9]);\n                                 (\"c\" . del [0-9])])\nlet lnormal =\n       (Sort.sort_concat #{lens}[(\"a\" . del [0-9]);\n                                 (\"b\" . del [0-9]);\n                                 (\"c\" . del [0-9])])\n\ntest lfiat.get   \"b2a1c3\" = \"abc\"\ntest lnormal.get \"b2a1c3\" = \"abc\"\ntest lfiat.put   \"abc\" into \"b2a1c3\" = \"b2a1c3\"\ntest lnormal.put \"abc\" into \"b2a1c3\" = \"a1b2c3\"\n\n(* application operator *)\n\nlet f (x:string) = \"f(\".x.\")\"\nlet g (x:string) = \"g(\".x.\")\"\ntest (f $ g $ f $ f \"x\") = \"f(g(f(f(x))))\"\n\nlet f (x:string) (g:string -> string) = g x\ntest (f \"x\" $ fun (x:string) -> f \"y\" $ fun (y:string) -> x.y) = \"xy\"\n\n(* default chunk tag *)\n\nlet _ = <[a-z]> . <greedy 0 \"\":[a-z]> (* if this fails, the documentation of lens_match in core.boom needs to be changed *)\n"
let _ = Hashtbl.add items "test_alias" "module Test_alias = \n\nlet l = ((copy \"ABC\" . copy \"DEF\") . copy \"GHI\") . copy \"JKL\"\n\ntest get l \"ABCDEFGHIJKL\" = \"ABCDEFGHIJKL\"\ntest put l \"ABCDEFGHIJKL\" \"ABCDEFGHIJKL\" = \"ABCDEFGHIJKL\"\n\nlet ALPHA : regexp = [A-Za-z ]+\nlet YEARS : regexp = [0-9]\nlet l2 = ALPHA . \", \" . del YEARS . del \", \" . ALPHA\n\ntest get l2 \"Sancho Panza, 1, La Mancha\" = \"Sancho Panza, La Mancha\"\ntest put l2 \"Pancho Villa, Mexico\" \"Sancho Panza, 1, La Mancha\" = \"Pancho Villa, 1, Mexico\"\n"
let _ = Hashtbl.add items "test_cex" "module Test_cex =\n\nlet l1 = copy (EPSILON | \"A\")\nlet l2 = copy (\"A\" | \"AA\")\n\ntest l1.l2 = error\n\ntest l2* = error\n\ntest (l1 | l2) = error\n\ntest (l1 || l2) = error\n"
let _ = Hashtbl.add items "setlike" "module Setlike =\n\nlet set (name:string) = Tag (Setlike, Threshold 0, Key, name)\n\n\nlet main =\n  let word = copy [a-z]+ . \" \" in\n  let line = <set \"w\":word>* in\n    line\n\ntest put main \"\" \"\" = \"\"\ntest put main \"asdf \" \"\" = \"asdf \"\ntest put main \"\" \"asdf \" = \"\"\n\n\nlet sep_list (a:lens) (b:lens) = (a . (b . a)* )\n\nlet main = (* b *)\n  let word = copy [a-z]+ . del [A-Z]* in\n  let line = sep_list <set \"w\":word> \" \" in\n  line\n\ntest put main \"a b c d e\" \"aA bB cC dD eE\" = \"aA bB cC dD eE\"\ntest put main \"a c b e d\" \"aA bB cC dD eE\" = \"aA cC bB eE dD\"\ntest put main \"bbb aaa ccg dh xyz\" \"aaaA bbbB cccC dddD eeeE\" = \"bbbB aaaA ccgC dhD xyz\"\n\n(* greedy vs. hungarian *)\n\nlet gmain = (* greedy *)\n  let word = copy [a-z]+ . del [A-Z]* in\n  let line = sep_list <greedy 0 \"w\":key word> \" \" in\n  line\n\ntest put  main \"abd acdefg\" \"xyzabdXX acdYY\" = \"abdXX acdefgYY\"\ntest put gmain \"abd acdefg\" \"xyzabdXX acdYY\" = \"abdYY acdefgXX\"\ntest put  main \"abcd a\" \"abcgXX abcdghYY\" = \"abcdYY aXX\"\ntest put gmain \"abcd a\" \"abcgXX abcdghYY\" = \"abcdXX aYY\"\n\n(* back to hungarian *)\n\nlet main =\n  let word = (copy [a-z] . del [A-Z]* )+ in\n  let line = sep_list <set \"w\":word> \" \" in\n  let file = sep_list <set \"l\":line> \"\\n\" in\n  file\n\ntest get main \"aRobASe\" = \"aobe\"\ntest get main <<\n  worDonE woRDTwo\n  linETwo loETne lOteE\n  omTEo mENToe o nto\n  aoOEEU thoeu nOEUA\n>> = <<\n  woron wowo\n  linwo lone lte\n  omo moe o nto\n  ao thoeu n\n>>\n\ntest create main \"aoeu\" = \"aoeu\"\ntest create main <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>> = <<\n  sntoh sanose ate\n  san asnta to\n  snt aoe nst\n>>\n\ntest put main \"a b c\" \"aA bB cC\" = \"aA bB cC\"\ntest put main \"a b c\" \"bB cC aA\" = \"aA bB cC\"\ntest put main \"a b c\" \"cC aA bB\" = \"aA bB cC\"\n\ntest put main \"a b c d f\" \"aA cC dD eE fF\" = \"aA b cC dD fF\"\n\ntest put main \"a b c\" \"aX aY aZ\" = \"aZ b c\"\ntest put main \"a a a\" \"bB aA cC\" = \"aC aA aB\"\n\ntest put main \"b c\" \"aA bB cC\" = \"bB cC\"\ntest put main \"a c\" \"aA bB cC\" = \"aA cC\"\ntest put main \"a b\" \"aA bB cC\" = \"aA bB\"\n\ntest put main \"a\" \"aA\"                = \"aA\"\ntest put main \"a\" \"aA aAA\"            = \"aAA\"\ntest put main \"a\" \"aA aAA aAAA\"       = \"aAAA\"\ntest put main \"a\" \"aA aAA aAAA aAAAA\" = \"aAAAA\"\n\ntest put main \"a\"         \"aA\" = \"aA\"\ntest put main \"a a\"       \"aA\" = \"a aA\"\ntest put main \"a a a\"     \"aA\" = \"a a aA\"\ntest put main \"a a a a\"   \"aA\" = \"a a a aA\"\ntest put main \"a a a a a\" \"aA\" = \"a a a a aA\"\n\n(* imprevisible answers when the costs are the same *)\ntest put main \"b\"         \"bB bBB bBBB\" = \"bBBB\"\ntest put main \"b b\"       \"bB bBB bBBB\" = \"bBBB bBB\"\ntest put main \"b b b\"     \"bB bBB bBBB\" = \"bB bBB bBBB\"\ntest put main \"b b b b\"   \"bB bBB bBBB\" = \"b bBB bBBB bB\"\ntest put main \"b b b b b\" \"bB bBB bBBB\" = \"b b bBBB bBB bB\"\n\ntest put main \"b a\" \"aA bB\" = \"bB aA\"\n\ntest put main \"b c a y\" \"aA bB cC dD\" = \"bB cC aA y\"\ntest put main \"x y z\" \"aA bB cC\" = \"x y z\"\n\ntest put main \"xxx yy z\" \"aA bBbBB cCcCCcCCC\" = \"xxx yy z\"\n\ntest put main <<\n  a a a a a\n  z\n  b c a y\n>> <<\n  aA bB cC dD\n  aAAA aAA aA\n  xXXX\n>> = <<\n  a a aA aAA aAAA\n  z\n  bB cC aA y\n>>\n\ntest put main <<\n  ooo ooo o\n  nn nnn\n  aaa a aa\n  uu u\n  ddd dd d\n>> <<\n  oooOOoO oOOooO oO\n  aaAAa aAaa aAA aAAa\n  eeEeEE eE\n  uUUuuU uuUU\n>> = <<\n  oOOooO oooOO oO\n  nn nnn\n  aAaa aAA aAAa\n  uuUU uUU\n  ddd dd d\n>>\n\ntest put main <<\ncursed eua lorem acumsam vitae\nator idfk ipsum naquele\nnulla adipiscing lorem\ncum sociss ipsum\nlorem ip summation dollar sit meat\nconsectetur lorem adipiscing ipsum lite\nlorem ipsum integer pirus nibh\n>> <<\nloremA ipsumB dolorC sitD ametE\nconsecteturF adipiscingG elitH\nintegerI purusJ nibhK\ncursusL euM accumsanN vitaeO\nauctorP idQ nequeR\ncumS sociisT\n>> = <<\ncursedL euMa lorem acumsam vitaeO\nator idQfk ipsum naqueRle\nnulla adipiscing lorem\ncumS socissT ipsum\nloremA ip summaBtion dollaCr sitD meatE\nconsecteturF lorem adipiscingG ipsum liteH\nlorem ipsum integerI pirusJ nibhK\n>>\n\nlet main =\n  let word = ([a-m] . del [A-Z]* | [n-z] . del [A-Z]* )+ in\n  sep_list (\"+\" . <set \"w\":word> | \"-\" . <set \"w\":word>) \" \"\n\ntest get main \"+aA -bB\" = \"+a -b\"\ntest put main \"+a -b +c -d\" \"+aA -bB +cC -dD\" = \"+aA -bB +cC -dD\"\ntest put main \"-a +b -c +d\" \"+aA -bB +cC -dD\" = \"-aA +bB -cC +dD\"\ntest put main \"+c -d +a -b\" \"+aA -bB +cC -dD\" = \"+cC -dD +aA -bB\"\ntest put main \"-c -d +a +b\" \"+aA -bB +cC -dD\" = \"-cC -dD +aA +bB\"\n\ntest put main \"+a +c -d\" \"+aA -bB +cC\" = \"+aA +cC -d\"\ntest put main \"-a +m +d -e\" \"+aA -bB +cC -dD\" = \"-aA +m +dD -e\"\ntest put main \"-a +n +d -e\" \"+aA -bB +cC -dD\" = \"-aA +n +dD -e\"\n\n(* compose *)\n\nlet main =\n  let word1 = ([a-z] . [A-Z]* . del [0-9]* )+ in\n  let line1 = sep_list <set \"w\":word1> \" \" in\n  let file1 = sep_list <set \"l\":line1> \"\\n\" in\n  let word2 = ([a-z] . del [A-Z]* )+ in\n  let line2 = sep_list <set \"w\":word2> \" \" in\n  let file2 = sep_list <set \"l\":line2> \"\\n\" in\n  file1 ; file2\n\ntest get main \"aA0 bB1 cC2\" = \"a b c\"\ntest create main \"a b c\" = \"a b c\"\ntest put main \"a b c\" \"aA0 bB1 cC2\" = \"aA0 bB1 cC2\"\ntest put main \"b a\" \"aA0 bB1 cC2\" = \"bB1 aA0\"\ntest put main \"a c d\" \"aA0 bB1 cC2\" = \"aA0 cC2 d\"\n\nlet main =\n  let sep_iter (a:lens) (b:lens) (n:int) = a . lens_iter (b . a) n n in\n  let cn = [a-z] . [A-Z]* in\n  let wn = <set \"c\":cn>+ in\n  let wnc = <set \"w\":wn> in\n  let c = [a-z] . del [A-Z]* in\n  let w = <set \"c\":c>+ in\n  let wc = <set \"w\":w> in\n  ( sep_iter   wnc \" \" 3 . '1' <-> '2'\n  ; sep_iter   wnc \" \" 3 . '2' <-> '3')\n  ; ( sep_iter wnc \" \" 3 . '3' <-> '4'\n    ; sep_iter wc \" \" 3 . '4' <-> '5')\n\ntest get main \"aAbB cCdD eE fF1\" = \"ab cd e f5\"\ntest create main \"a b c e5\" = \"a b c e1\"\ntest put main \"b de ge h5\" \"aAbB cC dDeE fFgG1\" = \"bB dDeE gGe h1\"\n\n(* invert *)\n\nlet main =\n  let l = invert (copy [a-z] . del \"B\") . del [ 0-9]\n  in <set \"\":l>*\n\ntest get main \"a1b2\" = \"aBbB\"\ntest create main \"aBbB\" = \"a b \"\ntest put main \"aBbBcBeB\" \"a1c3d4e5\" = \"a1b4c3e5\"\n\n\nlet setlikedict (l:lens) = <Tag (Setlike, Threshold 100, NoKey, \"\"):l>\n\nlet main =\n  let word = key [a-z]+ . [A-Z]* . del [0-9]* . \" \" in\n  let line = (setlikedict word)* in\n    line\n\ntest get main \"\" = \"\"\ntest get main \"aA9 \" = \"aA \"\ntest put main \"aC aBB aAAA aDDD \" \"aAAA1 aBBB2 aCCC3 aDDD4 \" = \"aC1 aBB2 aAAA3 aDDD4 \"\nlet str = \"aA1 aX9 aY8 bB2 bZ7 \"\ntest put main \"\" str = \"\"\ntest put main \"a a a \" str = \"a1 a9 a8 \"\ntest put main \"a a \" str = \"a8 a9 \"\ntest put main \"a \" str = \"a8 \"\ntest put main \"aF aG aH aJ \" str = \"aF aG9 aH8 aJ1 \"\ntest put main \"x y z \" str = \"x y z \"\n\ntest put main \"aaa aab aba abb \" \"baa4 bab3 bba2 bbb1 \" = \"aaa aab aba abb \"\n"
let _ = Hashtbl.add items "list" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2008                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /lenses/list.boom                                                          *)\n(* List module                                                                *)\n(* $Id: list.boom 4635 2009-08-25 18:52:01Z cretin $ *)\n(*******************************************************************************)\n\nmodule List = \n#{@}\n\n\\section{Lists}\n\nThe @List@ module defines a datatype for polymorphic list structures.\nIn this module we cannot use the Boomerang notation for lists because\nit is resolved using List.Nil and List.Cons, which are not valid names\nwhile the List module is being defined.\n\n\\LENSSECTION{@'a t@} A list is either the @Nil@ list or a @Cons@ of a head \nand a tail.\n\n#* type 'a t = Nil | Cons of 'a * 'a t\n\n\\LENSSECTION{@empty@,@nonempty@} Predicates for detecting (non)empty lists.\n\n#* let empty ('a) (l:'a t) : bool =\n#*   match l with\n#*     | Nil     -> true\n#*     | Cons(_) -> false\n\n#* let nonempty ('a) (l:'a t) : bool = not (empty{'a} l)\n\n\\LENSSECTION{@hd@,@tl@} The selectors @hd@ and @tl@ pull out the first and last\nparts of a @Cons@-cell, respectively.\n\n#* let hd ('a) (xs:'a t) : 'a =\n#*   let (Cons(x,_)) = xs in\n#*   x\n\n#* let tl ('a) (xs:'a t) : 'a t =\n#*   let (Cons(_,xs)) = xs in\n#*   xs\n\n\\LENSSECTION{@fold_left@} Boomerang does not support recursion. However, we \nprovide the @fold_left@ function on lists via a built-in primitive.\n\n#* let fold_left ('a) ('b) (f:'b -> 'a -> 'b) (acc:'b) (l:'a t) : 'b \n## = Native.Prelude.fold_left{'b}{'a} f acc l \n\n\\LENSSECTION{@length@} Calculates the length of a list.\n\n#* let length ('a) (l : 'a t) : int =\n#*   fold_left{'a}{int}\n#*     (fun (n:int) (v:'a) -> plus n 1)\n#*     0 l\n\n#* test length{bool} Nil{bool} = 0\n#* test length{bool} (Cons{bool}(true,Cons{bool}(false,Nil{bool}))) = 2\n\n\\LENSSECTION{@mk_seq@} The function @mk_seq@ returns a list of\nintegers from @0@ to @n-1@.\n\n#* let mk_seq (n:int where n geq 0) : (l:int t where length{int} l = n)\n## = Native.Prelude.mk_seq n\n\n\\LENSSECTION{@reverse@} The function @reverse@ can be defined straightforwardly\nusing @fold_left@.\n\n#* let reverse ('a) (l : 'a t) : 'a t =\n#*   fold_left{'a}{'a t} \n#*     (fun (t:'a t) (h:'a) -> Cons{'a}(h,t)) \n#*     Nil{'a} \n#*     l\n\n\\LENSSECTION{@append@} The function @append@ can be defined using\n@fold_left@ and @reverse@.\n\n#* let append ('a) (l1 : 'a t) (l2 : 'a t) : 'a t =\n#*   fold_left{'a}{'a t}\n#*     (fun (l:'a t) (x:'a) -> Cons{'a}(x,l))\n#*     l2\n#*     (reverse{'a} l1)\n\n\\LENSSECTION{@map@,@rev_map@} The function @map@ can be defined\n(inefficiently) using @fold_left@ and @reverse@.  The @rev_map@ is\nmore efficient, but leaves the list reversed.\n\n#* let rev_map ('a) ('b) (f:'a -> 'b) (l:'a t) : 'b t = \n#*   fold_left{'a}{'b t}\n#*     (fun (t:'b t) (h:'a) -> Cons{'b}(f h,t)) \n#*     Nil{'b}\n#*     l\n\n#* let map ('a) ('b) (f:'a -> 'b) (l:'a t) : 'b t = \n#*   reverse{'b} (rev_map{'a}{'b} f l)\n\n\\LENSSECTION{@exists@} The function @exists@ tests if a predicate holds of \nsome element of the list.\n\n#* let exists ('a) (t:'a -> bool) (l:'a t) : bool = \n#*   fold_left {'a}{bool} (fun (b:bool) (h:'a) -> b || t h) \n#*   false \n#*   l\n\n\\LENSSECTION{@for_all@} The function @for_all@ tests if a predicate holds of\nevery element of the list.\n\n#* let for_all ('a) (t:'a -> bool) (l:'a t) : bool =\n#*   fold_left {'a}{bool} (fun (b:bool) (h:'a) -> b && t h) \n#*   true\n#*   l\n\n\\LENSSECTION{@member@} The function @member@ tests if an element is a\nmember of the list. It is defined using @exists@.\n\n#* let member ('a) (x:'a) (l:'a t) : bool = \n#*  exists{'a} (fun (h:'a) -> x = h) l \n\n\\subsection{Permutations}\n\nA permutation is an integer list, mapping positions to other positions: if \nthe @i@th entry of a permutation is the number @j@, then the @i@th element \nin the original list will be the @j@th element in the permuted list.  A \npermutation for the list @#{bool}[true;true;false;true;false]@ might be \n@#{int}[0;1;2;3;4]@ (the identity permutation) or @#{int}[4;3;2;1;0]@ \n(reversal).\n\n\\LENSSECTION{@valid_permutation@} The predicate @valid_permutation@ is true \nwhen given the given permutation can be applied to the given list.\n\n#* let valid_permutation ('a) (sigma:int t) (l:'a t) : bool\n## = Native.Prelude.valid_permutation{'a} sigma l\n\n#* test valid_permutation{bool} Nil{int} Nil{bool} = true\n#* test valid_permutation{bool} \n#*  (Cons{int}(1,Cons{int}(0,Nil{int}))) \n#*  (Cons{bool}(false,Cons{bool}(true,Nil{bool}))) = true\n#* test valid_permutation{bool} \n#*   (Cons{int}(1,Cons{int}(1,Nil{int}))) \n#*   (Cons{bool}(false,Cons{bool}(true,Nil{bool}))) = false\n#* test valid_permutation{bool} \n#*   (Cons{int}(0 - 1,Cons{int}(1,Nil{int}))) \n#*   (Cons{bool}(false,Cons{bool}(true,Nil{bool}))) = false\n#* test valid_permutation{bool} \n#*   (Cons{int}(0,Cons{int}(1,Cons{int}(2,Nil{int})))) \n#*   (Cons{bool}(false,Cons{bool}(true,Nil{bool}))) = false\n#* test valid_permutation{bool} \n#*   (Cons{int}(1,Nil{int})) \n#*   (Cons{bool}(false,Cons{bool}(true,Nil{bool}))) = false\n#* test valid_permutation{bool} \n#*   (Cons{int}(1,Cons{int}(2,Nil{int}))) \n#*   (Cons{bool}(false,Cons{bool}(true,Nil{bool}))) = false\n\n\\LENSSECTION{@permute@} The operator @permute@ permutes a list according\n to a given permutation.\n\n#* let permute ('a) \n#*          (sigma:int t) \n#*          (l:'a t where valid_permutation{'a} sigma l)\n#*   : 'a t\n##   = Native.Prelude.list_permute{'a} sigma l\n\n#* test permute{bool} Nil{int} Nil{bool} = Nil{bool}\n#* test permute{bool} \n#*   (Cons{int}(0,Cons{int}(1,Nil{int}))) \n#*   (Cons{bool}(false,Cons{bool}(true,Nil{bool})))\n#* = (Cons{bool}(false,Cons{bool}(true,Nil{bool})))\n#* test permute{bool} \n#*   (Cons{int}(1,Cons{int}(0,Nil{int}))) \n#*   (Cons{bool}(false,Cons{bool}(true,Nil{bool}))) \n#* = (Cons{bool}(true,Cons{bool}(false,Nil{bool})))\n#* test permute{string} \n#*   (Cons{int}(0,Cons{int}(2,Cons{int}(1,Nil{int})))) \n#*   (Cons{string}(\"a\",Cons{string}(\"b\",Cons{string}(\"c\",Nil{string})))) \n#* = (Cons{string}(\"a\",Cons{string}(\"c\",Cons{string}(\"b\",Nil{string}))))\n\n\\LENSSECTION{@permutations@} The operator @permutations@ returns a list of\nall possible permutations for lists of a given length.\n\n#* let permutations : (n:int where (n geq 0)) -> (int t) t\n## = Native.Prelude.permutations\n\n#* test permutations 0 = (Cons{int t}(Nil{int},\n#*                        Nil{int t}))\n#* test permutations 1 = (Cons{int t}(Cons{int}(0,Nil{int}),\n#*                        Nil{int t}))\n#* test permutations 2 = (Cons{int t}(Cons{int}(0,Cons{int}(1,Nil{int})),\n#*                        Cons{int t}(Cons{int}(1,Cons{int}(0,Nil{int})),\n#*                        Nil{int t})))\n\n\\LENSSECTION{@invert_permutation@} The operator @invert_permutation@ inverts a\npermutation @sigma@, calculating the permutation @sigma_inv@ such that\n@permute_list{'a} sigma_inv (permuate_list{'a} sigma l) = l@ for all @l@.\n\n#* let invert_permutation : int t -> int t\n## = Native.Prelude.invert_permutation\n\n#* let sort : forall 'a => ('a -> 'a -> int) -> 'a t -> 'a t\n## = Native.Prelude.list_sort\n\n#* test sort{int} minus (Cons{int}(3, Cons{int}(4, Cons{int}(1, Cons{int}(0,\n#*      Nil{int}))))) = (Cons{int}(0, Cons{int}(1, Cons{int}(3, Cons{int}(4,\n#*      Nil{int})))))\n"
let _ = Hashtbl.add items "prefs" "(******************************************************************************)\n(* The Harmony Project                                                        *)\n(* harmony@lists.seas.upenn.edu                                               *)\n(******************************************************************************)\n(* Copyright (C) 2009                                                         *)\n(* J. Nathan Foster and Benjamin C. Pierce                                    *)\n(*                                                                            *)\n(* This library is free software; you can redistribute it and/or              *)\n(* modify it under the terms of the GNU Lesser General Public                 *)\n(* License as published by the Free Software Foundation; either               *)\n(* version 2.1 of the License, or (at your option) any later version.         *)\n(*                                                                            *)\n(* This library is distributed in the hope that it will be useful,            *)\n(* but WITHOUT ANY WARRANTY; without even the implied warranty of             *)\n(* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU          *)\n(* Lesser General Public License for more details.                            *)\n(******************************************************************************)\n(* /lenses/prefs.boom                                                         *)\n(* Handle arguments for the main function                                     *)\n(* $Id: prefs.boom 4624 2009-08-12 16:13:36Z cretin $ *)\n(******************************************************************************)\n\nmodule Prefs =\n\n#{@}\n\n\\section{Command line parsing}\n\n#* let get_prog_name : unit -> string\n## = Native.Prelude.prefs_get_prog_name\n\n\\LENSSECTION{@create_bool@} @create_bool name default doc fulldoc@\ncreates a preference such that if @-name@ is present in the command\nline, then the value will be @true@.  If @-name=false@ is present in\nthe command line then the value will be @false@.\n\n#* let create_bool (name:string) (default:bool) (doc:string) : bool_prefs\n## = Native.Prelude.prefs_create_bool name default doc\n\n#* let alias_bool : bool_prefs -> string -> unit\n## = Native.Prelude.prefs_alias_bool\n\n#* let read_bool : bool_prefs -> bool\n## = Native.Prelude.prefs_read_bool\n\n#* let create_int (name:string) (default:int) (doc:string) : int_prefs\n## = Native.Prelude.prefs_create_int name default doc\n\n#* let alias_int : int_prefs -> string -> unit\n## = Native.Prelude.prefs_alias_int\n\n#* let read_int : int_prefs -> int\n## = Native.Prelude.prefs_read_int\n\n#* let create_string (name:string) (default:string) (doc:string) : string_prefs\n## = Native.Prelude.prefs_create_string name default doc\n\n#* let alias_string : string_prefs -> string -> unit\n## = Native.Prelude.prefs_alias_string\n\n#* let read_string : string_prefs -> string\n## = Native.Prelude.prefs_read_string\n\n#* let create_string_list (name:string) (doc:string) : string_list_prefs\n## = Native.Prelude.prefs_create_string_list name doc\n\n#* let alias_string_list : string_list_prefs -> string -> unit\n## = Native.Prelude.prefs_alias_string_list\n\n#* let read_string_list : string_list_prefs -> string List.t\n## = Native.Prelude.prefs_read_string_list\n\n#* let print_usage : string -> unit\n## = Native.Prelude.prefs_print_usage\n\n\\LENSSECTION{@extern_rest@} @extern_rest ()@ returns the preference\nfor anonymous arguments.\n\n#* let extern_rest : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_rest\n\n#* let extern_output : unit -> string_prefs\n## = Native.Prelude.prefs_extern_output\n\n#* let extern_lens : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_lens\n\n#* let extern_source : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_source\n\n#* let extern_view : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_view\n\n#* let extern_expression : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_expression\n\n#* let extern_check : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_check\n\n#* let extern_include : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_include\n\n#* let extern_test : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_test\n\n#* let extern_testall : unit -> bool_prefs\n## = Native.Prelude.prefs_extern_testall\n\n#* let extern_debug : unit -> string_list_prefs\n## = Native.Prelude.prefs_extern_debug\n\n#* let extern_debugtimes : unit -> bool_prefs\n## = Native.Prelude.prefs_extern_debugtimes\n\n#* let extern_log : unit -> bool_prefs\n## = Native.Prelude.prefs_extern_log\n\n#* let extern_logfile : unit -> string_prefs\n## = Native.Prelude.prefs_extern_logfile\n\n#* let extern_terse : unit -> bool_prefs\n## = Native.Prelude.prefs_extern_terse\n\n#* let extern_timers : unit -> bool_prefs\n## = Native.Prelude.prefs_extern_timers\n\n#* let extern_colorize : unit -> bool_prefs\n## = Native.Prelude.prefs_extern_colorize\n\n"
let _ = Hashtbl.add items "nice" "module Nice = \n\n  let l (l:string) (u:string) : lens = \n    ins l . \n    Xml.simple_elt_no_kids NL1 u \n  \n  let xs : lens = (l \"x\" \"X\")*\n  \n  let ys : lens = (l \"y\" \"Y\")*\n\n  let n : lens = \n    Xml.elt NL0 \"A\"\n      begin\n        ys ~ xs\n      end\n\ntest n.get \n<<\n  <A>\n    <Y></Y><Y></Y>\n    <X></X><X></X><X></X><X></X>\n  </A>\n>> \n=\n<<\n  xxxxyy\n>>\n\ntest n.create \n<<\n  xxxxyy\n>>\n=\n<<\n \n <A>\n  <Y/>\n  <Y/>\n  <X/>\n  <X/>\n  <X/>\n  <X/>\n </A>\n>> \n\n \n"
